[
  {
    "idx": 2,
    "question": {
      "kor": "한 로봇 회사가 의료 수술을 위한 솔루션을 설계하고 있습니다. 로봇은 고급 센서, 카메라 및 AI 알고리즘을 사용하여 환경을 인식하고 수술을 완료합니다.\n회사에는 백엔드 서비스와의 원활한 통신을 보장할 AWS 클라우드의 공용 로드 밸런서가 필요합니다. 로드 밸런서는 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있어야 합니다. 트래픽도 암호화되어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A robotics company is designing a solution for medical surgery. The robots will use advanced sensors, cameras, and AI algorithms to perceive their environment and to complete surgeries.\nThe company needs a public load balancer in the AWS Cloud that will ensure seamless communication with backend services. The load balancer must be capable of routing traffic based on the query strings to different target groups. The traffic must also be encrypted.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "ACM(AWS Certificate Manager)에서 첨부된 인증서와 함께 Application Load Balancer를 사용합니다. 쿼리 매개변수 기반 라우팅을 사용합니다.",
        "B": "Network Load Balancer를 사용하십시오. AWS Identity and Access Management(IAM)에서 생성된 인증서를 가져옵니다. 인증서를 로드 밸런서에 연결합니다. 쿼리 매개변수 기반 라우팅을 사용합니다.",
        "C": "게이트웨이 로드 밸런서를 사용합니다. AWS Identity and Access Management(IAM)에서 생성된 인증서를 가져옵니다. 인증서를 로드 밸런서에 연결합니다. HTTP 경로 기반 라우팅을 사용합니다.",
        "D": "ACM(AWS Certificate Manager)에서 첨부된 인증서와 함께 Network Load Balancer를 사용하십시오. 쿼리 매개변수 기반 라우팅을 사용합니다."
      },
      "eng": {
        "A": "Use an Application Load Balancer with a certificate attached from AWS Certificate Manager (ACM). Use query parameter-based routing.",
        "B": "Use a Network Load Balancer. Import a generated certificate in AWS Identity and Access Management (IAM). Attach the certificate to the load balancer. Use query parameter-based routing.",
        "C": "Use a Gateway Load Balancer. Import a generated certificate in AWS Identity and Access Management (IAM). Attach the certificate to the load balancer. Use HTTP path-based routing.",
        "D": "Use a Network Load Balancer with a certificate attached from AWS Certificate Manager (ACM). Use query parameter-based routing."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "ELB",
      "routing methods",
      "encryption in flight"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/136955-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 5,
    "question": {
      "kor": "회사에는 1,000개의 Amazon EC2 Linux 인스턴스에서 실행되는 프로덕션 워크로드가 있습니다. 워크로드는 타사 소프트웨어로 구동됩니다. 회사는 중요한 보안 취약성을 수정하기 위해 가능한 한 빨리 모든 EC2 인스턴스에서 타사 소프트웨어를 패치해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company has a production workload that runs on 1,000 Amazon EC2 Linux instances. The workload is powered by third-party software. The company needs to patch the third-party software on all EC2 instances as quickly as possible to remediate a critical security vulnerability.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "모든 EC2 인스턴스에 패치를 적용할 AWS Lambda 함수를 생성합니다.",
        "B": "모든 EC2 인스턴스에 패치를 적용하도록 AWS Systems Manager Patch Manager를 구성합니다.",
        "C": "모든 인스턴스에 EC2 패치를 적용하도록 AWS Systems Manager 유지 관리 기간을 예약합니다.",
        "D": "AWS Systems Manager Run Command를 사용하여 패치를 모든 EC2 인스턴스에 적용하는 사용자 지정 명령을 실행합니다."
      },
      "eng": {
        "A": "Create an AWS Lambda function to apply the patch to all EC2 instances.",
        "B": "Configure AWS Systems Manager Patch Manager to apply the patch to all EC2 instances.",
        "C": "Schedule an AWS Systems Manager maintenance window to apply the patch to all EC2 instances.",
        "D": "Use AWS Systems Manager Run Command to run a custom command that applies the patch to all EC2 instances."
      }
    },
    "category": [
      "AWS Systems Manager"
    ],
    "subcategory": [
      "Patch Manager"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85026-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 8,
    "question": {
      "kor": "회사는 최근 청구서에서 Amazon EC2 비용이 증가했음을 확인했습니다. 청구 팀은 몇 가지 EC2 인스턴스에 대한 인스턴스 유형의 원치 않는 수직 확장을 발견했습니다. 솔루션 아키텍트는 최근 2개월간의 EC2 비용을 비교하는 그래프를 생성하고 심층 분석을 수행하여 수직 확장의 근본 원인을 식별해야 합니다.\n솔루션 설계자는 최소한의 운영 오버헤드로 정보를 어떻게 생성해야 합니까?",
      "eng": "A company observes an increase in Amazon EC2 costs in its most recent bill. The billing team notices unwanted vertical scaling of instance types for a couple of EC2 instances. A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in-depth analysis to identify the root cause of the vertical scaling.\nHow should the solutions architect generate the information with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 EC2 비용을 비교합니다.",
        "B": "비용 탐색기의 세분화된 필터링 기능을 사용하여 인스턴스 유형에 따라 EC2 비용을 심층 분석합니다.",
        "C": "AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2개월 동안 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.",
        "D": "AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 보냅니다. Amazon S3와 함께 Amazon QuickSight를 소스로 사용하여 인스턴스 유형을 기반으로 대화형 그래프를 생성합니다."
      },
      "eng": {
        "A": "Use AWS Budgets to create a budget report and compare EC2 costs based on instance types.",
        "B": "Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.",
        "C": "Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the last 2 months.",
        "D": "Use AWS Cost and Usage Reports to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight with Amazon S3 as a source to generate an interactive graph based on instance types."
      }
    },
    "category": [
      "Cost"
    ],
    "subcategory": [
      "Cost Management",
      "Cost Explorer"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85038-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 10,
    "question": {
      "kor": "회사는 Amazon DynamoDB를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 실행합니다. 데이터 손상의 경우 솔루션 설계자는 15분의 RPO(복구 지점 목표)와 1시간의 RTO(복구 시간 목표)를 충족하는 솔루션을 설계해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company runs a shopping application that uses Amazon DynamoDB to store customer information. In case of data corruption, a solutions architect needs to design a solution that meets a recovery point objective (RPO) of 15 minutes and a recovery time objective (RTO) of 1 hour.\nWhat should the solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB 전역 테이블을 구성합니다. RPO 복구의 경우 애플리케이션이 다른 AWS 리전을 가리키도록 합니다.",
        "B": "DynamoDB 특정 시점으로 복구를 구성합니다. RPO 복구를 위해 원하는 시점으로 복원합니다.",
        "C": "매일 DynamoDB 데이터를 Amazon S3 Glacier로 내보냅니다. RPO 복구를 위해 S3 Glacier에서 DynamoDB로 데이터를 가져옵니다.",
        "D": "15분마다 DynamoDB 테이블에 대한 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 예약합니다. RPO 복구의 경우 EBS 스냅샷을 사용하여 DynamoDB 테이블을 복원합니다."
      },
      "eng": {
        "A": "Configure DynamoDB global tables. For RPO recovery, point the application to a different AWS Region.",
        "B": "Configure DynamoDB point-in-time recovery. For RPO recovery, restore to the desired point in time.",
        "C": "Export the DynamoDB data to Amazon S3 Glacier on a daily basis. For RPO recovery, import the data from S3 Glacier to DynamoDB.",
        "D": "Schedule Amazon Elastic Block Store (Amazon EBS) snapshots for the DynamoDB table every 15 minutes. For RPO recovery, restore the DynamoDB table by using the EBS snapshot."
      }
    },
    "category": [
      "DynamoDB"
    ],
    "subcategory": [
      "recovery point objective",
      "recovery time objective"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85603-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 20,
    "question": {
      "kor": "회사에서 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 이 회사는 여러 AWS 지역에 배포했습니다.\n회사는 지연 시간이 가장 짧은 리전으로 사용자를 라우팅해야 합니다. 회사는 또한 리전 간에 자동화된 장애 조치가 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company provides a Voice over Internet Protocol (VoIP) service that uses UDP connections. The service consists of Amazon EC2 instances that run in an Auto Scaling group. The company has deployments across multiple AWS Regions.\nThe company needs to route users to the Region with the lowest latency. The company also needs automated failover between Regions.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 NLB를 AWS Global Accelerator 엔드포인트로 사용합니다.",
        "B": "ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 ALB를 AWS Global Accelerator 엔드포인트로 사용합니다.",
        "C": "NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 NLB의 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 생성합니다.",
        "D": "ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 ALB의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다."
      },
      "eng": {
        "A": "Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Use the NLB as an AWS Global Accelerator endpoint in each Region.",
        "B": "Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Use the ALB as an AWS Global Accelerator endpoint in each Region.",
        "C": "Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 latency record that points to aliases for each NLB. Create an Amazon CloudFront distribution that uses the latency record as an origin.",
        "D": "Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 weighted record that points to aliases for each ALB. Deploy an Amazon CloudFront distribution that uses the weighted record as an origin."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "ELB",
      "Global Accelerator",
      "protocol",
      "multi region routing",
      "latency based routing",
      "automatic failover"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85029-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 22,
    "question": {
      "kor": "Amazon EC2 관리자는 여러 사용자를 포함하는 IAM 그룹과 연결된 다음 정책을 생성했습니다.\n이 정책의 효과는 무엇입니까?",
      "eng": "An Amazon EC2 administrator created the following policy associated with an IAM group containing several users:\nWhat is the effect of this policy?"
    },
    "choices": {
      "kor": {
        "A": "사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다.",
        "B": "사용자는 us-east-1 지역에서 IP 주소가 10.100.100.1인 EC2 인스턴스를 종료할 수 있습니다.",
        "C": "사용자의 소스 IP가 10.100.100.254인 경우 사용자는 us-east-1 지역에서 EC2 인스턴스를 종료할 수 있습니다.",
        "D": "사용자의 소스 IP가 10.100.100.254인 경우 사용자는 us-east-1 지역에서 EC2 인스턴스를 종료할 수 없습니다."
      },
      "eng": {
        "A": "Users can terminate an EC2 instance in any AWS Region except us-east-1.",
        "B": "Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region.",
        "C": "Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.",
        "D": "Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86460-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 48,
    "question": {
      "kor": "솔루션 아키텍트가 2계층 웹 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 퍼블릭 서브넷의 Amazon EC2에서 호스팅되는 퍼블릭 웹 계층으로 구성됩니다. 데이터베이스 계층은 프라이빗 서브넷의 Amazon EC2에서 실행되는 Microsoft SQL Server로 구성됩니다. 보안은 회사의 최우선 순위입니다.\n이 상황에서 보안 그룹을 어떻게 구성해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A solutions architect is designing a two-tier web application. The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets.\nThe database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company.\nHow should security groups be configured in this situation? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "0.0.0.0/0에서 포트 443의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.",
        "B": "0.0.0.0/0의 포트 443에서 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.",
        "C": "웹 계층의 보안 그룹에서 포트 1433의 인바운드 트래픽을 허용하도록 데이터베이스 계층의 보안 그룹을 구성합니다.",
        "D": "웹 계층의 보안 그룹에 대한 포트 443 및 1433의 아웃바운드 트래픽을 허용하도록 데이터베이스 계층의 보안 그룹을 구성합니다.",
        "E": "웹 계층에 대한 보안 그룹의 포트 443 및 1433에서 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다."
      },
      "eng": {
        "A": "Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.",
        "B": "Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0.",
        "C": "Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.",
        "D": "Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier.",
        "E": "Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier."
      }
    },
    "category": [
      "Security Group"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85346-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 51,
    "question": {
      "kor": "회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 관심이 있습니다. 테이블은 대부분의 아침에 사용되지 않습니다. 저녁에는 읽기 및 쓰기 트래픽을 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur, they will happen very quickly.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.",
        "B": "글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.",
        "C": "프로비저닝된 용량과 Auto Scaling으로 DynamoDB 테이블을 생성합니다.",
        "D": "프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 글로벌 테이블로 구성합니다."
      },
      "eng": {
        "A": "Create a DynamoDB table in on-demand capacity mode.",
        "B": "Create a DynamoDB table with a global secondary index.",
        "C": "Create a DynamoDB table with provisioned capacity and auto scaling.",
        "D": "Create a DynamoDB table in provisioned capacity mode, and configure it as a global table."
      }
    },
    "category": [
      "DynamoDB"
    ],
    "subcategory": [
      "mode",
      "scaling"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 52,
    "question": {
      "kor": "회사에는 매일 동시에 실행되는 AWS Glue 추출 변환 및 로드(ETL) 작업이 있습니다. 작업은 Amazon S3 버킷에 있는 XML 데이터를 처리합니다. S3 버킷에는 매일 새 데이터가 추가됩니다. 솔루션 설계자는 각 실행 중에 AWS Glue가 모든 데이터를 처리하고 있음을 확인합니다.\n솔루션 설계자는 AWS Glue가 오래된 데이터를 재처리하지 못하도록 어떻게 해야 합니까?",
      "eng": "A company has an AWS Glue extract, transform, and load (ETL) job that runs every day at the same time. The job processes XML data that is in an Amazon S3 bucket. New data is added to the S3 bucket every day. A solutions architect notices that AWS Glue is processing all the data during each run.\nWhat should the solutions architect do to prevent AWS Glue from reprocessing old data?"
    },
    "choices": {
      "kor": {
        "A": "작업 북마크를 사용하도록 작업을 편집합니다.",
        "B": "작업을 편집하여 데이터 처리 후 데이터를 삭제합니다.",
        "C": "NumberOfWorkers 필드를 1로 설정하여 작업을 편집합니다.",
        "D": "FindMatches 기계 학습(ML) 변환을 사용합니다."
      },
      "eng": {
        "A": "Edit the job to use job bookmarks.",
        "B": "Edit the job to delete data after the data is processed.",
        "C": "Edit the job by setting the NumberOfWorkers field to 1.",
        "D": "Use a FindMatches machine learning (ML) transform."
      }
    },
    "category": [
      "Glue"
    ],
    "subcategory": [
      "bookmakr"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85781-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 59,
    "question": {
      "kor": "회사가 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 AWS 리전의 Amazon S3 버킷에 데이터를 저장합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하여 S3 버킷에 저장된 모든 데이터를 암호화해야 합니다. 두 S3 버킷의 데이터는 동일한 KMS 키로 암호화 및 암호 해독되어야 합니다. 데이터와 키는 두 지역 각각에 저장되어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is building an application in the AWS Cloud. The application will store data in Amazon S3 buckets in two AWS Regions. The company must use an AWS Key Management Service (AWS KMS) customer managed key to encrypt all data that is stored in the S3 buckets. The data in both S3 buckets must be encrypted and decrypted with the same KMS key. The data and the key must be stored in each of the two Regions.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "각 리전에서 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.",
        "B": "고객 관리 다중 리전 KMS 키를 생성합니다. 각 리전에서 S3 버킷을 생성합니다. S3 버킷 간의 복제를 구성합니다. 클라이언트 측 암호화와 함께 KMS 키를 사용하도록 애플리케이션을 구성합니다.",
        "C": "각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.",
        "D": "각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다."
      },
      "eng": {
        "A": "Create an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
        "B": "Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption.",
        "C": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
        "D": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets."
      }
    },
    "category": [
      "Encryption"
    ],
    "subcategory": [
      "KMS",
      "multi-Region key",
      "S3",
      "CRR"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84747-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 61,
    "question": {
      "kor": "회사의 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 카탈로그의 가용성이 높고 카탈로그가 안정적인 위치에 저장되기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company's website uses an Amazon EC2 instance store for its catalog of items. The company wants to make sure that the catalog is highly available and that the catalog is stored in a durable location.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Redis용 Amazon ElastiCache로 카탈로그를 이동합니다.",
        "B": "더 큰 인스턴스 저장소가 있는 더 큰 EC2 인스턴스를 배포합니다.",
        "C": "인스턴스 스토어에서 Amazon S3 Glacier Deep Archive로 카탈로그를 이동합니다.",
        "D": "카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다."
      },
      "eng": {
        "A": "Move the catalog to Amazon ElastiCache for Redis.",
        "B": "Deploy a larger EC2 instance with a larger instance store.",
        "C": "Move the catalog from the instance store to Amazon S3 Glacier Deep Archive.",
        "D": "Move the catalog to an Amazon Elastic File System (Amazon EFS) file system."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 82,
    "question": {
      "kor": "회사에서 대량의 생산 데이터를 동일한 AWS 리전의 테스트 환경으로 복제하는 기능을 개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon EC2 인스턴스에 저장됩니다. 복제된 데이터에 대한 수정은 생산 환경에 영향을 미치지 않아야 합니다. 이 데이터에 액세스하는 소프트웨어에는 지속적으로 높은 I/O 성능이 필요합니다.\n솔루션 설계자는 프로덕션 데이터를 테스트 환경으로 복제하는 데 필요한 시간을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to improve its ability to clone large amounts of production data into a test environment in the same AWS Region. The data is stored in Amazon EC2 instances on Amazon Elastic Block Store (Amazon EBS) volumes. Modifications to the cloned data must not affect the production environment.\nThe software that accesses this data requires consistently high I/O performance.\nA solutions architect needs to minimize the time that is required to clone the production data into the test environment.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 테스트 환경의 EC2 인스턴스 스토어 볼륨에 스냅샷을 복원합니다.",
        "B": "EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS 볼륨의 EBS 스냅샷을 생성합니다. 프로덕션 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "C": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 새 EBS 볼륨을 생성하고 초기화합니다. 프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 새 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "D": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 기능을 켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경에서 새 EBS 볼륨을 EC2 인스턴스에 연결합니다."
      },
      "eng": {
        "A": "Take EBS snapshots of the production EBS volumes. Restore the snapshots onto EC2 instance store volumes in the test environment.",
        "B": "Configure the production EBS volumes to use the EBS Multi-Attach feature. Take EBS snapshots of the production EBS volumes. Attach the production EBS volumes to the EC2 instances in the test environment.",
        "C": "Take EBS snapshots of the production EBS volumes. Create and initialize new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment before restoring the volumes from the production EBS snapshots.",
        "D": "Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 93,
    "question": {
      "kor": "회사는 AWS에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 PostgreSQL용 Amazon S3 및 Amazon RDS의 데이터로 구성됩니다. 회사는 데이터 시각화를 제공하고 데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 회사의 관리 팀만 모든 시각화에 대한 전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스만 허용해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a data lake on AWS. The data lake consists of data in Amazon S3 and Amazon RDS for PostgreSQL. The company needs a reporting solution that provides data visualization and includes all the data sources within the data lake. Only the company's management team should have full access to all the visualizations. The rest of the company should have only limited access.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 대시보드를 공유합니다.",
        "B": "Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 대시보드를 공유합니다.",
        "C": "Amazon S3 AWS Glue의 데이터에 대한 테이블 및 크롤러를 생성합니다. AWS Glue 추출 변환 및 로드(ETL) 작업을 생성하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.",
        "D": "Amazon S3의 데이터에 대한 AWS Glue 테이블 및 크롤러를 생성합니다. Amazon Athena Federated Query를 사용하여 PostgreSQL용 Amazon RDS 내의 데이터에 액세스합니다. Amazon Athena를 사용하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다."
      },
      "eng": {
        "A": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate IAM roles.",
        "B": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups.",
        "C": "Create an AWS Glue table and crawler for the data in Amazon S3. Create an AWS Glue extract, transform, and load (ETL) job to produce reports. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports.",
        "D": "Create an AWS Glue table and crawler for the data in Amazon S3. Use Amazon Athena Federated Query to access data within Amazon RDS for PostgreSQL. Generate reports by using Amazon Athena. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84732-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 102,
    "question": {
      "kor": "한 회사에 AWS에서 호스팅되는 웹사이트가 있습니다. 웹사이트는 HTTP와 HTTPS를 별도로 처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 HTTPS를 사용하도록 모든 요청을 웹 사이트로 전달하려고 합니다.\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company has a website hosted on AWS. The website is behind an Application Load Balancer (ALB) that is configured to handle HTTP and HTTPS separately. The company wants to forward all requests to the website so that the requests will use HTTPS.\nWhat should a solutions architect do to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "HTTPS 트래픽만 허용하도록 ALB의 네트워크 ACL을 업데이트합니다.",
        "B": "URL의 HTTP를 HTTPS로 바꾸는 규칙을 만듭니다.",
        "C": "ALB에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS로 리디렉션합니다.",
        "D": "ALB를 SNI(Server Name Indication)를 사용하도록 구성된 Network Load Balancer로 교체합니다."
      },
      "eng": {
        "A": "Update the ALB's network ACL to accept only HTTPS traffic.",
        "B": "Create a rule that replaces the HTTP in the URL with HTTPS.",
        "C": "Create a listener rule on the ALB to redirect HTTP traffic to HTTPS.",
        "D": "Replace the ALB with a Network Load Balancer configured to use Server Name Indication (SNI)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85121-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 105,
    "question": {
      "kor": "회사는 사용자 트랜잭션 데이터를 Amazon DynamoDB 테이블에 보관해야 합니다. 회사는 데이터를 7년간 보관해야 합니다.\n이러한 요구 사항을 충족하는 운영상 가장 효율적인 솔루션은 무엇입니까?",
      "eng": "A company needs to keep user transaction data in an Amazon DynamoDB table. The company must retain the data for 7 years.\nWhat is the MOST operationally efficient solution that meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB point-in-time recovery를 사용하여 테이블을 지속적으로 백업하십시오.",
        "B": "AWS Backup을 사용하여 테이블에 대한 백업 일정 및 보존 정책을 생성합니다.",
        "C": "DynamoDB 콘솔을 사용하여 테이블의 온디맨드 백업을 생성합니다. Amazon S3 버킷에 백업을 저장합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다.",
        "D": "AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. 테이블을 백업하고 백업을 Amazon S3 버킷에 저장하도록 Lambda 함수를 구성합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다."
      },
      "eng": {
        "A": "Use DynamoDB point-in-time recovery to back up the table continuously.",
        "B": "Use AWS Backup to create backup schedules and retention policies for the table.",
        "C": "Create an on-demand backup of the table by using the DynamoDB console. Store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket.",
        "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to invoke an AWS Lambda function. Configure the Lambda function to back up the table and to store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85742-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 107,
    "question": {
      "kor": "한 회사가 최근 메시지 처리 시스템을 AWS로 마이그레이션했습니다. 시스템은 Amazon EC2 인스턴스에서 실행되는 ActiveMQ 대기열로 메시지를 수신합니다. 메시지는 Amazon EC2에서 실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 메시지를 처리하고 결과를 Amazon EC2에서 실행되는 MySQL 데이터베이스에 기록합니다. 회사는\n이 애플리케이션이 운영 복잡성이 낮으면서 가용성이 높기를 원합니다.\n가장 높은 가용성을 제공하는 아키텍처는 무엇입니까?",
      "eng": "A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity.\nWhich architecture offers the HIGHEST availability?"
    },
    "choices": {
      "kor": {
        "A": "다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.",
        "B": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.",
        "C": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다.",
        "D": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 두 가용 영역에서 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다."
      },
      "eng": {
        "A": "Add a second ActiveMQ server to another Availability Zone. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
        "B": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
        "C": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled.",
        "D": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 113,
    "question": {
      "kor": "회사는 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 둘 다 Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 한 하위 집합 또는 다른 하위 집합을 볼 수 있지만 동시에 모든 문서를 볼 수는 없다고 보고했습니다.\n사용자가 모든 문서를 한 번에 볼 수 있도록 하기 위해 솔루션 설계자는 무엇을 제안해야 합니까?",
      "eng": "A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.\nWhat should a solutions architect propose to ensure users see all of their documents at once?"
    },
    "choices": {
      "kor": {
        "A": "두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다.",
        "B": "문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 구성",
        "C": "두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 새 문서를 Amazon EFS에 저장하도록 애플리케이션 수정",
        "D": "두 서버 모두에 요청을 보내도록 Application Load Balancer를 구성합니다. 올바른 서버에서 각 문서 반환"
      },
      "eng": {
        "A": "Copy the data so both EBS volumes contain all the documents",
        "B": "Configure the Application Load Balancer to direct a user to the server with the documents",
        "C": "Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS",
        "D": "Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server"
      }
    },
    "category": [
      "EFS"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 116,
    "question": {
      "kor": "한 회사에서 us-west-2 리전의 NLB(Network Load Balancer) 뒤에 있는 3개의 Amazon EC2 인스턴스에 자체 관리형 DNS 솔루션을 구현했습니다. 회사 사용자의 대부분은 미국과 유럽에 있습니다. 회사는 솔루션의 성능과 가용성을 개선하고자 합니다. 회사는 eu-west-1 지역에서 3개의 EC2 인스턴스를 시작 및 구성하고 EC2 인스턴스를 새 NLB의 대상으로 추가합니다.\n회사에서 트래픽을 모든 EC2 인스턴스로 라우팅하는 데 사용할 수 있는 솔루션은 무엇입니까?",
      "eng": "A company has implemented a self-managed DNS solution on three Amazon EC2 instances behind a Network Load Balancer (NLB) in the us-west-2 Region.\nMost of the company's users are located in the United States and Europe. The company wants to improve the performance and availability of the solution.\nThe company launches and configures three EC2 instances in the eu-west-1 Region and adds the EC2 instances as targets for a new NLB.\nWhich solution can the company use to route traffic to all the EC2 instances?"
    },
    "choices": {
      "kor": {
        "A": "두 NLB 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다.",
        "B": "AWS Global Accelerator에서 표준 가속기를 생성합니다. us-west-2 및 eu-west-1에서 엔드포인트 그룹을 생성합니다. 끝점 그룹의 끝점으로 두 개의 NLB를 추가합니다.",
        "C": "탄력적 IP 주소를 6개의 EC2 인스턴스에 연결합니다. 6개의 EC2 인스턴스 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다.",
        "D": "두 개의 NLB를 두 개의 ALB(Application Load Balancer)로 교체합니다. 요청을 두 ALB 중 하나로 라우팅하는 Amazon Route 53 지연 시간 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다."
      },
      "eng": {
        "A": "Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.",
        "B": "Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.",
        "C": "Attach Elastic IP addresses to the six EC2 instances. Create an Amazon Route 53 geolocation routing policy to route requests to one of the six EC2 instances. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution's origin.",
        "D": "Replace the two NLBs with two Application Load Balancers (ALBs). Create an Amazon Route 53 latency routing policy to route requests to one of the two ALBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 119,
    "question": {
      "kor": "회사는 AWS Organizations를 사용하여 각 사업부에 대한 전용 AWS 계정을 생성하여 요청 시 각 사업부의 계정을 독립적으로 관리합니다. 루트 이메일 수신자는 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림을 놓치지 않기를 원합니다. 향후 알림은 계정 관리자로 제한되어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses AWS Organizations to create dedicated AWS accounts for each business unit to manage each business unit's account independently upon request. The root email recipient missed a notification that was sent to the root user email address of one account. The company wants to ensure that all future notifications are not missed. Future notifications must be limited to account administrators.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS 계정 루트 사용자 이메일 주소로 전송되는 알림 이메일 메시지를 조직의 모든 사용자에게 전달하도록 회사의 이메일 서버를 구성합니다.",
        "B": "모든 AWS 계정 루트 사용자 이메일 주소를 알림에 응답할 수 있는 소수의 관리자에게 전달되는 배포 목록으로 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다.",
        "C": "모든 AWS 계정 루트 사용자 이메일 메시지가 경고를 모니터링하고 해당 그룹에 해당 경고를 전달하는 역할을 담당하는 한 명의 관리자에게 전송되도록 구성합니다.",
        "D": "동일한 루트 사용자 이메일 주소를 사용하도록 모든 기존 AWS 계정과 새로 생성된 모든 계정을 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다."
      },
      "eng": {
        "A": "Configure the company’s email server to forward notification email messages that are sent to the AWS account root user email address to all users in the organization.",
        "B": "Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.",
        "C": "Configure all AWS account root user email messages to be sent to one administrator who is responsible for monitoring alerts and forwarding those alerts to the appropriate groups.",
        "D": "Configure all existing AWS accounts and all newly created accounts to use the same root user email address. Configure AWS account alternate contacts in the AWS Organizations console or programmatically."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85997-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 121,
    "question": {
      "kor": "회사에서 CompanyConfidential Amazon S3 버킷에 대한 액세스 권한이 없어야 하는 새로운 클라우드 엔지니어를 채용했습니다. 클라우드 엔지니어는 AdminTools라는 S3 버킷에 대한 읽기 및 쓰기 권한이 있어야 합니다.\n이러한 기준을 충족하는 IAM 정책은 무엇입니까?",
      "eng": "A corporation has recruited a new cloud engineer who should not have access to the CompanyConfidential Amazon S3 bucket. The cloud engineer must have read and write permissions on an S3 bucket named AdminTools.\nWhich IAM policy will satisfy these criteria?"
    },
    "choices": {
      "kor": {
        "A": "",
        "B": "",
        "C": "",
        "D": ""
      },
      "eng": {
        "A": "",
        "B": "",
        "C": "",
        "D": ""
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/46383-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 129,
    "question": {
      "kor": "게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 실행되며 UDP 기반 트래픽만 지원합니다. 회사는 최상의 사용자 경험을 제공하기 위해 프런트엔드 계층이 필요합니다. 해당 계층은 대기 시간이 짧아야 하고 트래픽을 가장 가까운 엣지 로케이션으로 라우팅하고 애플리케이션 엔드포인트에 진입하기 위한 정적 IP 주소를 제공해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A gaming company is designing a highly available architecture. The application runs on a modified Linux kernel and supports only UDP-based traffic. The company needs the front-end tier to provide the best possible user experience. That tier must have low latency, route traffic to the nearest edge location, and provide static IP addresses for entry into the application endpoints.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "요청을 Application Load Balancer로 전달하도록 Amazon Route 53을 구성합니다. AWS Application Auto Scaling에서 애플리케이션에 AWS Lambda를 사용합니다.",
        "B": "요청을 Network Load Balancer로 전달하도록 Amazon CloudFront를 구성합니다. AWS Application Auto Scaling 그룹의 애플리케이션에 AWS Lambda를 사용합니다.",
        "C": "요청을 Network Load Balancer로 전달하도록 AWS Global Accelerator를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다.",
        "D": "요청을 Application Load Balancer로 전달하도록 Amazon API Gateway를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다."
      },
      "eng": {
        "A": "Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.",
        "B": "Configure Amazon CloudFront to forward requests to a Network Load Balancer. Use AWS Lambda for the application in an AWS Application Auto Scaling group.",
        "C": "Configure AWS Global Accelerator to forward requests to a Network Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.",
        "D": "Configure Amazon API Gateway to forward requests to an Application Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator",
      "availability",
      "protocol",
      "static IP addresses"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86667-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 149,
    "question": {
      "kor": "솔루션 설계자는 정적 웹 사이트를 저장하기 위해 Amazon S3 오리진과 함께 Amazon CloudFront를 사용하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹 사이트 트래픽은 AWS WAF에서 검사해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 어떻게 준수해야 합니까?",
      "eng": "A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company’s security policy requires that all website traffic be inspected by AWS WAF.\nHow should the solutions architect comply with these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS WAF Amazon 리소스 이름(ARN)에서만 오는 요청을 수락하도록 S3 버킷 정책을 구성합니다.",
        "B": "S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF로 전달하도록 Amazon CloudFront를 구성합니다.",
        "C": "Amazon CloudFront IP 주소가 Amazon S3에만 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에 연결합니다.",
        "D": "원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 Amazon S3를 구성합니다. 배포에서 AWS WAF를 활성화합니다."
      },
      "eng": {
        "A": "Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.",
        "B": "Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.",
        "C": "Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.",
        "D": "Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution."
      }
    },
    "category": [
      "Access Control"
    ],
    "subcategory": [
      "WAF",
      "CloudFront",
      "S3",
      "OAI"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 154,
    "question": {
      "kor": "한 회사에서 Amazon S3 버킷을 스토리지로 사용할 파일 공유 애플리케이션을 개발하고 있습니다. 회사는 Amazon CloudFront 배포를 통해 모든 파일을 제공하려고 합니다. 회사는 S3 URL에 대한 직접 탐색을 통해 파일에 액세스할 수 있기를 원하지 않습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is developing a file-sharing application that will use an Amazon S3 bucket for storage. The company wants to serve all the files through an Amazon CloudFront distribution. The company does not want the files to be accessible through direct navigation to the S3 URL.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "각 S3 버킷에 대한 개별 정책을 작성하여 CloudFront 액세스에 대해서만 읽기 권한을 부여하십시오.",
        "B": "IAM 사용자를 생성합니다. 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. 사용자를 CloudFront에 할당합니다.",
        "C": "CloudFront 배포 ID를 Principal로 할당하고 대상 S3 버킷을 Amazon 리소스 이름(ARN)으로 할당하는 S3 버킷 정책을 작성합니다.",
        "D": "원본 액세스 ID(OAI)를 만듭니다. CloudFront 배포에 OAI를 할당합니다. OAI만 읽기 권한을 갖도록 S3 버킷 권한을 구성합니다."
      },
      "eng": {
        "A": "Write individual policies for each S3 bucket to grant read permission for only CloudFront access.",
        "B": "Create an IAM user. Grant the user read permission to objects in the S3 bucket. Assign the user to CloudFront.",
        "C": "Write an S3 bucket policy that assigns the CloudFront distribution ID as the Principal and assigns the target S3 bucket as the Amazon Resource Name (ARN).",
        "D": "Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission."
      }
    },
    "category": [
      "Access Control"
    ],
    "subcategory": [
      "CloudFront",
      "OAI"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85992-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 155,
    "question": {
      "kor": "회사는 온프레미스에서 Oracle 데이터베이스를 실행합니다. 회사는 AWS로 마이그레이션하는 과정에서 데이터베이스를 사용 가능한 최신 버전으로 업그레이드하려고 합니다. 또한 회사는 데이터베이스에 재해 복구(DR)를 설정하려고 합니다. 회사는 정상 운영 및 DR 설정을 위한 운영 오버헤드를 최소화해야 합니다. 회사는 또한 데이터베이스의 기본 운영 체제에 대한 액세스를 유지 관리해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 다른 AWS 리전으로 데이터베이스 복제를 설정합니다.",
        "B": "Oracle 데이터베이스를 Oracle용 Amazon RDS로 마이그레이션합니다. 리전 간 자동 백업을 활성화하여 스냅샷을 다른 AWS 리전에 복제합니다.",
        "C": "Oracle 데이터베이스를 Amazon RDS Custom for Oracle로 마이그레이션합니다. 다른 AWS 리전에서 데이터베이스에 대한 읽기 전용 복제본을 생성합니다.",
        "D": "Oracle 데이터베이스를 Oracle용 Amazon RDS로 마이그레이션합니다. 다른 가용 영역에서 대기 데이터베이스를 생성합니다."
      },
      "eng": {
        "A": "Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region.",
        "B": "Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region.",
        "C": "Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.",
        "D": "Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone."
      }
    },
    "category": [
      "RDS"
    ],
    "subcategory": [
      "RDS Custom for Oracle",
      "disater recovery"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85423-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 162,
    "question": {
      "kor": "회사는 서로 다른 데이터베이스에서 오는 배치 데이터를 생성합니다. 이 회사는 또한 네트워크 센서 및 애플리케이션 API에서 라이브 스트림 데이터를 생성합니다. 회사는 비즈니스 분석을 위해 모든 데이터를 한 곳으로 통합해야 합니다. 회사는 수신 데이터를 처리한 다음 다른 Amazon S3 버킷에 데이터를 준비해야 합니다. 팀은 나중에 일회성 쿼리를 실행하고 데이터를 비즈니스 인텔리전스 도구로 가져와 핵심 성과 지표(KPI)를 표시합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company produces batch data that comes from different databases. The company also produces live stream data from network sensors and application APIs. The company needs to consolidate all the data into one place for business analytics. The company needs to process the incoming data and then stage the data in different Amazon S3 buckets. Teams will later run one-time queries and import the data into a business intelligence tool to show key performance indicators (KPIs).\nWhich combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "일회성 쿼리에는 Amazon Athena를 사용하십시오. Amazon QuickSight를 사용하여 KPI용 대시보드를 생성합니다.",
        "B": "일회성 쿼리에 Amazon Kinesis Data Analytics를 사용합니다. Amazon QuickSight를 사용하여 KPI용 대시보드를 생성합니다.",
        "C": "데이터베이스에서 Amazon Redshift 클러스터로 개별 레코드를 이동하는 사용자 지정 AWS Lambda 함수를 생성합니다.",
        "D": "AWS Glue 추출, 변환 및 로드(ETL) 작업을 사용하여 데이터를 JSON 형식으로 변환합니다. 여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 데이터를 로드합니다.",
        "E": "AWS Lake Formation의 청사진을 사용하여 데이터 레이크로 수집할 수 있는 데이터를 식별합니다. AWS Glue를 사용하여 소스를 크롤링하고, 데이터를 추출하고, 데이터를 Apache Parquet 형식으로 Amazon S3에 로드합니다."
      },
      "eng": {
        "A": "Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.",
        "B": "Use Amazon Kinesis Data Analytics for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.",
        "C": "Create custom AWS Lambda functions to move the individual records from the databases to an Amazon Redshift cluster.",
        "D": "Use an AWS Glue extract, transform, and load (ETL) job to convert the data into JSON format. Load the data into multiple Amazon OpenSearch Service (Amazon Elasticsearch Service) clusters.",
        "E": "Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85770-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 167,
    "question": {
      "kor": "회사에서 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 온프레미스 데이터베이스는 마이그레이션 중에 온라인 상태를 유지하고 액세스할 수 있어야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화된 상태를 유지해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company is migrating its on-premises PostgreSQL database to Amazon Aurora PostgreSQL. The on-premises database must remain online and accessible during the migration. The Aurora database must remain synchronized with the on-premises database.\nWhich combination of actions must a solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "지속적인 복제 작업을 만듭니다.",
        "B": "온프레미스 데이터베이스의 데이터베이스 백업을 생성합니다.",
        "C": "AWS Database Migration Service(AWS DMS) 복제 서버를 생성합니다.",
        "D": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 데이터베이스 스키마를 변환합니다.",
        "E": "Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 데이터베이스 동기화를 모니터링합니다."
      },
      "eng": {
        "A": "Create an ongoing replication task.",
        "B": "Create a database backup of the on-premises database.",
        "C": "Create an AWS Database Migration Service (AWS DMS) replication server.",
        "D": "Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT).",
        "E": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85438-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 174,
    "question": {
      "kor": "회사는 회사 웹 사이트에 널리 사용되는 콘텐츠 관리 시스템(CMS)을 사용합니다. 그러나 필요한 패칭과 유지보수가 부담스럽다. 회사는 웹사이트를 재설계하고 있으며 새로운 솔루션을 원합니다. 웹사이트는 1년에 4번 업데이트되며 동적 콘텐츠를 사용할 필요가 없습니다. 솔루션은 높은 확장성과 향상된 보안을 제공해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 변경 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company uses a popular content management system (CMS) for its corporate website. However, the required patching and maintenance are burdensome.\nThe company is redesigning its website and wants anew solution. The website will be updated four times a year and does not need to have any dynamic content available. The solution must provide high scalability and enhanced security.\nWhich combination of changes will meet these requirements with the LEAST operational overhead? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "HTTPS 기능을 사용하도록 웹 사이트 앞에 Amazon CloudFront를 구성합니다.",
        "B": "웹 사이트 앞에 AWS WAF 웹 ACL을 배포하여 HTTPS 기능을 제공합니다.",
        "C": "웹 사이트 콘텐츠를 관리하고 제공하기 위해 AWS Lambda 함수를 생성하고 배포합니다.",
        "D": "새 웹사이트와 Amazon S3 버킷을 생성합니다. 정적 웹 사이트 호스팅이 활성화된 S3 버킷에 웹 사이트를 배포합니다.",
        "E": "새 웹사이트를 만듭니다. Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스의 Auto Scaling 그룹을 사용하여 웹 사이트를 배포합니다."
      },
      "eng": {
        "A": "Configure Amazon CloudFront in front of the website to use HTTPS functionality.",
        "B": "Deploy an AWS WAF web ACL in front of the website to provide HTTPS functionality.",
        "C": "Create and deploy an AWS Lambda function to manage and serve the website content.",
        "D": "Create the new website and an Amazon S3 bucket. Deploy the website on the S3 bucket with static website hosting enabled.",
        "E": "Create the new website. Deploy the website by using an Auto Scaling group of Amazon EC2 instances behind an Application Load Balancer."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 175,
    "question": {
      "kor": "회사는 AWS에서 전자상거래 애플리케이션을 실행합니다. 모든 새 주문은 단일 가용 영역의 Amazon EC2 인스턴스에서 실행되는 RabbitMQ 대기열에 메시지로 게시됩니다. 이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에 의해 처리됩니다. 이 애플리케이션은 다른 EC2 인스턴스의 PostgreSQL 데이터베이스에 세부 정보를 저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다.\n회사는 최소한의 운영 오버헤드로 최고의 가용성을 제공하도록 아키텍처를 재설계해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company runs its ecommerce application on AWS. Every new order is published as a massage in a RabbitMQ queue that runs on an Amazon EC2 instance in a single Availability Zone. These messages are processed by a different application that runs on a separate EC2 instance. This application stores the details in a PostgreSQL database on another EC2 instance. All the EC2 instances are in the same Availability Zone.\nThe company needs to redesign its architecture to provide the highest availability with the least operational overhead.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "대기열을 Amazon MQ에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대한 또 다른 다중 AZ Auto Scaling 그룹을 생성합니다.",
        "B": "대기열을 Amazon MQ에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL용 Amazon RDS의 다중 AZ 배포에서 실행할 데이터베이스를 마이그레이션합니다.",
        "C": "RabbitMQ 대기열을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 또 다른 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL용 Amazon RDS의 다중 AZ 배포에서 실행할 데이터베이스를 마이그레이션합니다.",
        "D": "RabbitMQ 대기열을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 또 다른 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대한 세 번째 다중 AZ Auto Scaling 그룹을 생성합니다."
      },
      "eng": {
        "A": "Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Create another Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database.",
        "B": "Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.",
        "C": "Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.",
        "D": "Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Create a third Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85999-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 180,
    "question": {
      "kor": "한 회사에서 AWS에서 호스팅되는 서비스 솔루션으로서 고성능 컴퓨팅(HPC) 워크로드를 구축할 계획입니다. 16개의 Amazon EC2 Linux 인스턴스 그룹은 노드 간 통신을 위해 가능한 가장 낮은 지연 시간이 필요합니다. 인스턴스에는 고성능 스토리지를 위한 공유 블록 장치 볼륨도 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is planning to build a high performance computing (HPC) workload as a service solution that is hosted on AWS. A group of 16 Amazon EC2 Linux instances requires the lowest possible latency for node-to-node communication. The instances also need a shared block device volume for highperforming storage.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "클러스터 배치 그룹을 사용하십시오. Amazon EBS 다중 연결을 사용하여 단일 프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 연결합니다.",
        "B": "클러스터 배치 그룹을 사용하십시오. Amazon Elastic File System(Amazon EFS)을 사용하여 인스턴스 간에 공유 파일 시스템을 생성합니다.",
        "C": "파티션 배치 그룹을 사용하십시오. Amazon Elastic File System(Amazon EFS)을 사용하여 인스턴스 간에 공유 파일 시스템을 생성합니다.",
        "D": "스프레드 배치 그룹을 사용하십시오. Amazon EBS 다중 연결을 사용하여 단일 프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 연결합니다."
      },
      "eng": {
        "A": "Use a cluster placement group. Attach a single Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume to all the instances by using Amazon EBS Multi-Attach.",
        "B": "Use a cluster placement group. Create shared file systems across the instances by using Amazon Elastic File System (Amazon EFS).",
        "C": "Use a partition placement group. Create shared file systems across the instances by using Amazon Elastic File System (Amazon EFS).",
        "D": "Use a spread placement group. Attach a single Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume to all the instances by using Amazon EBS Multi-Attach."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/83867-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 186,
    "question": {
      "kor": "회사의 애플리케이션에 성능 문제가 있습니다. 애플리케이션은 상태 저장이며 Amazon EC2 인스턴스에서 인 메모리 작업을 완료해야 합니다. 이 회사는 AWS CloudFormation을 사용하여 인프라를 배포하고 M5 EC2 인스턴스 제품군을 사용했습니다. 트래픽이 증가함에 따라 애플리케이션 성능이 저하되었습니다. 사용자는 사용자가 애플리케이션에 액세스하려고 할 때 지연을 보고합니다.\n운영상 가장 효율적인 방식으로 이러한 문제를 해결하는 솔루션은 무엇입니까?",
      "eng": "A company’s application is having performance issues. The application is stateful and needs to complete in-memory tasks on Amazon EC2 instances. The company used AWS CloudFormation to deploy infrastructure and used the M5 EC2 instance family. As traffic increased, the application performance degraded. Users are reporting delays when the users attempt to access the application.\nWhich solution will resolve these issues in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "Auto Scaling 그룹에서 실행되는 T3 EC2 인스턴스로 EC2 인스턴스를 교체합니다. AWS Management Console을 사용하여 변경합니다.",
        "B": "Auto Scaling 그룹에서 EC2 인스턴스를 실행하도록 CloudFormation 템플릿을 수정합니다. 증가가 필요한 경우 Auto Scaling 그룹의 원하는 용량과 최대 용량을 수동으로 늘립니다.",
        "C": "CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. Amazon CloudWatch 내장 EC2 메모리 메트릭을 사용하여 향후 용량 계획을 위해 애플리케이션 성능을 추적합니다.",
        "D": "CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. EC2 인스턴스에 Amazon CloudWatch 에이전트를 배포하여 향후 용량 계획을 위한 사용자 지정 애플리케이션 지연 시간 메트릭을 생성합니다."
      },
      "eng": {
        "A": "Replace the EC2 instances with T3 EC2 instances that run in an Auto Scaling group. Make the changes by using the AWS Management Console.",
        "B": "Modify the CloudFormation templates to run the EC2 instances in an Auto Scaling group. Increase the desired capacity and the maximum capacity of the Auto Scaling group manually when an increase is necessary.",
        "C": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use Amazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning.",
        "D": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95162-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 201,
    "question": {
      "kor": "회사에서 최근 마케팅 캠페인의 효과를 측정하려고 합니다. 회사는 판매 데이터의 .csv 파일에 대해 일괄 처리를 수행하고 그 결과를 매시간 Amazon S3 버킷에 저장합니다. S3 버킷에는 페타바이트 규모의 객체가 포함되어 있습니다. 이 회사는 Amazon Athena에서 일회성 쿼리를 실행하여 특정 지역에서 특정 날짜에 가장 인기 있는 제품을 확인합니다. 쿼리가 실행을 완료하는데 예상보다 오래 걸리거나 실패하는 경우가 있습니다.\n솔루션 설계자는 쿼리 성능과 안정성을 개선하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company wants to measure the effectiveness of its recent marketing campaigns. The company performs batch processing on .csv files of sales data and stores the results in an Amazon S3 bucket once every hour. The S3 bucket contains petabytes of objects. The company runs one-time queries in Amazon Athena to determine which products are most popular on a particular date for a particular region. Queries sometimes fail or take longer than expected to finish running.\nWhich actions should a solutions architect take to improve the query performance and reliability? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "S3 객체 크기를 128MB 미만으로 줄입니다.",
        "B": "Amazon S3에서 데이터를 날짜 및 지역별로 분할합니다.",
        "C": "파일을 Amazon S3에 큰 단일 객체로 저장합니다.",
        "D": "Amazon Kinesis Data Analytics를 사용하여 일괄 처리 작업의 일부로 쿼리를 실행합니다.",
        "E": "AWS Glue 추출, 변환 및 로드(ETL) 프로세스를 사용하여 .csv 파일을 Apache Parquet 형식으로 변환합니다."
      },
      "eng": {
        "A": "Reduce the S3 object sizes to less than 128 MB.",
        "B": "Partition the data by date and region in Amazon S3.",
        "C": "Store the files as large, single objects in Amazon S3.",
        "D": "Use Amazon Kinesis Data Analytics to run the queries as part of the batch processing operation.",
        "E": "Use an AWS Glue extract, transform, and load (ETL) process to convert the .csv files into Apache Parquet format."
      }
    },
    "category": [
      "Data analysis"
    ],
    "subcategory": [
      "S3",
      "partioning",
      "Glue"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86458-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 202,
    "question": {
      "kor": "회사에는 AWS Lake Formation에서 관리하는 Amazon S3 데이터 레이크가 있습니다. 이 회사는 데이터 레이크의 데이터를 Amazon Aurora MySQL 데이터베이스에 저장된 운영 데이터와 결합하여 Amazon QuickSight에서 시각화를 생성하려고 합니다. 회사는 회사의 마케팅 팀이 데이터베이스의 열 하위 집합에만 액세스할 수 있도록 열 수준 권한을 적용하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an Amazon S3 data lake that is governed by AWS Lake Formation. The company wants to create a visualization in Amazon QuickSight by joining the data in the data lake with operational data that is stored in an Amazon Aurora MySQL database. The company wants to enforce column-level authorization so that the company’s marketing team can access only a subset of columns in the database.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EMR을 사용하여 데이터베이스에서 QuickSight SPICE 엔진으로 직접 데이터를 수집하십시오. 필요한 열만 포함합니다.",
        "B": "AWS Glue Studio를 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 수집합니다. IAM 정책을 QuickSight 사용자에게 연결하여 열 수준 액세스 제어를 적용합니다. QuickSight에서 Amazon S3를 데이터 원본으로 사용합니다.",
        "C": "AWS Glue Elastic Views를 사용하여 Amazon S3의 데이터베이스에 대한 구체화된 보기를 생성합니다. QuickSight 사용자에 대한 열 수준 액세스 제어를 적용하려면 S3 버킷 정책을 생성합니다. QuickSight에서 Amazon S3를 데이터 원본으로 사용합니다.",
        "D": "Lake Formation 청사진을 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 수집합니다. Lake Formation을 사용하여 QuickSight 사용자에 대한 열 수준 액세스 제어를 적용합니다. QuickSight에서 Amazon Athena를 데이터 원본으로 사용합니다."
      },
      "eng": {
        "A": "Use Amazon EMR to ingest the data directly from the database to the QuickSight SPICE engine. Include only the required columns.",
        "B": "Use AWS Glue Studio to ingest the data from the database to the S3 data lake. Attach an IAM policy to the QuickSight users to enforce column-level access control. Use Amazon S3 as the data source in QuickSight.",
        "C": "Use AWS Glue Elastic Views to create a materialized view for the database in Amazon S3. Create an S3 bucket policy to enforce column-level access control for the QuickSight users. Use Amazon S3 as the data source in QuickSight.",
        "D": "Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99710-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 207,
    "question": {
      "kor": "예산 계획의 일환으로 경영진은 사용자별로 나열된 AWS 청구 항목에 대한 보고서를 원합니다. 데이터는 부서 예산을 만드는 데 사용됩니다. 솔루션 설계자는 이 보고서 정보를 얻는 가장 효율적인 방법을 결정해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Athena로 쿼리를 실행하여 보고서를 생성합니다.",
        "B": "Cost Explorer에서 보고서를 생성하고 보고서를 다운로드합니다.",
        "C": "청구 대시보드에서 청구서 세부 정보에 액세스하고 청구서를 다운로드합니다.",
        "D": "Amazon Simple Email Service(Amazon SES)로 알리도록 AWS 예산에서 비용 예산을 수정합니다."
      },
      "eng": {
        "A": "Run a query with Amazon Athena to generate the report.",
        "B": "Create a report in Cost Explorer and download the report.",
        "C": "Access the bill details from the billing dashboard and download the bill.",
        "D": "Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99513-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 210,
    "question": {
      "kor": "회사에 Amazon DynamoDB 테이블이 지원하는 애플리케이션이 있습니다. 회사의 규정 준수 요구 사항은 데이터베이스 백업을 매월 수행하고 6개월 동안 사용할 수 있어야 하며 7년 동안 유지해야 한다고 지정합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an application that is backed by an Amazon DynamoDB table. The company’s compliance requirements specify that database backups must be taken every month, must be available for 6 months, and must be retained for 7 years.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "매월 1일에 DynamoDB 테이블을 백업하는 AWS Backup 계획을 생성합니다. 6개월 후 백업을 콜드 스토리지로 전환하는 수명 주기 정책을 지정합니다. 각 백업의 보존 기간을 7년으로 설정합니다.",
        "B": "매월 1일에 DynamoDB 테이블의 DynamoDB 온디맨드 백업을 생성합니다. 6개월 후 백업을 Amazon S3 Glacier Flexible Retrieval로 전환합니다. 7년보다 오래된 백업을 삭제하려면 S3 수명 주기 정책을 생성하십시오.",
        "C": "AWS SDK를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성하는 스크립트를 개발합니다. 매월 1일에 스크립트를 실행하는 Amazon EventBridge 규칙을 설정합니다. 6개월 이상 된 DynamoDB 백업을 콜드 스토리지로 전환하고 7년 이상 된 백업을 삭제하기 위해 매월 2일에 실행할 두 번째 스크립트를 생성합니다.",
        "D": "AWS CLI를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성합니다. Cron 표현식을 사용하여 매월 1일에 명령을 실행하는 Amazon EventBridge 규칙을 설정합니다. 6개월 후 백업을 콜드 스토리지로 전환하고 7년 후 백업을 삭제하도록 명령에 지정합니다."
      },
      "eng": {
        "A": "Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years.",
        "B": "Create a DynamoDB on-demand backup of the DynamoDB table on the first day of each month. Transition the backup to Amazon S3 Glacier Flexible Retrieval after 6 months. Create an S3 Lifecycle policy to delete backups that are older than 7 years.",
        "C": "Use the AWS SDK to develop a script that creates an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the script on the first day of each month. Create a second script that will run on the second day of each month to transition DynamoDB backups that are older than 6 months to cold storage and to delete backups that are older than 7 years.",
        "D": "Use the AWS CLI to create an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the command on the first day of each month with a cron expression. Specify in the command to transition the backups to cold storage after 6 months and to delete the backups after 7 years."
      }
    },
    "category": [
      "Backup"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99793-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 218,
    "question": {
      "kor": "한 회사는 최근 인스턴스에 대해 운영 체제 버전 패치 및 설치된 소프트웨어에 대한 정보를 중앙 집중화하기 위해 새로운 Amazon EC2 , 감사 시스템을 배포했습니다. 솔루션 설계자는 EC2\nAuto Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 시작 및 종료되는 즉시 성공적으로 감사 시스템에 보고서를 보내도록 해야 합니다.\n이러한 목표를 가장 효율적으로 달성하는 솔루션은 무엇입니까?",
      "eng": "A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated.\nWhich solution achieves these goals MOST efficiently?"
    },
    "choices": {
      "kor": {
        "A": "예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 데이터를 감사 시스템으로 보냅니다.",
        "B": "EC2 Auto Scaling 수명 주기 후크를 사용하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보내는 사용자 지정 스크립트를 실행합니다.",
        "C": "EC2 Auto Scaling 시작 구성을 사용하여 사용자 데이터를 통해 사용자 지정 스크립트를 실행하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보냅니다.",
        "D": "인스턴스 운영 체제에서 사용자 지정 스크립트를 실행하여 데이터를 감사 시스템으로 보냅니다. 인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹에서 호출할 스크립트를 구성합니다."
      },
      "eng": {
        "A": "Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.",
        "B": "Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.",
        "C": "Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.",
        "D": "Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102142-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 222,
    "question": {
      "kor": "회사는 3계층 상태 비저장 웹 애플리케이션을 위한 백업 전략이 필요합니다. 웹 애플리케이션은 조정 이벤트에 응답하도록 구성된 동적 조정 정책이 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 데이터베이스 계층은 PostgreSQL용 Amazon RDS에서 실행됩니다. 웹 애플리케이션은 EC2 인스턴스에 임시 로컬 스토리지가 필요하지 않습니다. 회사의 복구 지점 목표(RPO)는 2시간입니다.\n백업 전략은 확장성을 최대화하고 이 환경에 대한 리소스 활용을 최적화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours.\nThe backup strategy must maximize scalability and optimize resource utilization for this environment.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "RPO를 충족하기 위해 2시간마다 EC2 인스턴스 및 데이터베이스의 Amazon Elastic Block Store(Amazon EBS) 볼륨의 스냅샷을 생성합니다.",
        "B": "Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성하도록 스냅샷 수명 주기 정책을 구성합니다. RPO를 충족하기 위해 Amazon RDS에서 자동 백업을 활성화합니다.",
        "C": "웹 및 애플리케이션 계층의 최신 Amazon 머신 이미지(AMI)를 유지합니다. Amazon RDS에서 자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO를 충족합니다.",
        "D": "2시간마다 EC2 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 볼륨의 스냅샷을 생성합니다. Amazon RDS에서 자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO를 충족합니다."
      },
      "eng": {
        "A": "Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.",
        "B": "Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.",
        "C": "Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.",
        "D": "Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 223,
    "question": {
      "kor": "회사는 AWS에서 애플리케이션을 호스팅합니다. 이 회사는 Amazon Cognito를 사용하여 사용자를 관리합니다. 사용자가 애플리케이션에 로그인하면 애플리케이션은 Amazon API Gateway에서 호스팅되는 REST API를 사용하여 Amazon DynamoDB에서 필요한 데이터를 가져옵니다. 이 회사는 개발 노력을 줄이기 위해 REST API에 대한 액세스를 제어하는 AWS 관리형 솔루션을 원합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts its application on AWS. The company uses Amazon Cognito to manage users. When users log in to the application, the application fetches required data from Amazon DynamoDB by using a REST API that is hosted in Amazon API Gateway. The company wants an AWS managed solution that will control access to the REST API to reduce development efforts.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "어떤 사용자가 요청했는지 확인하기 위해 API Gateway에서 권한 부여자가 되도록 AWS Lambda 함수를 구성합니다.",
        "B": "각 사용자에 대해 각 요청과 함께 전송되어야 하는 API 키를 생성하고 할당합니다. AWS Lambda 함수를 사용하여 키를 검증합니다.",
        "C": "모든 요청과 함께 헤더에 사용자의 이메일 주소를 보냅니다. 해당 이메일 주소를 가진 사용자에게 적절한 액세스 권한이 있는지 확인하려면 AWS Lambda 함수를 호출하십시오.",
        "D": "Amazon Cognito가 각 요청을 검증할 수 있도록 API Gateway에서 Amazon Cognito 사용자 풀 권한 부여자를 구성합니다."
      },
      "eng": {
        "A": "Configure an AWS Lambda function to be an authorizer in API Gateway to validate which user made the request.",
        "B": "For each user, create and assign an API key that must be sent with each request. Validate the key by using an AWS Lambda function.",
        "C": "Send the user’s email address in the header with every request. Invoke an AWS Lambda function to validate that the user with that email address has proper access.",
        "D": "Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request."
      }
    },
    "category": [
      "Cognito"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89142-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 229,
    "question": {
      "kor": "회사에서 레거시 애플리케이션을 사용하여 데이터를 CSV 형식으로 생성합니다. 레거시 애플리케이션은 출력 데이터를 Amazon S3에 저장합니다. 이 회사는 복잡한 SQL 쿼리를 수행하여 Amazon Redshift 및 Amazon S3에만 저장된 데이터를 분석할 수 있는 새로운 상용 기성품(COTS) 애플리케이션을 배포하고 있습니다. 그러나 COTS 애플리케이션은 레거시 애플리케이션이 생성하는 .csv 파일을 처리할 수 없습니다.\n회사는 레거시 애플리케이션을 업데이트하여 다른 형식으로 데이터를 생성할 수 없습니다. 회사는 COTS 애플리케이션이 레거시 애플리케이션이 생성하는 데이터를 사용할 수 있도록 솔루션을 구현해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses a legacy application to produce data in CSV format. The legacy application stores the output data in Amazon S3. The company is deploying a new commercial off-the-shelf (COTS) application that can perform complex SQL queries to analyze data that is stored in Amazon Redshift and Amazon S3 only. However, the COTS application cannot process the .csv files that the legacy application produces.\nThe company cannot update the legacy application to produce data in another format. The company needs to implement a solution so that the COTS application can use the data that the legacy application produces.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "일정에 따라 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성합니다. .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift에 저장하도록 ETL 작업을 구성합니다.",
        "B": "Amazon EC2 인스턴스에서 실행되는 Python 스크립트를 개발하여 .csv 파일을 .sql 파일로 변환합니다. Cron 일정에서 Python 스크립트를 호출하여 출력 파일을 Amazon S3에 저장합니다.",
        "C": "AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트를 사용하여 Lambda 함수를 호출합니다. ETL(추출, 변환 및 로드) 작업을 수행하여 .csv 파일을 처리하고 처리된 데이터를 DynamoDB 테이블에 저장하도록 Lambda 함수를 구성합니다.",
        "D": "Amazon EventBridge를 사용하여 매주 일정에 따라 Amazon EMR 클러스터를 시작합니다. 추출, 변환 및 로드(ETL) 작업을 수행하여 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift 테이블에 저장하도록 EMR 클러스터를 구성합니다."
      },
      "eng": {
        "A": "Create an AWS Glue extract, transform, and load (ETL) job that runs on a schedule. Configure the ETL job to process the .csv files and store the processed data in Amazon Redshift.",
        "B": "Develop a Python script that runs on Amazon EC2 instances to convert the .csv files to .sql files. Invoke the Python script on a cron schedule to store the output files in Amazon S3.",
        "C": "Create an AWS Lambda function and an Amazon DynamoDB table. Use an S3 event to invoke the Lambda function. Configure the Lambda function to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in the DynamoDB table.",
        "D": "Use Amazon EventBridge to launch an Amazon EMR cluster on a weekly schedule. Configure the EMR cluster to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in an Amazon Redshift table."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99817-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 234,
    "question": {
      "kor": "회사에서 내부 브라우저 기반 애플리케이션을 실행합니다. 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 근무 시간 동안 최대 20개의 인스턴스로 확장되지만 밤에는 2개의 인스턴스로 축소됩니다. 오전 중반까지는 잘 돌아가는데도 하루가 시작되면 애플리케이션이 매우 느리다고 직원들이 불평하고 있다.\n직원 불만을 해결하고 비용을 최소화하기 위해 확장을 어떻게 변경해야 합니까?",
      "eng": "A company runs an internal browser-based application. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight. Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning.\nHow should the scaling be changed to address the staff complaints and keep costs to a minimum?"
    },
    "choices": {
      "kor": {
        "A": "사무실이 열리기 직전에 원하는 수용 인원을 20명으로 설정하는 예약 작업을 구현합니다.",
        "B": "더 낮은 CPU 임계값에서 트리거되는 단계 조정 작업을 구현하고 휴지 기간을 줄입니다.",
        "C": "더 낮은 CPU 임계값에서 트리거되는 대상 추적 작업을 구현하고 휴지 기간을 줄입니다.",
        "D": "사무실이 열리기 직전에 최소 및 최대 수용 인원을 20명으로 설정하는 예약 조치를 구현합니다."
      },
      "eng": {
        "A": "Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.",
        "B": "Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.",
        "C": "Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.",
        "D": "Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99584-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 242,
    "question": {
      "kor": "한 회사에서 Amazon Route 53 지연 시간 기반 라우팅을 사용하여 전 세계 사용자를 위해 UDP 기반 애플리케이션으로 요청을 라우팅하고 있습니다. 이 애플리케이션은 미국, 아시아 및 유럽에 있는 회사의 온프레미스 데이터 센터에 있는 중복 서버에서 호스팅됩니다. 회사의 규정 준수 요구 사항에 따르면 애플리케이션은 온프레미스에서 호스팅되어야 합니다. 회사는 애플리케이션의 성능과 가용성을 개선하고자 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company’s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "3개의 AWS 리전에서 3개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 처리합니다. AWS Global Accelerator를 사용하여 가속기를 생성하고 NLB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.",
        "B": "3개의 AWS 리전에서 3개의 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 처리합니다. AWS Global Accelerator를 사용하여 가속기를 생성하고 ALB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.",
        "C": "3개의 AWS 리전에서 3개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 처리합니다. Route 53에서 3개의 NLB를 가리키는 지연 시간 기반 레코드를 생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.",
        "D": "온프레미스 엔드포인트를 처리하기 위해 3개의 AWS 리전에서 3개의 ALB(Application Load Balancer)를 구성합니다. Route 53에서 3개의 ALB를 가리키는 지연 시간 기반 레코드를 생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다."
      },
      "eng": {
        "A": "Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.",
        "B": "Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.",
        "C": "Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.",
        "D": "Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator",
      "Elastic Load Balancer"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102131-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 246,
    "question": {
      "kor": "회사는 AWS 클라우드에 수백 개의 Amazon EC2 Linux 기반 인스턴스를 보유하고 있습니다. 시스템 관리자는 공유 SSH 키를 사용하여 인스턴스를 관리했습니다. 최근 감사 후 회사의 보안 팀은 모든 공유 키를 제거하도록 지시하고 있습니다. 솔루션 설계자는 EC2 인스턴스에 대한 보안 액세스를 제공하는 솔루션을 설계해야 합니다.\n최소한의 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company’s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances.\nWhich solution will meet this requirement with the LEAST amount of administrative overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결합니다.",
        "B": "AWS Security Token Service(AWS STS)를 사용하여 온디맨드 방식으로 일회성 SSH 키를 생성합니다.",
        "C": "배스천 인스턴스 집합에 대한 공유 SSH 액세스를 허용합니다. 배스천 인스턴스에서 SSH 액세스만 허용하도록 다른 모든 인스턴스를 구성합니다.",
        "D": "Amazon Cognito 사용자 지정 권한 부여자를 사용하여 사용자를 인증합니다. AWS Lambda 함수를 호출하여 임시 SSH 키를 생성합니다."
      },
      "eng": {
        "A": "Use AWS Systems Manager Session Manager to connect to the EC2 instances.",
        "B": "Use AWS Security Token Service (AWS STS) to generate one-time SSH keys on demand.",
        "C": "Allow shared SSH access to a set of bastion instances. Configure all other instances to allow only SSH access from the bastion instances.",
        "D": "Use an Amazon Cognito custom authorizer to authenticate users. Invoke an AWS Lambda function to generate a temporary SSH key."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99628-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 273,
    "question": {
      "kor": "빠르게 성장하는 전자상거래 회사는 단일 AWS 리전에서 워크로드를 실행하고 있습니다. 솔루션 설계자는 다른 AWS 리전을 포함하는 재해 복구(DR) 전략을 생성해야 합니다. 회사는 대기 시간을 최소화하면서 DR 지역에서 데이터베이스를 최신 상태로 유지하기를 원합니다. DR 지역의 나머지 인프라는 감소된 용량으로 실행되어야 하며 필요한 경우 확장할 수 있어야 합니다.\n가장 낮은 RTO(복구 시간 목표)로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary.\nWhich solution will meet these requirements with the LOWEST recovery time objective (RTO)?"
    },
    "choices": {
      "kor": {
        "A": "파일럿 라이트 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다.",
        "B": "웜 대기 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다.",
        "C": "파일럿 라이트 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다.",
        "D": "웜 대기 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다."
      },
      "eng": {
        "A": "Use an Amazon Aurora global database with a pilot light deployment.",
        "B": "Use an Amazon Aurora global database with a warm standby deployment.",
        "C": "Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment.",
        "D": "Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment."
      }
    },
    "category": [
      "DR"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99505-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 276,
    "question": {
      "kor": "회사에는 온프레미스 Windows Server에서 실행되는 Microsoft .NET 애플리케이션이 있습니다. 애플리케이션은 Oracle Database Standard Edition 서버를 사용하여 데이터를 저장합니다. 이 회사는 AWS로의 마이그레이션을 계획하고 있으며 애플리케이션을 이동하는 동안 개발 변경을 최소화하려고 합니다. AWS 애플리케이션 환경은 가용성이 높아야 합니다.\n이러한 요구 사항을 충족하기 위해 회사는 어떤 조합의 조치를 취해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company has a Microsoft .NET application that runs on an on-premises Windows Server. The application stores data by using an Oracle Database Standard Edition server. The company is planning a migration to AWS and wants to minimize development changes while moving the application. The AWS application environment should be highly available.\nWhich combination of actions should the company take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": ".NET Core를 실행하는 AWS Lambda 함수를 사용하여 애플리케이션을 서버리스로 리팩터링합니다.",
        "B": "다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic Beanstalk에서 애플리케이션을 다시 호스팅합니다.",
        "C": "Amazon Linux Amazon 머신 이미지(AMI)를 사용하여 Amazon EC2에서 실행되도록 애플리케이션 플랫폼을 변경합니다.",
        "D": "다중 AZ 배포에서 AWS DMS(AWS Database Migration Service)를 사용하여 Oracle 데이터베이스에서 Amazon DynamoDB로 마이그레이션합니다.",
        "E": "다중 AZ 배포에서 AWS Database Migration Service(AWS DMS)를 사용하여 Oracle 데이터베이스에서 Amazon RDS의 Oracle로 마이그레이션합니다."
      },
      "eng": {
        "A": "Refactor the application as serverless with AWS Lambda functions running .NET Core.",
        "B": "Rehost the application in AWS Elastic Beanstalk with the .NET platform in a Multi-AZ deployment.",
        "C": "Replatform the application to run on Amazon EC2 with the Amazon Linux Amazon Machine Image (AMI).",
        "D": "Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Amazon DynamoDB in a Multi-AZ deployment.",
        "E": "Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Oracle on Amazon RDS in a Multi-AZ deployment."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89068-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 279,
    "question": {
      "kor": "한 회사에 여러 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 각 EC2 인스턴스에는 여러 Amazon Elastic Block Store(Amazon EBS) 데이터 볼륨이 연결되어 있습니다. 애플리케이션의 EC2 인스턴스 구성 및 데이터는 야간에 백업해야 합니다. 또한 애플리케이션은 다른 AWS 리전에서 복구 가능해야 합니다.\n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an application that runs on several Amazon EC2 instances. Each EC2 instance has multiple Amazon Elastic Block Store (Amazon EBS) data volumes attached to it. The application’s EC2 instance configuration and data need to be backed up nightly. The application also needs to be recoverable in a different AWS Region.\nWhich solution will meet these requirements in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "애플리케이션 EBS 볼륨의 야간 스냅샷을 예약하고 스냅샷을 다른 리전에 복사하는 AWS Lambda 함수를 작성합니다.",
        "B": "야간 백업을 수행하기 위해 AWS Backup을 사용하여 백업 계획을 생성합니다. 백업을 다른 리전에 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다.",
        "C": "야간 백업을 수행하기 위해 AWS Backup을 사용하여 백업 계획을 만듭니다. 백업을 다른 리전에 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다.",
        "D": "애플리케이션 볼륨의 야간 스냅샷을 예약하고 스냅샷을 EBS 다른 가용 영역에 복사하는 AWS Lambda 함수를 작성합니다."
      },
      "eng": {
        "A": "Write an AWS Lambda function that schedules nightly snapshots of the application’s EBS volumes and copies the snapshots to a different Region.",
        "B": "Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EC2 instances as resources.",
        "C": "Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EBS volumes as resources.",
        "D": "Write an AWS Lambda function that schedules nightly snapshots of the application's EBS volumes and copies the snapshots to a different Availability Zone."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99785-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 285,
    "question": {
      "kor": "회사에서 이전 애플리케이션을 AWS로 마이그레이션하고 있습니다. 애플리케이션은 매시간 배치 작업을 실행하며 CPU를 많이 사용합니다. 배치 작업은 온프레미스 서버에서 평균 15분이 소요됩니다. 서버에는 64개의 가상 CPU(vCPU)와 512GiB의 메모리가 있습니다.\n최소한의 운영 오버헤드로 15분 이내에 배치 작업을 실행하는 솔루션은 무엇입니까?",
      "eng": "A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory.\nWhich solution will run the batch job within 15 minutes with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "기능적 확장과 함께 AWS Lambda를 사용하십시오.",
        "B": "AWS Fargate와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.",
        "C": "AWS Auto Scaling과 함께 Amazon Lightsail을 사용합니다.",
        "D": "Amazon EC2에서 AWS Batch를 사용합니다."
      },
      "eng": {
        "A": "Use AWS Lambda with functional scaling.",
        "B": "Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.",
        "C": "Use Amazon Lightsail with AWS Auto Scaling.",
        "D": "Use AWS Batch on Amazon EC2."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100227-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 288,
    "question": {
      "kor": "회사에서 Linux 기반 웹 서버 그룹을 AWS로 마이그레이션하고 있습니다. 웹 서버는 일부 콘텐츠에 대해 공유 파일 저장소의 파일에 액세스해야 합니다. 회사는 신청서를 변경해서는 안됩니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is migrating a Linux-based web server group to AWS. The web servers must access files in a shared file store for some content. The company must not make any changes to the application.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "웹 서버에 대한 액세스 권한이 있는 Amazon S3 Standard 버킷을 생성합니다.",
        "B": "Amazon S3 버킷을 원본으로 사용하여 Amazon CloudFront 배포를 구성합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 EFS 파일 시스템을 마운트합니다.",
        "D": "범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 모든 웹 서버에 EBS 볼륨을 마운트합니다."
      },
      "eng": {
        "A": "Create an Amazon S3 Standard bucket with access to the web servers.",
        "B": "Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.",
        "C": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on all web servers.",
        "D": "Configure a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume to all web servers."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99671-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 306,
    "question": {
      "kor": "회사는 여러 가용 영역에 걸쳐 Amazon EC2 Linux 인스턴스에서 애플리케이션을 실행합니다. 애플리케이션에는 고가용성 및 POSIX(Portable Operating System Interface) 호환 스토리지 계층이 필요합니다. 스토리지 계층은 최대 데이터 내구성을 제공해야 하며 EC2 인스턴스 간에 공유 가능해야 합니다. 저장소 계층의 데이터는 처음 30일 동안 자주 액세스되고 그 이후에는 드물게 액세스됩니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 Standard 스토리지 클래스를 사용하십시오. S3 수명 주기 정책을 생성하여 자주 액세스하지 않는 데이터를 S3 Glacier로 이동합니다.",
        "B": "Amazon S3 Standard 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 자주 액세스하지 않는 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) Standard 스토리지 클래스를 사용합니다. 자주 액세스하지 않는 데이터를 EFS Standard-Infrequent Access(EFS Standard-IA)로 이동하는 수명 주기 관리 정책을 만듭니다.",
        "D": "Amazon Elastic File System(Amazon EFS) One Zone 스토리지 클래스를 사용합니다. 자주 액세스하지 않는 데이터를 EFS One Zone-Infrequent Access(EFS One Zone-IA)로 이동하는 수명 주기 관리 정책을 만듭니다."
      },
      "eng": {
        "A": "Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier.",
        "B": "Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA).",
        "C": "Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).",
        "D": "Use the Amazon Elastic File System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102152-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 326,
    "question": {
      "kor": "한 전자상거래 회사에서 사용자 트래픽이 증가하고 있습니다. 회사의 스토어는 웹 계층과 별도의 데이터베이스 계층으로 구성된 2계층 웹 애플리케이션으로 Amazon EC2 인스턴스에 배포됩니다. 트래픽이 증가함에 따라 회사는 아키텍처로 인해 사용자에게 적시에 마케팅 및 주문 확인 이메일을 보내는 데 상당한 지연이 발생하고 있음을 알게 되었습니다. 이 회사는 복잡한 이메일 전송 문제를 해결하는 데 소요되는 시간을 줄이고 운영 오버헤드를 최소화하기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "An ecommerce company is experiencing an increase in user traffic. The company’s store is deployed on Amazon EC2 instances as a two-tier web application consisting of a web tier and a separate database tier. As traffic increases, the company notices that the architecture is causing significant delays in sending timely marketing and order confirmation email to users. The company wants to reduce the time it spends resolving complex email delivery issues and minimize operational overhead.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 만듭니다.",
        "B": "Amazon Simple Email Service(Amazon SES)를 통해 이메일을 보내도록 웹 인스턴스를 구성합니다.",
        "C": "Amazon Simple Notification Service(Amazon SNS)를 통해 이메일을 보내도록 웹 인스턴스를 구성합니다.",
        "D": "이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다. Auto Scaling 그룹에 인스턴스를 배치합니다."
      },
      "eng": {
        "A": "Create a separate application tier using EC2 instances dedicated to email processing.",
        "B": "Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).",
        "C": "Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS).",
        "D": "Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102190-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 330,
    "question": {
      "kor": "금융 회사는 AWS에서 웹 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon API Gateway 지역 API 엔드포인트를 사용하여 사용자에게 현재 주가를 검색할 수 있는 기능을 제공 합니다. 회사의 보안 팀은 API 요청 수가 증가한 것을 발견했습니다. 보안 팀은 HTTP 플러드 공격이 애플리케이션을 오프라인 상태로 만들 수 있다고 우려하고 있습니다.\n솔루션 설계자는 이러한 유형의 공격으로부터 애플리케이션을 보호하기 위한 솔루션을 설계해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company’s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline.\nA solutions architect must design a solution to protect the application from this type of attack.\nWhich solution meets these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "최대 TTL이 24시간인 API Gateway 지역 API 엔드포인트 앞에 Amazon CloudFront 배포를 생성합니다.",
        "B": "속도 기반 규칙을 사용하여 리전 AWS WAF 웹 ACL을 생성합니다. 웹 ACL을 API Gateway 단계와 연결합니다.",
        "C": "Amazon CloudWatch 지표를 사용하여 개수 지표를 모니터링하고 미리 정의된 속도에 도달하면 보안 팀에 알립니다.",
        "D": "API Gateway 지역 API 엔드포인트 앞에 Lambda@Edge를 사용하여 Amazon CloudFront 배포를 생성합니다. 사전 정의된 속도를 초과하는 IP 주소의 요청을 차단하는 AWS",
        "E": "Lambda 함수를 생성합니다."
      },
      "eng": {
        "A": "Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.",
        "B": "Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.",
        "C": "Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.",
        "D": "Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate."
      }
    },
    "category": [
      "WAF"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102167-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 333,
    "question": {
      "kor": "한 회사가 AWS Lake Formation을 사용하여 AWS에 데이터 분석 플랫폼을 구축하고 있습니다. 플랫폼은 Amazon S3 및 Amazon RDS와 같은 다양한 소스에서 데이터를 수집합니다. 회사에는 민감한 정보가 포함된 데이터 부분에 대한 액세스를 방지하기 위한 보안 솔루션이 필요합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Lake Formation 테이블에 액세스할 수 있는 권한이 포함된 IAM 역할을 생성합니다.",
        "B": "행 수준 보안과 셀 수준 보안을 구현하기 위한 데이터 필터를 만듭니다.",
        "C": "Lake Formation이 데이터를 수집하기 전에 민감한 정보를 제거하는 AWS Lambda 함수를 생성합니다.",
        "D": "Lake Formation 테이블에서 민감한 정보를 주기적으로 쿼리하고 제거하는 AWS Lambda 함수를 생성합니다."
      },
      "eng": {
        "A": "Create an IAM role that includes permissions to access Lake Formation tables.",
        "B": "Create data filters to implement row-level security and cell-level security.",
        "C": "Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.",
        "D": "Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121162-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 347,
    "question": {
      "kor": "회사는 Amazon S3 버킷에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon Cognito를 자격 증명 공급자로 사용하여 사용자를 인증하고 다른 S3 버킷에 저장된 보호된 리소스에 대한 액세스를 제공하는 JSON 웹 토큰(JWT)을 반환합니다.\n응용 프로그램 배포 시 사용자는 오류를 보고하고 보호된 콘텐츠에 액세스할 수 없습니다. 솔루션 설계자는 사용자가 보호된 콘텐츠에 액세스할 수 있도록 적절한 권한을 제공하여 이 문제를 해결해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket.\nUpon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Cognito 자격 증명 풀을 업데이트하여 보호된 콘텐츠에 액세스하기 위한 적절한 IAM 역할을 맡습니다.",
        "B": "애플리케이션이 보호된 콘텐츠에 액세스할 수 있도록 S3 ACL을 업데이트합니다.",
        "C": "애플리케이션을 Amazon S3에 재배포하여 S3 버킷의 최종적으로 일관된 읽기가 보호된 콘텐츠에 액세스하는 사용자의 기능에 영향을 미치지 않도록 합니다.",
        "D": "자격 증명 풀 내에서 사용자 지정 속성 매핑을 사용하고 사용자에게 보호된 콘텐츠에 액세스할 수 있는 적절한 권한을 부여하도록 Amazon Cognito 풀을 업데이트합니다."
      },
      "eng": {
        "A": "Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.",
        "B": "Update the S3 ACL to allow the application to access the protected content.",
        "C": "Redeploy the application to Amazon S3 to prevent eventually consistent reads in the S3 bucket from affecting the ability of users to access the protected content.",
        "D": "Update the Amazon Cognito pool to use custom attribute mappings within the identity pool and grant users the proper permissions to access the protected content."
      }
    },
    "category": [
      "Cognito"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99754-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 360,
    "question": {
      "kor": "한 회사에서 여러 프로덕션 애플리케이션을 호스팅합니다. 애플리케이션 중 하나는 여러 AWS 리전에서 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service(Amazon SNS) 및 Amazon Simple Queue Service(Amazon SQS)의 리소스로 구성됩니다. 모든 회사 리소스에는 \"응용 프로그램\"이라는 태그 이름과 각 응용 프로그램에 해당하는 값이 태그로 지정됩니다. 솔루션 설계자는 태그가 지정된 모든 구성 요소를 식별하기 위한 가장 빠른 솔루션을 제공해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company hosts multiple production applications. One of the applications consists of resources from Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service (Amazon SNS), and Amazon Simple Queue Service (Amazon SQS) across multiple AWS Regions. All company resources are tagged with a tag name of “application” and a value that corresponds to each application. A solutions architect must provide the quickest solution for identifying all of the tagged components.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS CloudTrail을 사용하여 애플리케이션 태그가 있는 리소스 목록을 생성합니다.",
        "B": "AWS CLI를 사용하여 모든 리전에서 각 서비스를 쿼리하여 태그가 지정된 구성 요소를 보고합니다.",
        "C": "Amazon CloudWatch Logs Insights에서 쿼리를 실행하여 애플리케이션 태그가 있는 구성 요소에 대해 보고합니다.",
        "D": "AWS Resource Groups Tag Editor로 쿼리를 실행하여 애플리케이션 태그를 사용하여 전역적으로 리소스에 대해 보고합니다."
      },
      "eng": {
        "A": "Use AWS CloudTrail to generate a list of resources with the application tag.",
        "B": "Use the AWS CLI to query each service across all Regions to report the tagged components.",
        "C": "Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag.",
        "D": "Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95145-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 364,
    "question": {
      "kor": "한 온라인 소매 회사는 5천만 명 이상의 활성 고객을 보유하고 있으며 매일 25,000건 이상의 주문을 받습니다. 회사는 고객의 구매 데이터를 수집하고 이 데이터를 Amazon S3에 저장합니다. 추가 고객 데이터는 Amazon RDS에 저장됩니다.\n회사는 팀이 분석을 수행할 수 있도록 다양한 팀에서 모든 데이터를 사용할 수 있도록 하려고 합니다. 솔루션은 데이터에 대한 세분화된 권한을 관리하는 기능을 제공하고 운영 오버헤드를 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "An online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS.\nThe company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "구매 데이터를 마이그레이션하여 Amazon RDS에 직접 씁니다. RDS 액세스 제어를 사용하여 액세스를 제한하십시오.",
        "B": "Amazon RDS에서 Amazon S3로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. AWS Glue 크롤러를 생성합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. S3 정책을 사용하여 액세스를 제한하십시오.",
        "C": "AWS Lake Formation을 사용하여 데이터 레이크를 생성합니다. Amazon RDS에 대한 AWS Glue JDBC 연결을 생성합니다. Lake Formation에 S3 버킷을 등록합니다. Lake Formation 액세스 제어를 사용하여 액세스를 제한하십시오.",
        "D": "Amazon Redshift 클러스터를 생성합니다. Amazon S3 및 Amazon RDS에서 Amazon Redshift로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. Amazon Redshift 액세스 제어를 사용하여 액세스를 제한하십시오."
      },
      "eng": {
        "A": "Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access.",
        "B": "Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access.",
        "C": "Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.",
        "D": "Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access."
      }
    },
    "category": [
      "Data Store"
    ],
    "subcategory": [
      "Lake Formation",
      "fine-grained permissions"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 369,
    "question": {
      "kor": "회사는 Amazon EC2에서 콘텐츠 관리 시스템(CMS)을 사용하는 웹 사이트를 운영합니다. CMS는 단일 EC2 인스턴스에서 실행되며 데이터 계층에 Amazon Aurora MySQL 다중 AZ DB 인스턴스를 사용합니다. 웹 사이트 이미지는 EC2 인스턴스 내부에 탑재된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장됩니다.\n웹 사이트의 성능과 복원력을 개선하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company runs a website that uses a content management system (CMS) on Amazon EC2. The CMS runs on a single EC2 instance and uses an Amazon Aurora MySQL Multi-AZ DB instance for the data tier. Website images are stored on an Amazon Elastic Block Store (Amazon EBS) volume that is mounted inside the EC2 instance.\nWhich combination of actions should a solutions architect take to improve the performance and resilience of the website? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "웹사이트 이미지를 모든 EC2 인스턴스에 탑재된 Amazon S3 버킷으로 이동합니다.",
        "B": "기본 EC2 인스턴스의 NFS 공유를 사용하여 웹사이트 이미지를 공유합니다. 이 공유를 다른 EC2 인스턴스에 마운트합니다.",
        "C": "모든 EC2 인스턴스에 탑재된 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 웹 사이트 이미지를 이동합니다.",
        "D": "기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하여 Auto Scaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. 최소 2개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹사이트용 AWS Global Accelerator에서 액셀러레이터 구성",
        "E": "기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하여 Auto Scaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. 최소 2개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹 사이트에 대한 Amazon CloudFront 배포를 구성합니다."
      },
      "eng": {
        "A": "Move the website images into an Amazon S3 bucket that is mounted on every EC2 instance",
        "B": "Share the website images by using an NFS share from the primary EC2 instance. Mount this share on the other EC2 instances.",
        "C": "Move the website images onto an Amazon Elastic File System (Amazon EFS) file system that is mounted on every EC2 instance.",
        "D": "Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an accelerator in AWS Global Accelerator for the website",
        "E": "Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an Amazon CloudFront distribution for the website."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109420-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 373,
    "question": {
      "kor": "회사는 VPC의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스에 배포된 웹 애플리케이션을 실행합니다. 퍼블릭 서브넷에서 확장되는 ALB(Application Load Balancer)는 웹 트래픽을 EC2 인스턴스로 보냅니다. 회사는 ALB에서 EC2 인스턴스로의 인바운드 트래픽을 제한하는 동시에 EC2 인스턴스의 프라이빗 서브넷 내부 또는 외부의 다른 소스로부터의 액세스를 방지하는 새로운 보안 조치를 구현하려고 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs a web application that is deployed on Amazon EC2 instances in the private subnet of a VPC. An Application Load Balancer (ALB) that extends across the public subnets directs web traffic to the EC2 instances. The company wants to implement new security measures to restrict inbound traffic from the ALB to the EC2 instances while preventing access from any other source inside or outside the private subnet of the EC2 instances.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "인터넷에서 EC2 인스턴스의 프라이빗 IP 주소로 트래픽을 보내도록 라우팅 테이블의 경로를 구성합니다.",
        "B": "ALB의 보안 그룹에서 오는 트래픽만 허용하도록 EC2 인스턴스의 보안 그룹을 구성합니다.",
        "C": "EC2 인스턴스를 퍼블릭 서브넷으로 이동합니다. EC2 인스턴스에 탄력적 IP 주소 집합을 제공합니다.",
        "D": "모든 포트에서 모든 TCP 트래픽을 허용하도록 ALB에 대한 보안 그룹을 구성합니다."
      },
      "eng": {
        "A": "Configure a route in a route table to direct traffic from the internet to the private IP addresses of the EC2 instances.",
        "B": "Configure the security group for the EC2 instances to only allow traffic that comes from the security group for the ALB.",
        "C": "Move the EC2 instances into the public subnet. Give the EC2 instances a set of Elastic IP addresses.",
        "D": "Configure the security group for the ALB to allow any TCP traffic on any port."
      }
    },
    "category": [
      "Security Group"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99660-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 377,
    "question": {
      "kor": "회사에서 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL로 이전하고 있습니다. 데이터베이스에는 동일한 테이블에 쓰는 여러 응용 프로그램이 있습니다. 응용 프로그램은 각 마이그레이션 사이에 한 달씩 하나씩 마이그레이션해야 합니다. 경영진은 데이터베이스에 많은 수의 읽기 및 쓰기가 있다는 우려를 표명했습니다. 데이터는 마이그레이션하는 동안 두 데이터베이스에서 동기화 상태를 유지해야 합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is moving its on-premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables.\nThe applications need to be migrated one by one with a month in between each migration. Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "초기 마이그레이션에는 AWS DataSync를 사용하십시오. AWS Database Migration Service(AWS DMS)를 사용하여 변경 데이터 캡처(CDC) 복제 작업 및 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "B": "초기 마이그레이션에 AWS DataSync를 사용합니다. AWS Database Migration Service(AWS DMS)를 사용하여 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "C": "메모리 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 CDC(변경 데이터 캡처) 복제 작업과 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "D": "컴퓨팅 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다."
      },
      "eng": {
        "A": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables.",
        "B": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "C": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "D": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95326-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 382,
    "question": {
      "kor": "한 회사에서 클러스터와 인스턴스를 사용하여 결제 처리 애플리케이션을 Amazon Elastic Container Service(Amazon ECS) Amazon RDS DB 구축하고 실행하려고 합니다. 회사는 규정 준수를 위해 온프레미스 데이터 센터에서 애플리케이션을 실행합니다.\n솔루션 아키텍트는 AWS Outposts를 솔루션의 일부로 사용하려고 합니다. 솔루션 설계자는 회사의 운영 팀과 협력하여 애플리케이션을 구축하고 있습니다.\n회사 운영팀에서는 어떤 활동을 담당하나요? (3개를 선택하세요.)",
      "eng": "A company wants to use Amazon Elastic Container Service (Amazon ECS) clusters and Amazon RDS DB instances to build and run a payment processing application. The company will run the application in its on-premises data center for compliance purposes.\nA solutions architect wants to use AWS Outposts as part of the solution. The solutions architect is working with the company's operational team to build the application.\nWhich activities are the responsibility of the company's operational team? (Choose three.)"
    },
    "choices": {
      "kor": {
        "A": "Outposts 랙에 탄력적인 전원 및 네트워크 연결 제공",
        "B": "Outposts에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스 관리",
        "C": "데이터센터 환경의 물리적 보안 및 접근통제",
        "D": "Outposts 랙 내의 전원 공급 장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 가용성",
        "E": "Outposts 구성 요소의 물리적 유지 관리",
        "F": "서버 오류 및 유지 관리 이벤트를 완화하기 위해 Amazon ECS 클러스터에 추가 용량 제공"
      },
      "eng": {
        "A": "Providing resilient power and network connectivity to the Outposts racks",
        "B": "Managing the virtualization hypervisor, storage systems, and the AWS services that run on Outposts",
        "C": "Physical security and access controls of the data center environment",
        "D": "Availability of the Outposts infrastructure including the power supplies, servers, and networking equipment within the Outposts racks",
        "E": "Physical maintenance of Outposts components",
        "F": "Providing extra capacity for Amazon ECS clusters to mitigate server failures and maintenance events"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/119530-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C",
      "F"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 384,
    "question": {
      "kor": "회사는 서로 다른 제품군에 대해 AWS에서 여러 애플리케이션을 호스팅합니다. 애플리케이션은 Amazon EC2 인스턴스 및 Application Load Balancer를 비롯한 다양한 컴퓨팅 리소스를 사용합니다. 애플리케이션은 여러 AWS 리전의 AWS Organizations에서 동일한 조직의 다른 AWS 계정에서 실행됩니다. 각 제품군의 팀은 개별 계정의 각 컴퓨팅 리소스에 태그를 지정했습니다.\n회사는 조직의 통합 청구 기능에서 각 제품군의 비용에 대한 자세한 정보를 원합니다.\n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company hosts multiple applications on AWS for different product lines. The applications use different compute resources, including Amazon EC2 instances and Application Load Balancers. The applications run in different AWS accounts under the same organization in AWS Organizations across multiple AWS Regions. Teams for each product line have tagged each compute resource in the individual accounts.\nThe company wants more details about the cost for each product line from the consolidated billing feature in Organizations.\nWhich combination of steps will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "AWS 결제 콘솔에서 특정 AWS 생성 태그를 선택합니다.",
        "B": "AWS 결제 콘솔에서 특정 사용자 정의 태그를 선택합니다.",
        "C": "AWS 리소스 그룹 콘솔에서 특정 사용자 정의 태그를 선택합니다.",
        "D": "각 AWS 계정에서 선택한 태그를 활성화합니다.",
        "E": "조직 마스터 계정에서 선택한 태그를 활성화합니다."
      },
      "eng": {
        "A": "Select a specific AWS generated tag in the AWS Billing console.",
        "B": "Select a specific user-defined tag in the AWS Billing console.",
        "C": "Select a specific user-defined tag in the AWS Resource Groups console.",
        "D": "Activate the selected tag from each AWS account.",
        "E": "Activate the selected tag from the Organizations management account."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117403-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 389,
    "question": {
      "kor": "회사에서 PostgreSQL용 Amazon RDS를 사용하는 애플리케이션을 실행합니다. 애플리케이션은 평일 업무 시간에만 트래픽을 수신합니다. 회사는 이 사용량을 기반으로 비용을 최적화하고 운영 오버헤드를 줄이려고 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an application that uses Amazon RDS for PostgreSQL. The application receives traffic only on weekdays during business hours. The company wants to optimize costs and reduce operational overhead based on this usage.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS의 인스턴스 스케줄러를 사용하여 시작 및 중지 일정을 구성하십시오.",
        "B": "자동 백업을 끕니다. 데이터베이스의 매주 수동 스냅샷을 생성합니다.",
        "C": "최소 CPU 사용률을 기준으로 데이터베이스를 시작하고 중지하는 사용자 지정 AWS Lambda 함수를 생성합니다.",
        "D": "모든 Upfront 예약 DB 인스턴스를 구매합니다."
      },
      "eng": {
        "A": "Use the Instance Scheduler on AWS to configure start and stop schedules.",
        "B": "Turn off automatic backups. Create weekly manual snapshots of the database.",
        "C": "Create a custom AWS Lambda function to start and stop the database based on minimum CPU utilization.",
        "D": "Purchase All Upfront reserved DB instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/116924-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 390,
    "question": {
      "kor": "회사에서 해당 애플리케이션을 위한 스토리지 솔루션을 찾고 있습니다. 솔루션은 가용성과 확장성이 높아야 합니다. 또한 솔루션은 기본 프로토콜을 통해 AWS 및 온프레미스의 여러 Linux 인스턴스에 의해 마운트될 수 있고 최소 크기 요구 사항이 없는 파일 시스템으로 작동해야 합니다. 회사는 온프레미스 네트워크에서 VPC로 액세스하기 위해 사이트 간 VPN을 설정했습니다.\n이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?",
      "eng": "A company seeks a storage solution for its application. The solution must be highly available and scalable. The solution also must function as a file system be mountable by multiple Linux instances in AWS and on premises through native protocols, and have no minimum size requirements. The company has set up a Site-to-Site VPN for access from its on-premises network to its VPC.\nWhich storage solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon FSx 다중 AZ 배포",
        "B": "Amazon Elastic Block Store(Amazon EBS) 다중 연결 볼륨",
        "C": "탑재 대상이 여러 개인 Amazon Elastic File System(Amazon EFS)",
        "D": "단일 탑재 대상 및 여러 액세스 지점이 있는 Amazon Elastic File System(Amazon EFS)"
      },
      "eng": {
        "A": "Amazon FSx Multi-AZ deployments",
        "B": "Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes",
        "C": "Amazon Elastic File System (Amazon EFS) with multiple mount targets",
        "D": "Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109665-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 391,
    "question": {
      "kor": "회사에 통합 결제를 사용하는 여러 AWS 계정이 있습니다. 이 회사는 90일 동안 여러 개의 활성 고성능 Amazon RDS for Oracle 온디맨드 DB 인스턴스를 실행합니다. 회사의 재무 팀은 통합 결제 계정 및 기타 모든 AWS 계정에서 AWS Trusted Advisor에 액세스할 수 있습니다.\n재무 팀은 적절한 AWS 계정을 사용하여 RDS에 대한 Trusted Advisor 확인 권장 사항에 액세스해야 합니다. 재무팀은 적절한 Trusted Advisor 수표를 검토하여 RDS 비용을 줄여야 합니다.\n이러한 요구 사항을 충족하기 위해 재무 팀은 어떤 조합의 단계를 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company has multiple AWS accounts that use consolidated billing. The company runs several active high performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company’s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts.\nThe finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS. The finance team must review the appropriate Trusted Advisor check to reduce RDS costs.\nWhich combination of steps should the finance team take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "RDS 인스턴스가 실행 중인 계정의 Trusted Advisor 권장 사항을 사용합니다.",
        "B": "통합 결제 계정의 Trusted Advisor 권장 사항을 사용하여 모든 RDS 인스턴스 확인을 동시에 확인합니다.",
        "C": "Amazon RDS 예약 인스턴스 최적화에 대한 Trusted Advisor 검사를 검토합니다.",
        "D": "Amazon RDS 유휴 DB 인스턴스에 대한 Trusted Advisor 검사를 검토합니다.",
        "E": "Amazon Redshift 예약 노드 최적화에 대한 Trusted Advisor 검사를 검토합니다."
      },
      "eng": {
        "A": "Use the Trusted Advisor recommendations from the account where the RDS instances are running.",
        "B": "Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.",
        "C": "Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.",
        "D": "Review the Trusted Advisor check for Amazon RDS Idle DB Instances.",
        "E": "Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99936-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 393,
    "question": {
      "kor": "솔루션 아키텍트가 Policy1과 Policy2라는 두 가지 IAM 정책을 만들었습니다. 두 정책 모두 IAM 그룹에 연결됩니다.\n클라우드 엔지니어가 IAM 그룹에 IAM 사용자로 추가됩니다. 클라우드 엔지니어는 어떤 작업을 수행할 수 있습니까?",
      "eng": "A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.\nA cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?"
    },
    "choices": {
      "kor": {
        "A": "IAM 사용자 삭제",
        "B": "디렉토리 삭제",
        "C": "Amazon EC2 인스턴스 삭제",
        "D": "Amazon CloudWatch Logs에서 로그 삭제"
      },
      "eng": {
        "A": "Deleting IAM users",
        "B": "Deleting directories",
        "C": "Deleting Amazon EC2 instances",
        "D": "Deleting logs from Amazon CloudWatch Logs"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95008-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 401,
    "question": {
      "kor": "다음 IAM 정책은 IAM 그룹에 연결됩니다. 이것은 그룹에 적용되는 유일한 정책입니다.\n그룹 구성원에 대한 이 정책의 유효 IAM 권한은 무엇입니까?",
      "eng": "The following IAM policy is attached to an IAM group. This is the only policy applied to the group.\nWhat are the effective IAM permissions of this policy for group members?"
    },
    "choices": {
      "kor": {
        "A": "그룹 구성원은 us-east-1 지역 내 모든 Amazon EC2 작업이 허용됩니다. 허용 권한 이후의 문은 적용되지 않습니다.",
        "B": "그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인하지 않는 한 us-east-1 리전에서 모든 Amazon EC2 권한이 거부됩니다.",
        "C": "그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인할 때 모든 리전에 대한 ec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 다른 모든 Amazon EC2 작업이 허용됩니다.",
        "D": "그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인한 경우에만 us-east-1 리전에 대한 ec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 us-east-1 리전 내에서 다른 모든 Amazon EC2 작업이 허용됩니다."
      },
      "eng": {
        "A": "Group members are permitted any Amazon EC2 action within the us-east-1 Region. Statements after the Allow permission are not applied.",
        "B": "Group members are denied any Amazon EC2 permissions in the us-east-1 Region unless they are logged in with multi-factor authentication (MFA).",
        "C": "Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for all Regions when logged in with multi-factor authentication (MFA). Group members are permitted any other Amazon EC2 action.",
        "D": "Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for the us-east-1 Region only when logged in with multifactor authentication (MFA). Group members are permitted any other Amazon EC2 action within the us-east-1 Region."
      }
    },
    "category": [
      ""
    ],
    "subcategory": [
      ""
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109286-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 409,
    "question": {
      "kor": "회사에는 온프레미스 파일 시스템이 SFTP를 통해 매일 수신하는 보고서 파일을 분석하는 야간 일괄 처리 루틴이 있습니다. 회사는 솔루션을 AWS 클라우드로 이전하려고 합니다. 솔루션은 가용성과 복원력이 높아야 합니다. 또한 솔루션은 운영 노력을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a nightly batch processing routine that analyzes report files that an on-premises file system receives daily through SFTP. The company wants to move the solution to the AWS Cloud. The solution must be highly available and resilient. The solution also must minimize operational effort.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "SFTP용 AWS 전송 및 스토리지용 Amazon Elastic File System(Amazon EFS) 파일 시스템을 배포합니다. 예약된 조정 정책이 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용하여 배치 작업을 실행합니다.",
        "B": "Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장에는 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하십시오. 최소 인스턴스 수와 원하는 인스턴스 수를 1로 설정한 Auto Scaling 그룹을 사용합니다.",
        "C": "Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장을 위해 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다. 최소 인스턴스 수와 원하는 인스턴스 수를 1로 설정한 Auto Scaling 그룹을 사용합니다.",
        "D": "SFTP용 AWS 전송과 저장용 Amazon S3 버킷을 배포합니다. 처리를 위해 Amazon S3에서 Amazon EC2 인스턴스로 배치 파일을 가져오도록 애플리케이션을 수정합니다. 예약된 조정 정책이 있는 Auto Scaling 그룹의 EC2 인스턴스를 사용하여 일괄 작업을 실행합니다."
      },
      "eng": {
        "A": "Deploy AWS Transfer for SFTP and an Amazon Elastic File System (Amazon EFS) file system for storage. Use an Amazon EC2 instance in an Auto Scaling group with a scheduled scaling policy to run the batch operation.",
        "B": "Deploy an Amazon EC2 instance that runs Linux and an SFTP service. Use an Amazon Elastic Block Store (Amazon EBS) volume for storage. Use an Auto Scaling group with the minimum number of instances and desired number of instances set to 1.",
        "C": "Deploy an Amazon EC2 instance that runs Linux and an SFTP service. Use an Amazon Elastic File System (Amazon EFS) file system for storage. Use an Auto Scaling group with the minimum number of instances and desired number of instances set to 1.",
        "D": "Deploy AWS Transfer for SFTP and an Amazon S3 bucket for storage. Modify the application to pull the batch files from Amazon S3 to an Amazon EC2 instance for processing. Use an EC2 instance in an Auto Scaling group with a scheduled scaling policy to run the batch operation."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132944-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 416,
    "question": {
      "kor": "회사에서 고성능 컴퓨팅 및 인공 지능을 사용하여 사기 방지 및 감지 기술을 개선하려고 합니다. 회사는 가능한 한 빨리 단일 워크로드를 완료하기 위해 분산 처리가 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to use high-performance computing and artificial intelligence to improve its fraud prevention and detection technology. The company requires distributed processing to complete a single workload as quickly as possible.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic Kubernetes Service(Amazon EKS) 및 여러 컨테이너를 사용합니다.",
        "B": "AWS ParallelCluster 및 MPI(Message Passing Interface) 라이브러리를 사용합니다.",
        "C": "Application Load Balancer 및 Amazon EC2 인스턴스를 사용합니다.",
        "D": "AWS Lambda 함수를 사용합니다."
      },
      "eng": {
        "A": "Use Amazon Elastic Kubernetes Service (Amazon EKS) and multiple containers.",
        "B": "Use AWS ParallelCluster and the Message Passing Interface (MPI) libraries.",
        "C": "Use an Application Load Balancer and Amazon EC2 instances.",
        "D": "Use AWS Lambda functions."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 418,
    "question": {
      "kor": "회사는 Amazon RDS DB 인스턴스에서 실행되는 모든 데이터베이스에 대해 새로운 데이터 보존 정책을 구현하고 있습니다. 회사는 최소 2년 동안 일일 백업을 유지해야 합니다. 백업은 일관되고 복원 가능해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?",
      "eng": "A company is implementing new data retention policies for all databases that run on Amazon RDS DB instances. The company must retain daily backups for a minimum period of 2 years. The backups must be consistent and restorable.\nWhich solution should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "RDS 백업을 유지하기 위해 AWS Backup에서 백업 볼트를 생성합니다. 일일 일정과 생성 후 2년의 만료 기간으로 새 백업 계획을 생성합니다. 백업 계획에 RDS DB 인스턴스를 할당 합니다.",
        "B": "일일 스냅샷을 위해 RDS DB 인스턴스의 백업 기간을 구성합니다. 각 RDS DB 인스턴스에 2년의 스냅샷 보존 정책을 할당합니다. Amazon DLM(Amazon Data Lifecycle Manager)을 사용하여 스냅샷 삭제를 예약합니다.",
        "C": "만료 기간이 2년인 Amazon CloudWatch Logs에 자동으로 백업되도록 데이터베이스 트랜잭션 로그를 구성합니다.",
        "D": "AWS Database Migration Service(AWS DMS) 복제 작업을 구성합니다. 복제 인스턴스를 배포하고 변경 데이터 캡처(CDC) 작업을 구성하여 데이터베이스 변경 사항을 대상으로 Amazon S3에 스트리밍합니다. 2년 후 스냅샷을 삭제하도록 S3 수명 주기 정책을 구성합니다."
      },
      "eng": {
        "A": "Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan.",
        "B": "Configure a backup window for the RDS DB instances for daily snapshots. Assign a snapshot retention policy of 2 years to each RDS DB instance. Use Amazon Data Lifecycle Manager (Amazon DLM) to schedule snapshot deletions.",
        "C": "Configure database transaction logs to be automatically backed up to Amazon CloudWatch Logs with an expiration period of 2 years.",
        "D": "Configure an AWS Database Migration Service (AWS DMS) replication task. Deploy a replication instance, and configure a change data capture (CDC) task to stream database changes to Amazon S3 as the target. Configure S3 Lifecycle policies to delete the snapshots after 2 years."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95030-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 421,
    "question": {
      "kor": "회사는 여러 AWS 리전 및 계정에 걸쳐 리소스를 보유하고 있습니다. 새로 고용된 솔루션 설계자는 이전 직원이 리소스 인벤토리에 대한 세부 정보를 제공하지 않은 것을 발견했습니다. 솔루션 설계자는 모든 계정에서 다양한 워크로드의 관계 세부 정보를 구축하고 매핑해야 합니다.\n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has resources across multiple AWS Regions and accounts. A newly hired solutions architect discovers a previous employee did not provide details about the resources inventory. The solutions architect needs to build and map the relationship details of the various workloads across all accounts.\nWhich solution will meet these requirements in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "AWS Systems Manager Inventory를 사용하여 상세 보기 보고서에서 맵 보기를 생성합니다.",
        "B": "AWS Step Functions를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 아키텍처 다이어그램을 수동으로 작성합니다.",
        "C": "Workload Discovery on AWS를 사용하여 워크로드의 아키텍처 다이어그램을 생성합니다.",
        "D": "AWS X-Ray를 사용하여 워크로드 세부 정보를 봅니다. 관계를 사용하여 아키텍처 다이어그램을 구축합니다."
      },
      "eng": {
        "A": "Use AWS Systems Manager Inventory to generate a map view from the detailed view report.",
        "B": "Use AWS Step Functions to collect workload details. Build architecture diagrams of the workloads manually.",
        "C": "Use Workload Discovery on AWS to generate architecture diagrams of the workloads.",
        "D": "Use AWS X-Ray to view the workload details. Build architecture diagrams with relationships."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109433-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 422,
    "question": {
      "kor": "회사에는 트랜잭션 데이터를 처리하는 온프레미스 MySQL 데이터베이스가 있습니다. 회사는 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 마이그레이션된 데이터베이스는 데이터베이스를 사용하는 회사의 애플리케이션과 호환성을 유지해야 합니다. 마이그레이션된 데이터베이스는 또한 수요가 증가하는 기간 동안 자동으로 확장되어야 합니다.\n이러한 요구 사항을 충족하는 마이그레이션 솔루션은 무엇입니까?",
      "eng": "A company has an on-premises MySQL database that handles transactional data. The company is migrating the database to the AWS Cloud. The migrated database must maintain compatibility with the company's applications that use the database. The migrated database also must scale automatically during periods of increased demand.\nWhich migration solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "기본 MySQL 도구를 사용하여 데이터베이스를 MySQL용 Amazon RDS로 마이그레이션합니다. 탄력적 스토리지 확장을 구성합니다.",
        "B": "mysqldump 유틸리티를 사용하여 데이터베이스를 Amazon Redshift로 마이그레이션합니다. Amazon Redshift 클러스터에 대해 Auto Scaling을 켭니다.",
        "C": "AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다. Aurora Auto Scaling을 켭니다.",
        "D": "AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. Auto Scaling 정책을 구성합니다."
      },
      "eng": {
        "A": "Use native MySQL tools to migrate the database to Amazon RDS for MySQL. Configure elastic storage scaling.",
        "B": "Migrate the database to Amazon Redshift by using the mysqldump utility. Turn on Auto Scaling for the Amazon Redshift cluster.",
        "C": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon Aurora. Turn on Aurora Auto Scaling.",
        "D": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon DynamoDB. Configure an Auto Scaling policy."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117025-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 425,
    "question": {
      "kor": "한 회사에서 여러 Microsoft Windows Server 워크로드를 us-west-1 리전에서 실행되는 Amazon EC2 인스턴스로 마이그레이션했습니다. 회사는 필요에 따라 이미지를 생성하기 위해 워크로드를 수동으로 백업합니다.\nus-west-1 리전에서 자연 재해가 발생한 경우 회사는 us-west-2 리전에서 워크로드를 신속하게 복구하기를 원합니다. 회사는 EC2 인스턴스에서 24시간 이상의 데이터 손실을 원하지 않습니다. 회사는 또한 EC2 인스턴스의 모든 백업을 자동화하려고 합니다.\n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company has migrated multiple Microsoft Windows Server workloads to Amazon EC2 instances that run in the us-west-1 Region. The company manually backs up the workloads to create an image as needed.\nIn the event of a natural disaster in the us-west-1 Region, the company wants to recover workloads quickly in the us-west-2 Region. The company wants no more than 24 hours of data loss on the EC2 instances. The company also wants to automate any backups of the EC2 instances.\nWhich solutions will meet these requirements with the LEAST administrative effort? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. 필요에 따라 이미지를 복사합니다.",
        "B": "Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. us-west-2 리전에 대한 복사본을 구성합니다.",
        "C": "AWS Backup을 사용하여 us-west-1 및 us-west-2에 백업 볼트를 생성합니다. 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 백업 데이터를 us-west-2에 복사하기 위해 예약된 작업으로 실행할 AWS Lambda 함수를 생성합니다.",
        "D": "AWS Backup을 사용하여 백업 볼트를 생성합니다. AWS Backup을 사용하여 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 사본의 대상을 us-west-2로 정의 합니다. 하루에 두 번 실행할 백업 일정을 지정합니다.",
        "E": "AWS Backup을 사용하여 백업 볼트를 생성합니다. AWS Backup을 사용하여 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 하루에 두 번 실행할 백업 일정을 지정합니다. 요청 시 us-west-2에 복사합니다."
      },
      "eng": {
        "A": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand.",
        "B": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region.",
        "C": "Create backup vaults in us-west-1 and in us-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2.",
        "D": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily.",
        "E": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109530-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 426,
    "question": {
      "kor": "회사의 규정 준수 팀은 파일 공유를 AWS로 이동해야 합니다. 공유는 Windows Server SMB 파일 공유에서 실행됩니다. 자체 관리형 온프레미스 Active Directory는 파일 및 폴더에 대한 액세스를 제어합니다.\n이 회사는 Windows File Server용 Amazon FSx를 솔루션의 일부로 사용하려고 합니다. 회사는 온프레미스 Active Directory 그룹이 AWS로 이동한 후 FSx for Windows File Server SMB 규정 준수 공유, 폴더 및 파일에 대한 액세스를 제한하는지 확인해야 합니다. 이 회사는 Windows 파일 서버 파일 시스템용 FSx를 만들었습니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company’s compliance team needs to move its file shares to AWS. The shares run on a Windows Server SMB file share. A self-managed on-premises Active Directory controls access to the files and folders.\nThe company wants to use Amazon FSx for Windows File Server as part of the solution. The company must ensure that the on-premises Active Directory groups restrict access to the FSx for Windows File Server SMB compliance shares, folders, and files after the move to AWS. The company has created an\nFSx for Windows File Server file system.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Active Directory에 연결할 Active Directory 커넥터를 만듭니다. Active Directory 그룹을 IAM 그룹에 매핑하여 액세스를 제한합니다.",
        "B": "제한 태그 키와 규정 준수 태그 값을 사용하여 태그를 할당합니다. Active Directory 그룹을 IAM 그룹에 매핑하여 액세스를 제한합니다.",
        "C": "액세스를 제한하기 위해 FSx for Windows File Server에 직접 연결된 IAM 서비스 연결 역할을 생성합니다.",
        "D": "파일 시스템을 Active Directory에 연결하여 액세스를 제한합니다."
      },
      "eng": {
        "A": "Create an Active Directory Connector to connect to the Active Directory. Map the Active Directory groups to IAM groups to restrict access.",
        "B": "Assign a tag with a Restrict tag key and a Compliance tag value. Map the Active Directory groups to IAM groups to restrict access.",
        "C": "Create an IAM service-linked role that is linked directly to FSx for Windows File Server to restrict access.",
        "D": "Join the file system to the Active Directory to restrict access."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95343-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 427,
    "question": {
      "kor": "회사는 AWS 비즈니스 지원 계획에 가입되어 있습니다. 규정상 배포를 진행하기 전에 AWS 인프라 상태를 확인해야 합니다. 회사는 새로운 배포가 시작될 때마다 프로그램적이고 자동화된 방식으로 인프라 상태를 확인할 필요가 있습니다.\n어떤 솔루션이 이러한 요구사항을 충족시킬까요?",
      "eng": "A company is subscribed to the AWS Business Support plan. Compliance rules require the company to check on AWS infrastructure health before deployments can proceed. The company needs a programmatic and automated way to check on infrastructure health at the beginning of new deployments.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "각 배포 시작 시 AWS Trusted Advisor API를 사용하고, API가 문제를 반환하면 모든 새로운 배포를 중지합니다.",
        "B": "각 배포 시작 시 AWS Health API를 사용하고, API가 문제를 반환하면 모든 새로운 배포를 중지합니다.",
        "C": "각 배포 시작 시 AWS Support API를 쿼리하고, API가 열려 있는 문제를 반환하면 모든 새로운 배포를 중지합니다.",
        "D": "각 워크로드에 API 호출을 보내고, API 호출이 실패하면 배포를 중지합니다."
      },
      "eng": {
        "A": "Use the AWS Trusted Advisor API at the start of each deployment. Pause all new deployments if the API returns any issues.",
        "B": "Use the AWS Health API at the start of each deployment. Pause all new deployments if the API returns any issues.",
        "C": "Query the AWS Support API at the start of each deployment. Pause all new deployments if the API returns any open issues.",
        "D": "Send an API call to each workload ahead of deployment. Pause the deployments if the API call fails."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 437,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 애플리케이션에 재해 복구(DR) 솔루션을 구현해야 합니다. DR 솔루션은 RTO(복구 시간 목표)가 4시간 미만이어야 합니다. 또한 DR 솔루션은 정상 작동 중에 가능한 한 적은 AWS 리소스를 사용해야 합니다.\n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an application on Amazon EC2 instances. The company needs to implement a disaster recovery (DR) solution for the application. The DR solution needs to have a recovery time objective (RTO) of less than 4 hours. The DR solution also needs to use the fewest possible AWS resources during normal operations.\nWhich solution will meet these requirements in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI를 보조 AWS 리전에 복사합니다. AWS Lambda 및 사용자 지정 스크립트를 사용하여 보조 리전에서 인프라 배포를 자동화합니다.",
        "B": "Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI를 보조 AWS 리전에 복사합니다. AWS CloudFormation을 사용하여 보조 리전에서 인프라 배포를 자동화합니다.",
        "C": "보조 AWS 리전에서 EC2 인스턴스를 시작합니다. 보조 리전의 EC2 인스턴스를 항상 활성 상태로 유지하십시오.",
        "D": "보조 가용 영역에서 EC2 인스턴스를 시작합니다. 보조 가용 영역의 EC2 인스턴스를 항상 활성 상태로 유지합니다."
      },
      "eng": {
        "A": "Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS Lambda and custom scripts.",
        "B": "Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.",
        "C": "Launch EC2 instances in a secondary AWS Region. Keep the EC2 instances in the secondary Region active at all times.",
        "D": "Launch EC2 instances in a secondary Availability Zone. Keep the EC2 instances in the secondary Availability Zone active at all times."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 450,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 비용에 대해 정기적인 재무 평가를 수행합니다. 회사는 최근 비정상적인 지출을 확인했습니다.\n회사는 비정상적인 지출을 방지하기 위한 솔루션이 필요합니다. 솔루션은 비용을 모니터링하고 비정상적인 지출이 발생할 경우 책임 있는 이해관계자에게 알려야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs its applications on Amazon EC2 instances. The company performs periodic financial assessments of its AWS costs. The company recently identified unusual spending.\nThe company needs a solution to prevent unusual spending. The solution must monitor costs and notify responsible stakeholders in the event of unusual spending.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "지출이 없는 예산을 생성하려면 AWS Budgets 템플릿을 사용하십시오.",
        "B": "AWS Billing and Cost Management 콘솔에서 AWS 비용 이상 탐지 모니터를 생성합니다.",
        "C": "현재 실행 중인 워크로드 가격 세부 정보에 대한 AWS 가격 계산기 추정치를 생성합니다.",
        "D": "Amazon CloudWatch를 사용하여 비용을 모니터링하고 비정상적인 지출을 식별합니다."
      },
      "eng": {
        "A": "Use an AWS Budgets template to create a zero spend budget.",
        "B": "Create an AWS Cost Anomaly Detection monitor in the AWS Billing and Cost Management console.",
        "C": "Create AWS Pricing Calculator estimates for the current running workload pricing details.",
        "D": "Use Amazon CloudWatch to monitor costs and to identify unusual spending."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/129712-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 460,
    "question": {
      "kor": "회사에 TCP 및 UDP 멀티플레이어 게임 기능이 있는 온라인 게임 응용 프로그램이 있습니다. 이 회사는 Amazon Route 53을 사용하여 애플리케이션 트래픽이 서로 다른 AWS 리전에 있는 여러 NLB(Network Load Balancer)를 가리키도록 합니다. 회사는 사용자 증가에 대비하여 애플리케이션 성능을 개선하고 온라인 게임의 지연 시간을 줄여야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an online gaming application that has TCP and UDP multiplayer gaming capabilities. The company uses Amazon Route 53 to point the application traffic to multiple Network Load Balancers (NLBs) in different AWS Regions. The company needs to improve application performance and decrease latency for the online game in preparation for user growth.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "NLB 앞에 Amazon CloudFront 배포를 추가합니다. Cache-Control max-age 매개변수를 늘리십시오.",
        "B": "NLB를 ALB(Application Load Balancer)로 교체합니다. 지연 시간 기반 라우팅을 사용하도록 Route 53을 구성합니다.",
        "C": "NLB 앞에 AWS Global Accelerator를 추가합니다. 올바른 수신기 포트를 사용하도록 Global Accelerator 끝점을 구성합니다.",
        "D": "NLB 뒤에 Amazon API Gateway 엔드포인트를 추가합니다. API 캐싱을 활성화합니다. 다른 단계에 대한 메서드 캐싱을 재정의합니다."
      },
      "eng": {
        "A": "Add an Amazon CloudFront distribution in front of the NLBs. Increase the Cache-Control max-age parameter.",
        "B": "Replace the NLBs with Application Load Balancers (ALBs). Configure Route 53 to use latency-based routing.",
        "C": "Add AWS Global Accelerator in front of the NLBs. Configure a Global Accelerator endpoint to use the correct listener ports.",
        "D": "Add an Amazon API Gateway endpoint behind the NLBs. Enable API caching. Override method caching for the different stages."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/111271-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 462,
    "question": {
      "kor": "회사는 Amazon Elastic Block Store(Amazon EBS)가 지원하는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. EC2 인스턴스는 최신 Amazon Linux 릴리스를 실행합니다. 회사 직원이 25GB 이상의 파일을 저장하고 검색할 때 애플리케이션에 가용성 문제가 발생합니다. 회사에는 EC2 인스턴스 간에 파일을 전송할 필요가 없는 솔루션이 필요합니다. 파일은 여러 EC2 인스턴스와 여러 가용 영역에서 사용할 수 있어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs its applications on Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS). The EC2 instances run the most recent Amazon Linux release. The applications are experiencing availability issues when the company's employees store and retrieve files that are 25 GB or larger. The company needs a solution that does not require the company to transfer files between EC2 instances. The files must be available across many EC2 instances and across multiple Availability Zones.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "모든 파일을 Amazon S3 버킷으로 마이그레이션합니다. 직원에게 S3 버킷의 파일에 액세스하도록 지시합니다.",
        "B": "기존 EBS 볼륨의 스냅샷을 찍습니다. EC2 인스턴스 전반에 걸쳐 스냅샷을 EBS 볼륨으로 탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다.",
        "C": "모든 EC2 인스턴스에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다.",
        "D": "EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 인스턴스 스토어 볼륨을 사용하는 AMI에서 새 EC2 인스턴스를 구성합니다. 직원에게 EC2 인스턴스의 파일에 액세스",
        "E": "하도록 지시합니다."
      },
      "eng": {
        "A": "Migrate all the files to an Amazon S3 bucket. Instruct the employees to access the files from the S3 bucket.",
        "B": "Take a snapshot of the existing EBS volume. Mount the snapshot as an EBS volume across the EC2 instances. Instruct the employees to access the files from the EC2 instances.",
        "C": "Mount an Amazon Elastic File System (Amazon EFS) file system across all the EC2 instances. Instruct the employees to access the files from the EC2 instances.",
        "D": "Create an Amazon Machine Image (AMI) from the EC2 instances. Configure new EC2 instances from the AMI that use an instance store volume. Instruct the employees to access the files from the EC2 instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/137843-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 463,
    "question": {
      "kor": "한 회사가 테스트 환경에서 자사 애플리케이션을 위한 AWS CloudFormation 스택을 사용하려고 합니다. 이 회사는 공개 액세스를 차단하는 Amazon S3 버킷에 CloudFormation 템플릿을 저장하고 있습니다. 회사는 CloudFormation에게 특정 사용자 요청을 기반으로 S3 버킷의 템플릿에 액세스 권한을 부여하려고 합니다. 이 솔루션은 보안 최상의 실천 방법을 준수해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to use an AWS CloudFormation stack for its application in a test environment. The company stores the CloudFormation template in an Amazon S3 bucket that blocks public access. The company wants to grant CloudFormation access to the template in the S3 bucket based on specific user requests to create the test environment. The solution must follow security best practices.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3에 대한 게이트웨이 VPC 엔드포인트를 생성합니다. CloudFormation 스택을 S3 오브젝트 URL을 사용하도록 구성합니다.",
        "B": "Amazon API Gateway REST API를 생성하고 해당 API를 S3 버킷을 대상으로 설정합니다. CloudFormation 스택을 API Gateway URL을 사용하도록 구성합니다.",
        "C": "템플릿 오브젝트에 대한 사전 서명된 URL을 생성합니다. CloudFormation 스택을 사전 서명된 URL을 사용하도록 구성합니다.",
        "D": "S3 버킷에서 템플릿 오브젝트에 대한 공개 액세스를 허용합니다. 테스트 환경이 생성된 후에는 공개 액세스를 차단합니다."
      },
      "eng": {
        "A": "Create a gateway VPC endpoint for Amazon S3. Configure the CloudFormation stack to use the S3 object URL.",
        "B": "Create an Amazon API Gateway REST API that has the S3 bucket as the target. Configure the CloudFormation stack to use the API Gateway URL.",
        "C": "Create a presigned URL for the template object. Configure the CloudFormation stack to use the presigned URL.",
        "D": "Allow public access to the template object in the S3 bucket. Block public access after the test environment is created."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 465,
    "question": {
      "kor": "솔루션 설계자가 새 AWS 계정을 생성했으며 AWS 계정 루트 사용자 액세스를 보호해야 합니다.\n어떤 작업 조합이 이를 달성합니까? (두 가지를 선택하세요.)",
      "eng": "A solutions architect has created a new AWS account and must secure AWS account root user access.\nWhich combination of actions will accomplish this? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "루트 사용자가 강력한 암호를 사용하는지 확인하십시오.",
        "B": "루트 사용자에 대한 다단계 인증을 활성화합니다.",
        "C": "암호화된 Amazon S3 버킷에 루트 사용자 액세스 키를 저장합니다.",
        "D": "관리 권한이 포함된 그룹에 루트 사용자를 추가합니다.",
        "E": "인라인 정책 문서를 사용하여 루트 사용자에게 필요한 권한을 적용합니다."
      },
      "eng": {
        "A": "Ensure the root user uses a strong password.",
        "B": "Enable multi-factor authentication to the root user.",
        "C": "Store root user access keys in an encrypted Amazon S3 bucket.",
        "D": "Add the root user to a group containing administrative permissions.",
        "E": "Apply the required permissions to the root user with an inline policy document."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95084-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 466,
    "question": {
      "kor": "병원은 환자 기록을 Amazon S3 버킷에 저장해야 합니다. 병원의 규정 준수 팀은 모든 PHI(보호된 건강 정보)가 전송 및 저장 중에 암호화되도록 해야 합니다. 규정 준수 팀은 미사용 데이터에 대한 암호화 키를 관리해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A hospital needs to store patient records in an Amazon S3 bucket. The hospital’s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Certificate Manager(ACM)에서 퍼블릭 SSL/TLS 인증서를 생성합니다. 인증서를 Amazon S3와 연결합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 기본 암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다.",
        "B": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용합니다. S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 기본 암호화를 구성합니다. SSE-S3 키를 관리할 규정 준수 팀을 할당합니다.",
        "C": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 버킷에 대한 기본 암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다.",
        "D": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용합니다. Amazon Macie를 사용하여 Amazon S3에 저장된 민감한 데이터를 보호하십시오. Macie를 관리할 규정 준수 팀을 지정합니다."
      },
      "eng": {
        "A": "Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.",
        "B": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.",
        "C": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.",
        "D": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "encryption in flight"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100232-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 476,
    "question": {
      "kor": "회사는 2개의 가용 영역에 걸쳐 VPC에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다. 인스턴스는 계층적 디렉터리 구조를 사용하는 애플리케이션을 호스팅합니다. 애플리케이션은 공유 스토리지에서 동시에 빠르게 읽고 쓸 수 있어야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company runs multiple Amazon EC2 Linux instances in a VPC across two Availability Zones. The instances host applications that use a hierarchical directory structure. The applications need to read and write rapidly and concurrently to shared storage.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 버킷을 생성합니다. VPC의 모든 EC2 인스턴스에서 액세스를 허용합니다.",
        "B": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2 인스턴스에서 EFS 파일 시스템을 탑재합니다.",
        "C": "프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 시스템을 생성합니다. EBS 볼륨을 모든 EC2 인스턴스에 연결합니다.",
        "D": "각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 시스템을 만듭니다. 여러 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다."
      },
      "eng": {
        "A": "Create an Amazon S3 bucket. Allow access from all the EC2 instances in the VPC.",
        "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system from each EC2 instance.",
        "C": "Create a file system on a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume. Attach the EBS volume to all the EC2 instances.",
        "D": "Create file systems on Amazon Elastic Block Store (Amazon EBS) volumes that are attached to each EC2 instance. Synchronize the EBS volumes across the different EC2 instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/116902-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 487,
    "question": {
      "kor": "회사에는 AWS에서 실행되는 인기 있는 게임 플랫폼이 있습니다. 대기 시간은 사용자 경험에 영향을 미치고 일부 플레이어에게 부당한 이점을 제공할 수 있기 때문에 애플리케이션은 대기 시간에 민감합니다. 애플리케이션은 모든 AWS 리전에 배포됩니다. Application Load Balancer(ALB) 뒤에 구성된 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스에서 실행됩니다. 솔루션 설계자는 애플리케이션의 상태를 모니터링하고 트래픽을 정상 엔드포인트로 리디렉션하는 메커니즘을 구현해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region. It runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect traffic to healthy endpoints.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Global Accelerator에서 액셀러레이터를 구성합니다. 애플리케이션이 청취하는 포트에 대한 리스너를 추가하고 각 리전의 리전 엔드포인트에 연결합니다. ALB를 엔드포인트로 추가하십시오.",
        "B": "Amazon CloudFront 배포를 생성하고 ALB를 원본 서버로 지정합니다. 원본 캐시 헤더를 사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오.",
        "C": "Amazon CloudFront 배포를 생성하고 Amazon S3를 원본 서버로 지정합니다. 원본 캐시 헤더를 사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오.",
        "D": "애플리케이션의 데이터 저장소 역할을 하도록 Amazon DynamoDB 데이터베이스를 구성합니다. 애플리케이션 데이터를 호스팅하는 DynamoDB의 인 메모리 캐시 역할을 할 DynamoDB Accelerator(DAX) 클러스터를 생성합니다."
      },
      "eng": {
        "A": "Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.",
        "B": "Create an Amazon CloudFront distribution and specify the ALB as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.",
        "C": "Create an Amazon CloudFront distribution and specify Amazon S3 as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.",
        "D": "Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the inmemory cache for DynamoDB hosting the application data."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95014-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 490,
    "question": {
      "kor": "회사에서 Amazon EC2 데이터 및 여러 Amazon S3 버킷에 대한 백업 전략을 구현하려고 합니다. 규정 요구 사항으로 인해 회사는 특정 기간 동안 백업 파일을 보존해야 합니다. 회사는 보유기간 동안 파일을 변조해서는 안됩니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to implement a backup strategy for Amazon EC2 data and multiple Amazon S3 buckets. Because of regulatory requirements, the company must retain backup files for a specific time period. The company must not alter the files for the duration of the retention period.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Backup을 사용하여 거버넌스 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. 필요한 백업 계획을 생성합니다.",
        "B": "Amazon Data Lifecycle Manager를 사용하여 필요한 자동 스냅샷 정책을 생성합니다.",
        "C": "Amazon S3 파일 게이트웨이를 사용하여 백업을 생성합니다. 적절한 S3 수명 주기 관리를 구성합니다.",
        "D": "AWS Backup을 사용하여 규정 준수 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. 필요한 백업 계획을 생성합니다."
      },
      "eng": {
        "A": "Use AWS Backup to create a backup vault that has a vault lock in governance mode. Create the required backup plan.",
        "B": "Use Amazon Data Lifecycle Manager to create the required automated snapshot policy.",
        "C": "Use Amazon S3 File Gateway to create the backup. Configure the appropriate S3 Lifecycle management.",
        "D": "Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109410-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 493,
    "question": {
      "kor": "한 회사가 AWS에 최신 제품을 배포했습니다. 제품은 Network Load Balancer 뒤의 Auto Scaling 그룹에서 실행됩니다. 회사는 제품의 객체를 Amazon S3 버킷에 저장합니다.\n이 회사는 최근 자사 시스템에 대한 악의적인 공격을 경험했습니다. 회사에는 AWS 계정의 악의적인 활동, 워크로드 및 S3 버킷에 대한 액세스 패턴을 지속적으로 모니터링하는 솔루션이 필요합니다. 또한 솔루션은 의심스러운 활동을 보고하고 대시보드에 정보를 표시해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has deployed its newest product on AWS. The product runs in an Auto Scaling group behind a Network Load Balancer. The company stores the product’s objects in an Amazon S3 bucket.\nThe company recently experienced malicious attacks against its systems. The company needs a solution that continuously monitors for malicious activity in the AWS account, workloads, and access patterns to the S3 bucket. The solution must also report suspicious activity and display the information on a dashboard.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "결과를 모니터링하고 AWS Config에 보고하도록 Amazon Macie를 구성합니다.",
        "B": "결과를 모니터링하고 AWS CloudTrail에 보고하도록 Amazon Inspector를 구성합니다.",
        "C": "결과를 모니터링하고 AWS Security Hub에 보고하도록 Amazon GuardDuty를 구성합니다.",
        "D": "결과를 모니터링하고 Amazon EventBridge에 보고하도록 AWS Config를 구성합니다."
      },
      "eng": {
        "A": "Configure Amazon Macie to monitor and report findings to AWS Config.",
        "B": "Configure Amazon Inspector to monitor and report findings to AWS CloudTrail.",
        "C": "Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub.",
        "D": "Configure AWS Config to monitor and report findings to Amazon EventBridge."
      }
    },
    "category": [
      "GuardDuty"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121177-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 500,
    "question": {
      "kor": "회사에서 엔지니어 팀을 위해 개별 AWS 계정을 실험하려고 합니다. 회사는 지정된 달의 Amazon EC2 인스턴스 사용량이 각 계정의 특정 임계값을 초과하는 즉시 알림을 받기를 원합니다.\n이 요구 사항을 가장 비용 효율적으로 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?",
      "eng": "A company wants to experiment with individual AWS accounts for its engineer team. The company wants to be notified as soon as the Amazon EC2 instance usage for a given month exceeds a specific threshold for each account.\nWhat should a solutions architect do to meet this requirement MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Cost Explorer를 사용하여 서비스별 비용에 대한 일일 보고서를 생성합니다. EC2 인스턴스별로 보고서를 필터링합니다. 임계값을 초과하면 Amazon Simple Email Service(Amazon SES) 알림을 보내도록 Cost Explorer를 구성합니다.",
        "B": "Cost Explorer를 사용하여 서비스별 월별 비용 보고서를 생성합니다. EC2 인스턴스별로 보고서를 필터링합니다. 임계값을 초과하면 Amazon Simple Email Service(Amazon SES) 알림을 보내도록 Cost Explorer를 구성합니다.",
        "C": "AWS 예산을 사용하여 각 계정에 대한 비용 예산을 생성합니다. 기간을 매월로 설정합니다. 범위를 EC2 인스턴스로 설정합니다. 예산에 대한 경고 임계값을 설정합니다. 임계값 초과 시 알림을 받도록 Amazon Simple Notification Service(Amazon SNS) 주제를 구성합니다.",
        "D": "AWS 비용 및 사용 보고서를 사용하여 시간 단위로 보고서를 생성합니다. 보고서 데이터를 Amazon Athena와 통합합니다. Amazon EventBridge를 사용하여 Athena 쿼리를 예약 합니다. 임계값 초과 시 알림을 받도록 Amazon Simple Notification Service(Amazon SNS) 주제를 구성합니다."
      },
      "eng": {
        "A": "Use Cost Explorer to create a daily report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.",
        "B": "Use Cost Explorer to create a monthly report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.",
        "C": "Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.",
        "D": "Use AWS Cost and Usage Reports to create a report with hourly granularity. Integrate the report data with Amazon Athena. Use Amazon EventBridge to schedule an Athena query. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/94996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 503,
    "question": {
      "kor": "한 회사에서 온라인 멀티플레이어 게임용 네트워크를 설계하고 있습니다. 이 게임은 UDP 네트워킹 프로토콜을 사용하며 8개의 AWS 리전에 배포됩니다. 네트워크 아키텍처는 최종 사용자에게 고품질 게임 경험을 제공하기 위해 대기 시간과 패킷 손실을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS\nRegions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "각 리전에서 전송 게이트웨이를 설정합니다. 각 전송 게이트웨이 간에 리전 간 피어링 연결을 생성합니다.",
        "B": "각 리전에서 UDP 리스너 및 엔드포인트 그룹으로 AWS Global Accelerator를 설정합니다.",
        "C": "UDP를 켠 상태에서 Amazon CloudFront를 설정합니다. 각 리전에서 오리진을 구성합니다.",
        "D": "각 지역 간에 VPC 피어링 메시를 설정합니다. 각 VPC에 대해 UDP를 켭니다."
      },
      "eng": {
        "A": "Setup a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.",
        "B": "Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.",
        "C": "Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.",
        "D": "Set up a VPC peering mesh between each Region. Turn on UDP for each VPC."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100197-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 505,
    "question": {
      "kor": "회사에서 모바일 앱 사용자를 대상으로 하는 마케팅 커뮤니케이션 서비스를 개발하고 있습니다. 회사는 SMS(Short Message Service)를 통해 사용자에게 확인 메시지를 보내야 합니다.\n사용자는 SMS 메시지에 회신할 수 있어야 합니다. 회사는 분석을 위해 응답을 1년 동안 저장해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is developing a marketing communications service that targets mobile app users. The company needs to send confirmation messages with Short\nMessage Service (SMS) to its users. The users must be able to reply to the SMS messages. The company must store the responses for a year for analysis.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Connect 통화 흐름을 생성하여 SMS 메시지를 보냅니다. AWS Lambda를 사용하여 응답을 처리합니다.",
        "B": "Amazon Pinpoint 여정을 구축하십시오. 분석 및 보관을 위해 이벤트를 Amazon Kinesis 데이터 스트림으로 보내도록 Amazon Pinpoint를 구성합니다.",
        "C": "Amazon Simple Queue Service(Amazon SQS)를 사용하여 SMS 메시지를 배포합니다. AWS Lambda를 사용하여 응답을 처리합니다.",
        "D": "Amazon Simple Notification Service(Amazon SNS) FIFO 주제를 생성합니다. 분석 및 보관을 위해 Amazon Kinesis 데이터 스트림을 SNS 주제에 구독합니다."
      },
      "eng": {
        "A": "Create an Amazon Connect contact flow to send the SMS messages. Use AWS Lambda to process the responses.",
        "B": "Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.",
        "C": "Use Amazon Simple Queue Service (Amazon SQS) to distribute the SMS messages. Use AWS Lambda to process the responses.",
        "D": "Create an Amazon Simple Notification Service (Amazon SNS) FIFO topic. Subscribe an Amazon Kinesis data stream to the SNS topic for analysis and archiving."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89080-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 510,
    "question": {
      "kor": "회사는 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 애플리케이션을 실행합니다. 애플리케이션에는 고객을 관리하고 주문하는 마이크로서비스가 포함되어 있습니다. 회사는 들어오는 요청을 적절한 마이크로서비스로 라우팅해야 합니다.\n이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs a container application by using Amazon Elastic Kubernetes Service (Amazon EKS). The application includes microservices that manage customers and place orders. The company needs to route incoming requests to the appropriate microservices.\nWhich solution will meet this requirement MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "AWS 로드 밸런서 컨트롤러를 사용하여 Network Load Balancer를 프로비저닝하십시오.",
        "B": "AWS Load Balancer Controller를 사용하여 Application Load Balancer를 프로비저닝합니다.",
        "C": "AWS Lambda 함수를 사용하여 요청을 Amazon EKS에 연결합니다.",
        "D": "Amazon API Gateway를 사용하여 요청을 Amazon EKS에 연결합니다."
      },
      "eng": {
        "A": "Use the AWS Load Balancer Controller to provision a Network Load Balancer.",
        "B": "Use the AWS Load Balancer Controller to provision an Application Load Balancer.",
        "C": "Use an AWS Lambda function to connect the requests to Amazon EKS.",
        "D": "Use Amazon API Gateway to connect the requests to Amazon EKS."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/119574-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 516,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스를 사용하여 내부 시스템을 호스팅합니다. 배포 작업의 일부로 관리자는 AWS CLI를 사용하여 EC2 인스턴스를 종료하려고 합니다. 그러나 관리자는 403(액세스 거부) 오류 메시지를 받습니다.\n관리자는 다음 IAM 정책이 연결된 IAM 역할을 사용하고 있습니다.\n실패한 요청의 원인은 무엇입니까?",
      "eng": "A company uses Amazon EC2 instances to host its internal systems. As part of a deployment operation, an administrator tries to use the AWS CLI to terminate an EC2 instance. However, the administrator receives a 403 (Access Denied) error message.\nThe administrator is using an IAM role that has the following IAM policy attached:\nWhat is the cause of the unsuccessful request?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스에는 Deny 문이 포함된 리소스 기반 정책이 있습니다.",
        "B": "정책 설명에 주체가 지정되지 않았습니다.",
        "C": "\"Action\" 필드는 EC2 인스턴스를 종료하는 데 필요한 조치를 부여하지 않습니다.",
        "D": "EC2 인스턴스 종료 요청은 CIDR 블록 192.0.2.0/24 또는 203.0.113.0/24에서 시작되지 않습니다."
      },
      "eng": {
        "A": "The EC2 instance has a resource-based policy with a Deny statement.",
        "B": "The principal has not been specified in the policy statement.",
        "C": "The \"Action\" field does not grant the actions that are required to terminate the EC2 instance.",
        "D": "The request to terminate the EC2 instance does not originate from the CIDR blocks 192.0.2.0/24 or 203.0.113.0/24."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109727-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 522,
    "question": {
      "kor": "한 회사에서 최근 3계층 애플리케이션을 VPC로 마이그레이션하는 것을 검토하고 있습니다. 보안 팀은 최소 권한 원칙이 애플리케이션 계층 간의 Amazon EC2 보안 그룹 수신 및 송신 규칙에 적용되지 않는다는 사실을 발견했습니다.\n솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까?",
      "eng": "A company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.\nWhat should a solutions architect do to correct this issue?"
    },
    "choices": {
      "kor": {
        "A": "인스턴스 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
        "B": "보안 그룹 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
        "C": "VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
        "D": "서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다."
      },
      "eng": {
        "A": "Create security group rules using the instance ID as the source or destination.",
        "B": "Create security group rules using the security group ID as the source or destination.",
        "C": "Create security group rules using the VPC CIDR blocks as the source or destination.",
        "D": "Create security group rules using the subnet CIDR blocks as the source or destination."
      }
    },
    "category": [
      "Security Group"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95009-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 526,
    "question": {
      "kor": "그룹에는 Amazon S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 수 있는 권한이 필요합니다. 관리자는 버킷에 대한 액세스 권한을 제공하기 위해 다음 IAM 정책을 생성하고 해당 정책을 그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. 회사는 최소 권한 액세스 규칙을 따릅니다.\n버킷 액세스를 수정하기 위해 솔루션 설계자가 정책에 추가해야 하는 설명은 무엇입니까?",
      "eng": "A group requires permissions to list an Amazon S3 bucket and delete objects from that bucket. An administrator has created the following IAM policy to provide access to the bucket and applied that policy to the group. The group is not able to delete objects in the bucket. The company follows least-privilege access rules.\nWhich statement should a solutions architect add to the policy to correct bucket access?"
    },
    "choices": {
      "kor": {
        "A": "",
        "B": "",
        "C": "",
        "D": ""
      },
      "eng": {
        "A": "",
        "B": "",
        "C": "",
        "D": ""
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 540,
    "question": {
      "kor": "한 회사에서 MySQL용 Amazon RDS에 데이터베이스를 배포했습니다. 트랜잭션 증가로 인해 데이터베이스 지원 팀은 DB 인스턴스에 대한 느린 읽기를 보고하고 있으며 읽기 전용 복제본을 추가할 것을 권장합니다.\n이 변경 사항을 구현하기 전에 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company has deployed a database in Amazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding a read replica.\nWhich combination of actions should a solutions architect take before implementing this change? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "RDS 기본 노드에서 binlog 복제를 활성화합니다.",
        "B": "원본 DB 인스턴스의 장애 조치 우선 순위를 선택합니다.",
        "C": "원본 DB 인스턴스에서 장기 실행 트랜잭션이 완료되도록 허용합니다.",
        "D": "글로벌 테이블을 생성하고 테이블을 사용할 수 있는 AWS 리전을 지정합니다.",
        "E": "백업 보존 기간을 0 이외의 값으로 설정하여 원본 인스턴스에서 자동 백업을 활성화합니다."
      },
      "eng": {
        "A": "Enable binlog replication on the RDS primary node.",
        "B": "Choose a failover priority for the source DB instance.",
        "C": "Allow long-running transactions to complete on the source DB instance.",
        "D": "Create a global table and specify the AWS Regions where the table will be available.",
        "E": "Enable automatic backups on the source instance by setting the backup retention period to a value other than 0."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95004-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 545,
    "question": {
      "kor": "회사의 인프라는 단일 AWS 리전에 있는 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성됩니다. 회사는 별도의 리전에 데이터를 백업하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company’s infrastructure consists of Amazon EC2 instances and an Amazon RDS DB instance in a single AWS Region. The company wants to back up its data in a separate Region.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Backup을 사용하여 EC2 백업과 RDS 백업을 별도의 리전에 복사합니다.",
        "B": "Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EC2 백업 및 RDS 백업을 별도의 리전에 복사합니다.",
        "C": "EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 별도의 리전에 복사합니다. 별도의 리전에서 RDS DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다.",
        "D": "Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. EBS 스냅샷을 별도의 리전에 복사합니다. RDS 스냅샷을 생성합니다. RDS 스냅샷을 Amazon S3로 내보냅니다. S3 CRR(Cross-Region Replication)을 별도의 리전에 구성합니다."
      },
      "eng": {
        "A": "Use AWS Backup to copy EC2 backups and RDS backups to the separate Region.",
        "B": "Use Amazon Data Lifecycle Manager (Amazon DLM) to copy EC2 backups and RDS backups to the separate Region.",
        "C": "Create Amazon Machine Images (AMIs) of the EC2 instances. Copy the AMIs to the separate Region. Create a read replica for the RDS DB instance in the separate Region.",
        "D": "Create Amazon Elastic Block Store (Amazon EBS) snapshots. Copy the EBS snapshots to the separate Region. Create RDS snapshots. Export the RDS snapshots to Amazon S3. Configure S3 Cross-Region Replication (CRR) to the separate Region."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87639-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 550,
    "question": {
      "kor": "회사의 보고 시스템은 매일 수백 개의 .csv 파일을 Amazon S3 버킷에 전달합니다. 회사는 이러한 파일을 Apache Parquet 형식으로 변환하고 변환된 데이터 버킷에 파일을 저장해야 합니다.\n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company’s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket.\nWhich solution will meet these requirements with the LEAST development effort?"
    },
    "choices": {
      "kor": {
        "A": "Apache Spark가 설치된 Amazon EMR 클러스터를 생성합니다. 데이터를 변환하는 Spark 애플리케이션을 작성합니다. EMRFS(EMR 파일 시스템)를 사용하여 변환된 데이터 버킷에 파일을 씁니다.",
        "B": "AWS Glue 크롤러를 생성하여 데이터를 검색합니다. AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성하여 데이터를 변환합니다. 출력 단계에서 변환된 데이터 버킷을 지정합니다.",
        "C": "AWS Batch를 사용하여 Bash 구문으로 작업 정의를 생성하여 데이터를 변환하고 데이터를 변환된 데이터 버킷으로 출력합니다. 작업 정의를 사용하여 작업을 제출합니다. 어레이 작업을 작업 유형으로 지정합니다.",
        "D": "데이터를 변환하고 변환된 데이터 버킷으로 데이터를 출력하는 AWS Lambda 함수를 생성합니다. S3 버킷에 대한 이벤트 알림을 구성합니다. 이벤트 알림의 대상으로 Lambda 함수를 지정합니다."
      },
      "eng": {
        "A": "Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.",
        "B": "Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.",
        "C": "Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type.",
        "D": "Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95154-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 552,
    "question": {
      "kor": "회사에는 AWS Organizations 조직의 일부로 5개의 조직 단위(OU)가 있습니다. 각 OU는 회사가 소유한 5개 비즈니스와 연관되어 있습니다. 회사의 연구개발(R&D) 사업이 회사에서 분리되어 자체 조직이 필요할 것입니다. 솔루션 설계자는 이 목적을 위해 별도의 새 관리 계정을 생성합니다.\n솔루션 설계자는 새 마스터 계정에서 다음에 무엇을 수행해야 합니까?",
      "eng": "A company has five organizational units (OUs) as part of its organization in AWS Organizations. Each OU correlates to the five businesses that the company owns. The company's research and development (R&D) business is separating from the company and will need its own organization. A solutions architect creates a separate new management account for this purpose.\nWhat should the solutions architect do next in the new management account?"
    },
    "choices": {
      "kor": {
        "A": "전환하는 동안 R&D AWS 계정이 두 조직의 일부가 되도록 하십시오.",
        "B": "R&D AWS 계정이 이전 조직을 떠난 후 R&D AWS 계정을 새 조직의 일부로 초대합니다.",
        "C": "새 조직에 새 R&D AWS 계정을 생성합니다. 이전 R&D AWS 계정의 리소스를 새 R&D AWS 계정으로 마이그레이션합니다.",
        "D": "R&D AWS 계정이 새 조직에 가입하도록 합니다. 새 마스터 계정을 이전 조직의 구성원으로 만드세요."
      },
      "eng": {
        "A": "Have the R&D AWS account be part of both organizations during the transition.",
        "B": "Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.",
        "C": "Create a new R&D AWS account in the new organization. Migrate resources from the prior R&D AWS account to the new R&D AWS account.",
        "D": "Have the R&D AWS account join the new organization. Make the new management account a member of the prior organization."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/119645-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 553,
    "question": {
      "kor": "회사에는 다양한 AWS 리전의 여러 AWS 계정에 분산된 프로덕션 워크로드가 있습니다. 이 회사는 AWS Cost Explorer를 사용하여 비용과 사용량을 지속적으로 모니터링합니다. 회사는 워크로드의 비용 및 사용 지출이 비정상적일 때 알림을 받기를 원합니다.\n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2개 선택)",
      "eng": "A company has a production workload that is spread across different AWS accounts in various AWS Regions. The company uses AWS Cost Explorer to continuously monitor costs and usage. The company wants to receive notifications when the cost and usage spending of the workload is unusual.\nWhich combination of steps will meet these requirements? (Select TWO.)"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS Cost Management 콘솔의 Cost Explorer를 사용하여 연결된 계정 예산을 생성합니다.",
        "B": "프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS Cost Management 콘솔의 AWS Cost Anomaly Detection을 사용하여 연결된 계정 모니터를 생성합니다.",
        "C": "프로덕션 워크로드가 실행 중인 AWS 계정에서 AWS 비용 관리 콘솔의 비용 이상 탐지를 사용하여 비용 및 사용 보고서를 생성합니다.",
        "D": "보고서를 작성하고 이메일 메시지를 보내 매주 회사에 알립니다.",
        "E": "필요한 임계값으로 구독을 생성하고 주간 요약을 사용하여 회사에 알립니다."
      },
      "eng": {
        "A": "In the AWS accounts where the production workload is running, create a linked account budget by using Cost Explorer in the AWS Cost Management console.",
        "B": "In the AWS accounts where the production workload is running, create a linked account monitor by using AWS Cost Anomaly Detection in the AWS Cost Management console.",
        "C": "In the AWS accounts where the production workload is running, create a Cost and Usage Report by using Cost Anomaly Detection in the AWS Cost Management console.",
        "D": "Create a report and send email messages to notify the company on a weekly basis.",
        "E": "Create a subscription with the required threshold and notify the company by using weekly summaries."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 554,
    "question": {
      "kor": "회사에서 필요한 인프라를 수동으로 프로비저닝하여 새 웹 사이트의 인프라 프로토타입을 만들고 있습니다. 이 인프라에는 Auto Scaling 그룹, Application Load Balancer 및 Amazon RDS 데이터베이스가 포함됩니다. 구성이 철저히 검증된 후 회사는 자동화된 방식으로 두 가용 영역에서 개발 및 프로덕션 사용을 위한 인프라를 즉시 배포할 수 있는 기능을 원합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company is making a prototype of the infrastructure for its new website by manually provisioning the necessary infrastructure. This infrastructure includes an Auto Scaling group, an Application Load Balancer, and an Amazon RDS database. After the configuration has been thoroughly validated, the company wants the capability to immediately deploy the infrastructure for development and production use in two Availability Zones in an automated fashion.\nWhat should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Systems Manager를 사용하여 두 가용 영역에서 프로토타입 인프라를 복제하고 프로비저닝합니다.",
        "B": "프로토타입 인프라를 가이드로 사용하여 인프라를 템플릿으로 정의합니다. AWS CloudFormation으로 인프라를 배포하십시오.",
        "C": "AWS Config를 사용하여 프로토타입 인프라에서 사용되는 리소스 인벤토리를 기록합니다. AWS Config를 사용하여 프로토타입 인프라를 두 개의 가용 영역에 배포합니다.",
        "D": "AWS Elastic Beanstalk를 사용하고 프로토타입 인프라에 대한 자동 참조를 사용하도록 구성하여 2개의 가용 영역에 새 환경을 자동으로 배포합니다."
      },
      "eng": {
        "A": "Use AWS Systems Manager to replicate and provision the prototype infrastructure in two Availability Zones.",
        "B": "Define the infrastructure as a template by using the prototype infrastructure as a guide. Deploy the infrastructure with AWS CloudFormation.",
        "C": "Use AWS Config to record the inventory of resources that are used in the prototype infrastructure. Use AWS Config to deploy the prototype infrastructure into two Availability Zones.",
        "D": "Use AWS Elastic Beanstalk and configure it to use an automated reference to the prototype infrastructure to automatically deploy new environments in two Availability Zones."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109461-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 568,
    "question": {
      "kor": "한 회사가 거의 실시간으로 스트리밍 데이터를 처리하는 애플리케이션을 배포하고 있습니다. 회사는 워크로드에 Amazon EC2 인스턴스를 사용할 계획입니다. 네트워크 아키텍처는 노드 간 가능한 최저 대기 시간을 제공하도록 구성 가능해야 합니다.\n이러한 요구 사항을 충족하는 네트워크 솔루션 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company is deploying an application that processes streaming data in near-real time. The company plans to use Amazon EC2 instances for the workload.\nThe network architecture must be configurable to provide the lowest possible latency between nodes.\nWhich combination of network solutions will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "각 EC2 인스턴스에서 향상된 네트워킹을 활성화하고 구성합니다.",
        "B": "EC2 인스턴스를 별도의 계정으로 그룹화합니다.",
        "C": "클러스터 배치 그룹에서 EC2 인스턴스를 실행합니다.",
        "D": "각 EC2 인스턴스에 여러 탄력적 네트워크 인터페이스를 연결합니다.",
        "E": "Amazon Elastic Block Store(Amazon EBS) 최적화 인스턴스 유형을 사용합니다."
      },
      "eng": {
        "A": "Enable and configure enhanced networking on each EC2 instance.",
        "B": "Group the EC2 instances in separate accounts.",
        "C": "Run the EC2 instances in a cluster placement group.",
        "D": "Attach multiple elastic network interfaces to each EC2 instance.",
        "E": "Use Amazon Elastic Block Store (Amazon EBS) optimized instance types."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132936-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 576,
    "question": {
      "kor": "회사는 AWS Organizations를 사용하여 여러 AWS 계정 내에서 워크로드를 실행합니다. 태깅 정책은 회사에서 태그를 생성할 때 부서 태그를 AWS 리소스에 추가합니다.\n회계 팀은 Amazon EC2 소비에 대한 지출을 결정해야 합니다. 회계 팀은 AWS 계정과 관계없이 비용을 담당하는 부서를 결정해야 합니다. 회계 팀은 조직 내 모든 AWS 계정에 대해 AWS Cost Explorer에 액세스할 수 있으며 Cost Explorer의 모든 보고서에 액세스해야 합니다.\n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses AWS Organizations to run workloads within multiple AWS accounts. A tagging policy adds department tags to AWS resources when the company creates tags.\nAn accounting team needs to determine spending on Amazon EC2 consumption. The accounting team must determine which departments are responsible for the costs regardless ofAWS account. The accounting team has access to AWS Cost Explorer for all AWS accounts within the organization and needs to access all reports from Cost Explorer.\nWhich solution meets these requirements in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "조직 관리 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2별로 필터링합니다.",
        "B": "Organizations 마스터 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2별로 필터링합니다.",
        "C": "조직 회원 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2별로 필터링합니다.",
        "D": "Organizations 회원 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2별로 필터링합니다."
      },
      "eng": {
        "A": "From the Organizations management account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.",
        "B": "From the Organizations management account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.",
        "C": "From the Organizations member account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, and filter by EC2.",
        "D": "From the Organizations member account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109440-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 586,
    "question": {
      "kor": "금융회사는 매우 민감한 데이터를 처리해야 합니다. 회사는 Amazon S3 버킷에 데이터를 저장합니다. 회사는 데이터가 전송 중이거나 저장되어 있을 때 암호화되었는지 확인해야 합니다. 회사는 AWS 클라우드 외부의 암호화 키를 관리해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A financial company needs to handle highly sensitive data. The company will store the data in an Amazon S3 bucket. The company needs to ensure that the data is encrypted in transit and at rest. The company must manage the encryption keys outside the AWS Cloud.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하는 서버 측 암호화(SSE)로 S3 버킷의 데이터를 암호화합니다.",
        "B": "AWS Key Management Service(AWS KMS) AWS 관리형 키를 사용하는 서버 측 암호화(SSE)로 S3 버킷의 데이터를 암호화합니다.",
        "C": "기본 서버 측 암호화(SSE)를 사용하여 S3 버킷의 데이터를 암호화합니다.",
        "D": "S3 버킷에 데이터를 저장하기 전에 회사 데이터 센터의 데이터를 암호화하십시오."
      },
      "eng": {
        "A": "Encrypt the data in the S3 bucket with server-side encryption (SSE) that uses an AWS Key Management Service (AWS KMS) customer managed key.",
        "B": "Encrypt the data in the S3 bucket with server-side encryption (SSE) that uses an AWS Key Management Service (AWS KMS) AWS managed key.",
        "C": "Encrypt the data in the S3 bucket with the default server-side encryption (SSE).",
        "D": "Encrypt the data at the company's data center before storing the data in the S3 bucket."
      }
    },
    "category": [
      "Encryption"
    ],
    "subcategory": [
      "encryption at rest",
      "encryption in flight"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135259-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 590,
    "question": {
      "kor": "분석 회사는 Amazon VPC를 사용하여 다중 계층 서비스를 실행합니다. 회사는 RESTful API를 사용하여 수백만 명의 사용자에게 웹 분석 서비스를 제공하려고 합니다. API에 액세스하려면 인증 서비스를 사용하여 사용자를 확인해야 합니다.\n가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "An analytics company uses Amazon VPC to run its multi-tier services. The company wants to use RESTful APIs to offer a web analytics service to millions of users. Users must be verified by using an authentication service to access the APIs.\nWhich solution will meet these requirements with the MOST operational efficiency?"
    },
    "choices": {
      "kor": {
        "A": "사용자 인증을 위해 Amazon Cognito 사용자 풀을 구성합니다. Cognito 권한 부여자를 사용하여 Amazon API Gateway REST API를 구현합니다.",
        "B": "사용자 인증을 위해 Amazon Cognito 자격 증명 풀을 구성합니다. Cognito 권한 부여자를 사용하여 Amazon API Gateway HTTP API를 구현합니다.",
        "C": "사용자 인증을 처리하도록 AWS Lambda 함수를 구성합니다. Lambda 권한 부여자를 사용하여 Amazon API Gateway REST API를 구현합니다.",
        "D": "사용자 인증을 처리하도록 IAM 사용자를 구성합니다. IAM 권한 부여자를 사용하여 Amazon API Gateway HTTP API를 구현합니다."
      },
      "eng": {
        "A": "Configure an Amazon Cognito user pool for user authentication. Implement Amazon API Gateway REST APIs with a Cognito authorizer.",
        "B": "Configure an Amazon Cognito identity pool for user authentication. Implement Amazon API Gateway HTTP APIs with a Cognito authorizer.",
        "C": "Configure an AWS Lambda function to handle user authentication. Implement Amazon API Gateway REST APIs with a Lambda authorizer.",
        "D": "Configure an IAM user to handle user authentication. Implement Amazon API Gateway HTTP APIs with an IAM authorizer."
      }
    },
    "category": [
      "Cognito"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133031-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 598,
    "question": {
      "kor": "회사는 ALB(Application Load Balancer)를 사용하여 애플리케이션을 온라인에 선보입니다. 최근 회사는 애플리케이션 전체에서 불규칙한 트래픽 패턴을 발견했습니다. 이러한 이상 현상을 더 잘 이해하려면 솔루션 설계자가 인프라 가시성을 효율적으로 향상해야 합니다.\n이러한 요구 사항을 충족하는 데 운영상 가장 효율적인 솔루션은 무엇입니까?",
      "eng": "A company uses an Application Load Balancer (ALB) to showcase its application online. Recently, the company noticed irregular traffic patterns across the application. To gain a better understanding of these abnormalities, a solutions architect needs to enhance infrastructure visibility efficiently.\nWhich solution would be the most operationally efficient to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Athena에서 AWS CloudTrail 로그용 테이블을 생성합니다. 관련 정보를 추출하는 쿼리를 개발합니다.",
        "B": "Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. Amazon Athena에서 테이블을 설정하고 로그를 쿼리합니다.",
        "C": "Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. 텍스트 편집기에서 각 파일을 수동으로 검사하고 관련 정보를 검색합니다.",
        "D": "전용 Amazon EC2 인스턴스에서 Amazon EMR을 활용하여 ALB에 트래픽 액세스 로그 정보를 직접 쿼리합니다."
      },
      "eng": {
        "A": "Create a table in Amazon Athena for AWS CloudTrail logs. Develop a query to extract the relevant information.",
        "B": "Enable ALB access logging to Amazon S3. Set up a table in Amazon Athena and query the logs.",
        "C": "Enable ALB access logging to Amazon S3. Manually inspect each file in a text editor and search for the relevant information.",
        "D": "Utilize Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB for traffic access log information."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 601,
    "question": {
      "kor": "회사는 Amazon S3에 텍스트 파일을 저장합니다. 텍스트 파일에는 고객 채팅 메시지, 날짜 및 시간 정보, 고객 개인 식별 정보(PII)가 포함됩니다.\n회사에는 품질 관리를 위해 외부 서비스 제공업체에 대화 샘플을 제공하는 솔루션이 필요합니다. 외부 서비스 제공자는 가장 최근 대화까지 샘플 대화를 무작위로 선택해야 합니다. 회사는 고객 PII를 외부 서비스 제공업체와 공유해서는 안 됩니다. 고객 대화 수가 증가하면 솔루션도 확장되어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company stores text files in Amazon S3. The text files include customer chat messages, date and time information, and customer personally identifiable information (PII).\nThe company needs a solution to provide samples of the conversations to an external service provider for quality control. The external service provider needs to randomly pick sample conversations up to the most recent conversation. The company must not share the customer PII with the external service provider.\nThe solution must scale when the number of customer conversations increases.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "객체 Lambda 액세스 포인트를 생성합니다. 함수가 파일을 읽을 때 PII를 수정하는 AWS Lambda 함수를 생성합니다. 외부 서비스 공급자에게 객체 Lambda 액세스 포인트에 액세스하도록 지시합니다.",
        "B": "모든 새 파일을 정기적으로 읽고, 파일에서 PII를 수정하고, 수정된 파일을 다른 S3 버킷에 쓰는 Amazon EC2 인스턴스에 배치 프로세스를 만듭니다. PII가 포함되지 않은 버킷에 액세스하도록 외부 서비스 제공자에게 지시하십시오.",
        "C": "파일 목록을 표시하고, 파일에서 PII를 수정하고, 외부 서비스 공급자가 PII가 수정된 파일의 새 버전을 다운로드할 수 있도록 하는 웹 애플리케이션을 Amazon EC2 인스턴스에 생성합니다.",
        "D": "Amazon DynamoDB 테이블을 생성합니다. PII가 포함되지 않은 파일의 데이터만 읽는 AWS Lambda 함수를 생성합니다. 새 파일이 Amazon S3에 기록될 때 DynamoDB 테이블에 PII가 아닌 데이터를 저장하도록 Lambda 함수를 구성합니다. 외부 서비스 공급자에게 DynamoDB 테이블에 대한 액세스 권한을 부여합니다."
      },
      "eng": {
        "A": "Create an Object Lambda Access Point. Create an AWS Lambda function that redacts the PII when the function reads the file. Instruct the external service provider to access the Object Lambda Access Point.",
        "B": "Create a batch process on an Amazon EC2 instance that regularly reads all new files, redacts the PII from the files, and writes the redacted files to a different S3 bucket. Instruct the external service provider to access the bucket that does not contain the PII.",
        "C": "Create a web application on an Amazon EC2 instance that presents a list of the files, redacts the PII from the files, and allows the external service provider to download new versions of the files that have the PII redacted.",
        "D": "Create an Amazon DynamoDB table. Create an AWS Lambda function that reads only the data in the files that does not contain PII. Configure the Lambda function to store the non-PII data in the DynamoDB table when a new file is written to Amazon S3. Grant the external service provider access to the DynamoDB table."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132947-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 608,
    "question": {
      "kor": "회사는 여러 가용 영역에 걸쳐 VPC에서 3계층 웹 애플리케이션을 실행합니다. Amazon EC2 인스턴스는 애플리케이션 계층에 대한 Auto Scaling 그룹에서 실행됩니다.\n회사는 각 리소스의 일일 및 주간 기록 워크로드 추세를 분석하는 자동화된 확장 계획을 수립해야 합니다. 구성은 활용도의 예측 및 실시간 변화에 따라 리소스를 적절하게 확장해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 확장 전략을 권장해야 합니까?",
      "eng": "A company runs a three-tier web application in a VPC across multiple Availability Zones. Amazon EC2 instances run in an Auto Scaling group for the application tier.\nThe company needs to make an automated scaling plan that will analyze each resource's daily and weekly historical workload trends. The configuration must scale resources appropriately according to both the forecast and live changes in utilization.\nWhich scaling strategy should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스의 평균 CPU 사용률을 기준으로 단계 조정을 통해 동적 조정을 구현합니다.",
        "B": "예측 및 확장을 위해 예측 확장을 활성화합니다. 대상 추적을 사용하여 동적 조정 구성",
        "C": "웹 애플리케이션의 트래픽 패턴을 기반으로 자동화된 예약 조정 작업을 생성합니다.",
        "D": "간단한 확장 정책을 설정합니다. EC2 인스턴스 시작 시간을 기준으로 휴지 기간을 늘립니다."
      },
      "eng": {
        "A": "Implement dynamic scaling with step scaling based on average CPU utilization from the EC2 instances.",
        "B": "Enable predictive scaling to forecast and scale. Configure dynamic scaling with target tracking",
        "C": "Create an automated scheduled scaling action based on the traffic patterns of the web application.",
        "D": "Set up a simple scaling policy. Increase the cooldown period based on the EC2 instance startup time."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132911-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 615,
    "question": {
      "kor": "연구 회사에서는 온프레미스 장치를 사용하여 분석용 데이터를 생성합니다. 회사는 AWS 클라우드를 사용하여 데이터를 분석하려고 합니다. 장치는 .csv 파일을 생성하고 SMB 파일 공유에 데이터 쓰기를 지원합니다. 회사 분석가는 SQL 명령을 사용하여 데이터를 쿼리할 수 있어야 합니다. 분석가는 하루 종일 주기적으로 쿼리를 실행합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (3개를 선택하세요.)",
      "eng": "A research company uses on-premises devices to generate data for analysis. The company wants to use the AWS Cloud to analyze the data. The devices generate .csv files and support writing the data to an SMB file share. Company analysts must be able to use SQL commands to query the data. The analysts will run queries periodically throughout the day.\nWhich combination of steps will meet these requirements MOST cost-effectively? (Choose three.)"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 파일 게이트웨이 모드로 온프레미스에 AWS Storage Gateway를 배포합니다.",
        "B": "Amazon FSx File Gateway를 통해 온프레미스에 AWS Storage Gateway를 배포합니다.",
        "C": "Amazon S3에 있는 데이터를 기반으로 테이블을 생성하도록 AWS Glue 크롤러를 설정합니다.",
        "D": "EMRFS(EMR 파일 시스템)를 사용하여 Amazon EMR 클러스터를 설정하여 Amazon S3에 있는 데이터를 쿼리합니다. 분석가에 대한 액세스를 제공합니다.",
        "E": "Amazon S3에 있는 데이터를 쿼리하도록 Amazon Redshift 클러스터를 설정합니다. 분석가에 대한 액세스를 제공합니다.",
        "F": "Amazon S3에 있는 데이터를 쿼리하도록 Amazon Athena를 설정합니다. 분석가에 대한 액세스를 제공합니다."
      },
      "eng": {
        "A": "Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.",
        "B": "Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway made.",
        "C": "Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.",
        "D": "Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts.",
        "E": "Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts.",
        "F": "Set up Amazon Athena to query the data that is in Amazon S3. Provide access to analysts."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/119563-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C",
      "F"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 621,
    "question": {
      "kor": "회사에서 AWS Organizations를 사용합니다. 회사는 다른 예산으로 일부 AWS 계정을 운영하려고 합니다. 회사는 특정 기간 동안 할당된 예산 임계값에 도달하면 알림을 받고 AWS 계정에 추가 리소스 프로비저닝을 자동으로 방지하려고 합니다.\n이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3개를 선택하세요.)",
      "eng": "A company uses AWS Organizations. The company wants to operate some of its AWS accounts with different budgets. The company wants to receive alerts and automatically prevent provisioning of additional resources on AWS accounts when the allocated budget threshold is met during a specific period.\nWhich combination of solutions will meet these requirements? (Choose three.)"
    },
    "choices": {
      "kor": {
        "A": "AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 비용 및 사용 보고서 섹션에서 예산 금액을 설정합니다.",
        "B": "AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 결제 대시보드에서 예산 금액을 설정합니다.",
        "C": "필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 사용자를 생성합니다.",
        "D": "필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 역할을 생성합니다.",
        "E": "각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 프로비저닝을 방지하기 위해 적절한 구성 규칙으로 생성된 IAM 자격 증명을 선택하는 예산 작업을 추가합니다.",
        "F": "각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 프로비저닝을 방지하기 위해 적절한 SCP(서비스 제어 정책)로 생성된 IAM 자격 증명을 선택하는 예산 작업을 추가합니다."
      },
      "eng": {
        "A": "Use AWS Budgets to create a budget. Set the budget amount under the Cost and Usage Reports section of the required AWS accounts.",
        "B": "Use AWS Budgets to create a budget. Set the budget amount under the Billing dashboards of the required AWS accounts.",
        "C": "Create an IAM user for AWS Budgets to run budget actions with the required permissions.",
        "D": "Create an IAM role for AWS Budgets to run budget actions with the required permissions.",
        "E": "Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources.",
        "F": "Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109522-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D",
      "F"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 625,
    "question": {
      "kor": "한 회사가 Amazon S3에서 데이터 레이크를 호스팅하고 있습니다. 데이터 레이크는 다양한 데이터 소스에서 Apache Parquet 형식으로 데이터를 수집합니다. 회사는 수집된 데이터를 준비하기 위해 여러 변환 단계를 사용합니다. 이 단계에는 이상 항목 필터링, 데이터를 표준 날짜 및 시간 값으로 정규화, 분석을 위한 집계 생성이 포함됩니다.\n회사는 변환된 데이터를 데이터 분석가가 액세스하는 S3 버킷에 저장해야 합니다. 회사에는 코드가 필요하지 않은 데이터 변환을 위해 사전 구축된 솔루션이 필요합니다. 솔루션은 데이터 계보 및 데이터 프로파일링을 제공해야 합니다. 회사는 회사 전체의 직원과 데이터 변환 단계를 공유해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company hosts a data lake on Amazon S3. The data lake ingests data in Apache Parquet format from various data sources. The company uses multiple transformation steps to prepare the ingested data. The steps include filtering of anomalies, normalizing of data to standard date and time values, and generation of aggregates for analyses.\nThe company must store the transformed data in S3 buckets that data analysts access. The company needs a prebuilt solution for data transformation that does not require code. The solution must provide data lineage and data profiling. The company needs to share the data transformation steps with employees throughout the company.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "데이터를 변환하도록 AWS Glue Studio 시각적 캔버스를 구성합니다. AWS Glue 작업을 사용하여 변화 단계를 직원과 공유하세요.",
        "B": "데이터를 변환하도록 Amazon EMR Serverless를 구성합니다. EMR 서버리스 작업을 사용하여 전환 단계를 직원과 공유하세요.",
        "C": "데이터를 변환하도록 AWS Glue DataBrew를 구성합니다. DataBrew 레시피를 사용하여 변환 단계를 직원과 공유하세요.",
        "D": "데이터용 Amazon Athena 테이블을 생성합니다. Athena SQL 쿼리를 작성하여 데이터를 변환합니다. Athena SQL 쿼리를 직원과 공유하세요."
      },
      "eng": {
        "A": "Configure an AWS Glue Studio visual canvas to transform the data. Share the transformation steps with employees by using AWS Glue jobs.",
        "B": "Configure Amazon EMR Serverless to transform the data. Share the transformation steps with employees by using EMR Serverless jobs.",
        "C": "Configure AWS Glue DataBrew to transform the data. Share the transformation steps with employees by using DataBrew recipes.",
        "D": "Create Amazon Athena tables for the data. Write Athena SQL queries to transform the data. Share the Athena SQL queries with employees."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135265-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 640,
    "question": {
      "kor": "한 회사에 Amazon DynamoDB 테이블을 저장용으로 사용하는 애플리케이션이 있습니다. 솔루션 설계자는 테이블에 대한 많은 요청이 최신 데이터를 반환하지 않는다는 것을 발견했습니다. 회사 사용자는 데이터베이스 성능과 관련된 다른 문제를 보고하지 않았습니다. 지연 시간이 허용 가능한 범위 내에 있습니다.\n솔루션 설계자는 어떤 디자인 변경을 권장해야 합니까?",
      "eng": "A company has an application that uses an Amazon DynamoDB table for storage. A solutions architect discovers that many requests to the table are not returning the latest data. The company's users have not reported any other issues with database performance. Latency is in an acceptable range.\nWhich design change should the solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "테이블에 읽기 전용 복제본을 추가합니다.",
        "B": "글로벌 보조 인덱스(GSI)를 사용합니다.",
        "C": "테이블에 대해 강력하게 일관된 읽기를 요청합니다.",
        "D": "테이블에 대한 최종적 일관된 읽기를 요청합니다."
      },
      "eng": {
        "A": "Add read replicas to the table.",
        "B": "Use a global secondary index (GSI).",
        "C": "Request strongly consistent reads for the table.",
        "D": "Request eventually consistent reads for the table."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132914-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 643,
    "question": {
      "kor": "한 회사는 AWS 클라우드에서 실험적인 워크로드를 실행할 계획이며 클라우드 지출에 예산을 할당했습니다. 회사의 CFO는 각 부서의 지출 책임을 추적하는 데 관심이 있으며 지출이 예산의 60%에 도달하면 알림을 받기를 원합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company plans to run its experimental workloads in the AWS Cloud and has allocated a budget for cloud spending. The company's CFO is concerned about tracking spending accountability for each department and wishes to receive notifications when spending reaches 60% of the budget.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS 리소스의 비용 할당 태그를 사용하여 소유자에게 레이블을 지정합니다. AWS 예산에서 사용 예산을 생성합니다. 지출이 예산의 60%를 초과할 때 알림을 받도록 경고 임계값을 설정합니다.",
        "B": "AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. 지출이 예산의 60%를 초과하면 AWS 비용 이상 탐지를 활용하여 경고 알림을 생성합니다.",
        "C": "AWS 리소스에 대한 비용 할당 태그를 사용하여 리소스 소유자에게 레이블을 지정합니다. 지출이 예산의 60%를 초과할 때 경고 알림을 생성하려면 AWS Trusted Advisor 내에서 AWS Support API를 사용하십시오.",
        "D": "AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. AWS 예산에서 사용 예산을 설정하고 지출이 예산의 60%를 초과할 때 알림을 받도록 경고 임계값을 설정합니다."
      },
      "eng": {
        "A": "Use cost allocation tags on AWS resources to label owners. Create usage budgets in AWS Budgets. Set an alert threshold to receive notifications when spending exceeds 60% of the budget.",
        "B": "Use AWS Cost Explorer forecasts to determine resource owners. Utilize AWS Cost Anomaly Detection to generate alert notifications when spending surpasses 60% of the budget.",
        "C": "Label resource owners using cost allocation tags on AWS resources. Employ the AWS Support API within AWS Trusted Advisor to create alert notifications when spending surpasses 60% of the budget.",
        "D": "Determine resource owners using AWS Cost Explorer forecasts. Establish usage budgets in AWS Budgets and set an alert threshold to receive notifications when spending exceeds 60% of the budget."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 649,
    "question": {
      "kor": "회사에 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. EC2 인스턴스는 관련 정책이 있는 IAM 역할을 사용하여 Amazon RDS 데이터베이스에 연결합니다. 회사는 AWS Systems Manager를 사용하여 실행 중인 애플리케이션을 중단하지 않고 EC2 인스턴스를 패치하려고 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has applications that run on Amazon EC2 instances. The EC2 instances connect to Amazon RDS databases by using an IAM role that has associated policies. The company wants to use AWS Systems Manager to patch the EC2 instances without disrupting the running applications.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "새로운 IAM 역할을 생성합니다. AmazonSSMManagedInstanceCore 정책을 새 IAM 역할에 연결합니다. 새 IAM 역할을 EC2 인스턴스와 기존 IAM 역할에 연결합니다.",
        "B": "IAM 사용자를 생성합니다. AmazonSSMManagedInstanceCore 정책을 IAM 사용자에게 연결합니다. IAM 사용자를 사용하여 EC2 인스턴스를 관리하도록 Systems Manager를 구성합니다.",
        "C": "Systems Manager에서 기본 호스트 구성 관리를 활성화하여 EC2 인스턴스를 관리합니다.",
        "D": "기존 IAM 역할에서 기존 정책을 제거합니다. 기존 IAM 역할에 AmazonSSMManagedInstanceCore 정책을 추가합니다."
      },
      "eng": {
        "A": "Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role.",
        "B": "Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances.",
        "C": "Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances.",
        "D": "Remove the existing policies from the existing IAM role. Add the AmazonSSMManagedInstanceCore policy to the existing IAM role."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132900-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 651,
    "question": {
      "kor": "솔루션 설계자는 여러 가용 영역에 배포되는 웹 애플리케이션용 공유 스토리지 솔루션을 설계하고 있습니다. 웹 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. 회사는 내용을 수시로 변경할 계획입니다. 솔루션은 변경사항이 발생하는 즉시 새 콘텐츠를 반환하는 강력한 일관성을 가져야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones. The web application runs on Amazon EC2 instances that are in an Auto Scaling group. The company plans to make frequent changes to the content. The solution must have strong consistency in returning the new content as soon as the changes occur.\nWhich solutions meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "개별 EC2 인스턴스에 탑재된 AWS Storage Gateway 볼륨 게이트웨이 iSCSI(Internet Small Computer Systems Interface) 블록 스토리지를 사용하십시오.",
        "B": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 개별 EC2 인스턴스에 EFS 파일 시스템을 탑재합니다.",
        "C": "공유 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 개별 EC2 인스턴스에 EBS 볼륨을 탑재합니다.",
        "D": "AWS DataSync를 사용하여 Auto Scaling 그룹의 EC2 호스트 간에 데이터를 지속적으로 동기화합니다.",
        "E": "웹 콘텐츠를 저장할 Amazon S3 버킷을 생성합니다. Cache-Control 헤더의 메타데이터를 no-cache로 설정합니다. Amazon CloudFront를 사용하여 콘텐츠를 제공합니다."
      },
      "eng": {
        "A": "Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.",
        "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.",
        "C": "Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.",
        "D": "Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.",
        "E": "Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132853-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 653,
    "question": {
      "kor": "한 회사는 Amazon S3 버킷에 Apache Parquet 형식으로 10TB의 로그 파일을 저장했습니다. 회사에서는 때때로 SQL을 사용하여 로그 파일을 분석해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has stored 10 TB of log files in Apache Parquet format in an Amazon S3 bucket. The company occasionally needs to use SQL to analyze the log files.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Aurora MySQL 데이터베이스를 생성하십시오. AWS Database Migration Service(AWS DMS)를 사용하여 S3 버킷의 데이터를 Aurora로 마이그레이션합니다. Aurora 데이터베이스에 SQL 문을 발행합니다.",
        "B": "Amazon Redshift 클러스터를 생성합니다. Redshift Spectrum을 사용하여 S3 버킷의 데이터에 대해 직접 SQL 문을 실행하세요.",
        "C": "S3 버킷에서 테이블 메타데이터를 저장하고 검색하는 AWS Glue 크롤러를 생성합니다. Amazon Athena를 사용하여 S3 버킷의 데이터에 대해 직접 SQL 문을 실행하세요.",
        "D": "Amazon EMR 클러스터를 생성합니다. Apache Spark SQL을 사용하여 S3 버킷의 데이터에 대해 직접 SQL 문을 실행하세요."
      },
      "eng": {
        "A": "Create an Amazon Aurora MySQL database. Migrate the data from the S3 bucket into Aurora by using AWS Database Migration Service (AWS DMS). Issue SQL statements to the Aurora database.",
        "B": "Create an Amazon Redshift cluster. Use Redshift Spectrum to run SQL statements directly on the data in the S3 bucket.",
        "C": "Create an AWS Glue crawler to store and retrieve table metadata from the S3 bucket. Use Amazon Athena to run SQL statements directly on the data in the S3 bucket.",
        "D": "Create an Amazon EMR cluster. Use Apache Spark SQL to run SQL statements directly on the data in the S3 bucket."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133024-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 659,
    "question": {
      "kor": "솔루션 설계자는 회사를 위한 사용자 인증 솔루션을 설계하고 있습니다. 솔루션은 일관되지 않은 지리적 위치, IP 주소 또는 장치에서 로그인하는 사용자에 대해 2단계 인증을 호출해야 합니다.\n또한 솔루션은 수백만 명의 사용자를 수용할 수 있도록 확장할 수 있어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A solutions architect is designing a user authentication solution for a company. The solution must invoke two-factor authentication for users that log in from inconsistent geographical locations, IP addresses, or devices. The solution must also be able to scale up to accommodate millions of users.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "사용자 인증을 위해 Amazon Cognito 사용자 풀을 구성합니다. MFA(다단계 인증)를 통해 위험 기반 적응형 인증 기능을 활성화합니다.",
        "B": "사용자 인증을 위해 Amazon Cognito 자격 증명 풀을 구성합니다. 다단계 인증(MFA)을 활성화합니다.",
        "C": "사용자 인증을 위해 AWS Identity and Access Management(IAM) 사용자를 구성합니다. AllowManageOwnUserMFA 작업을 허용하는 IAM 정책을 연결합니다.",
        "D": "사용자 인증을 위해 AWS IAM Identity Center(AWS Single Sign-On) 인증을 구성합니다. MFA(다단계 인증)를 요구하도록 권한 집합을 구성합니다."
      },
      "eng": {
        "A": "Configure Amazon Cognito user pools for user authentication. Enable the risk-based adaptive authentication feature with multifactor authentication (MFA).",
        "B": "Configure Amazon Cognito identity pools for user authentication. Enable multi-factor authentication (MFA).",
        "C": "Configure AWS Identity and Access Management (IAM) users for user authentication. Attach an IAM policy that allows the AllowManageOwnUserMFA action.",
        "D": "Configure AWS IAM Identity Center (AWS Single Sign-On) authentication for user authentication. Configure the permission sets to require multi-factor authentication (MFA)."
      }
    },
    "category": [
      "Cognito"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135472-exam-aws-certified-solutions-architect-associate-saa-c03/%60",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 661,
    "question": {
      "kor": "회사에는 Amazon EC2 인스턴스에서 실행되는 비즈니스에 중요한 애플리케이션이 있습니다. 애플리케이션은 Amazon DynamoDB 테이블에 데이터를 저장합니다. 회사는 지난 24시간 내의 어느 시점으로든 테이블을 되돌릴 수 있어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a business-critical application that runs on Amazon EC2 instances. The application stores data in an Amazon DynamoDB table. The company must be able to revert the table to any point within the last 24 hours.\nWhich solution meets these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "테이블에 대한 특정 시점 복구를 구성합니다.",
        "B": "테이블에 AWS Backup을 사용하십시오.",
        "C": "AWS Lambda 함수를 사용하여 매시간 테이블의 주문형 백업을 만듭니다.",
        "D": "테이블에서 스트림을 켜서 지난 24시간 동안 테이블에 대한 모든 변경 사항에 대한 로그를 캡처합니다. Amazon S3 버킷에 스트림 복사본을 저장합니다."
      },
      "eng": {
        "A": "Configure point-in-time recovery for the table.",
        "B": "Use AWS Backup for the table.",
        "C": "Use an AWS Lambda function to make an on-demand backup of the table every hour.",
        "D": "Turn on streams on the table to capture a log of all changes to the table in the last 24 hours. Store a copy of the stream in an Amazon S3 bucket."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132960-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 666,
    "question": {
      "kor": "회사는 AWS로 마이그레이션하고 애플리케이션에 Amazon EC2 온디맨드 인스턴스를 사용할 계획입니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 실행되고 메모리를 로드하여 완전한 생산성을 발휘하는 데 오랜 시간이 걸린다는 사실을 관찰했습니다.\n다음 테스트 단계에서 애플리케이션 실행 시간을 단축할 솔루션은 무엇입니까?",
      "eng": "A company plans to migrate to AWS and use Amazon EC2 On-Demand Instances for its application. During the migration testing phase, a technical team observes that the application takes a long time to launch and load memory to become fully productive.\nWhich solution will reduce the launch time of the application during the next testing phase?"
    },
    "choices": {
      "kor": {
        "A": "두 개 이상의 EC2 온디맨드 인스턴스를 시작합니다. Auto Scaling 기능을 활성화하고 다음 테스트 단계에서 EC2 온디맨드 인스턴스를 사용할 수 있도록 하십시오.",
        "B": "EC2 스팟 인스턴스를 시작하여 애플리케이션을 지원하고 다음 테스트 단계에서 사용할 수 있도록 애플리케이션을 확장합니다.",
        "C": "최대 절전 모드를 활성화한 상태에서 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 EC2 Auto Scaling 웜 풀을 구성합니다.",
        "D": "용량 예약을 통해 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 추가 EC2 인스턴스를 시작하십시오."
      },
      "eng": {
        "A": "Launch two or more EC2 On-Demand Instances. Turn on auto scaling features and make the EC2 On-Demand Instances available during the next testing phase.",
        "B": "Launch EC2 Spot Instances to support the application and to scale the application so it is available during the next testing phase.",
        "C": "Launch the EC2 On-Demand Instances with hibernation turned on. Configure EC2 Auto Scaling warm pools during the next testing phase.",
        "D": "Launch EC2 On-Demand Instances with Capacity Reservations. Start additional EC2 instances during the next testing phase."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/119570-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 668,
    "question": {
      "kor": "회사는 온프레미스 데이터 센터에서 여러 워크로드를 실행합니다. 회사의 데이터 센터는 회사의 확장되는 비즈니스 요구 사항을 충족할 만큼 빠르게 확장할 수 없습니다. 회사는 AWS로의 마이그레이션을 계획하기 위해 온프레미스 서버 및 워크로드에 대한 사용량 및 구성 데이터를 수집하려고 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs multiple workloads in its on-premises data center. The company's data center cannot scale fast enough to meet the company's expanding business needs. The company wants to collect usage and configuration data about the on-premises servers and workloads to plan a migration to AWS.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Migration Hub에서 홈 AWS 리전을 설정합니다. AWS Systems Manager를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
        "B": "AWS Migration Hub에서 홈 AWS 지역을 설정합니다. AWS Application Discovery Service를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
        "C": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성합니다. AWS Trusted Advisor를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
        "D": "AWS SCT(AWS Schema Conversion Tool)를 사용하여 관련 템플릿을 생성합니다. AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한",
        "E": "데이터를 수집합니다."
      },
      "eng": {
        "A": "Set the home AWS Region in AWS Migration Hub. Use AWS Systems Manager to collect data about the on-premises servers.",
        "B": "Set the home AWS Region in AWS Migration Hub. Use AWS Application Discovery Service to collect data about the on-premises servers.",
        "C": "Use the AWS Schema Conversion Tool (AWS SCT) to create the relevant templates. Use AWS Trusted Advisor to collect data about the on-premises servers.",
        "D": "Use the AWS Schema Conversion Tool (AWS SCT) to create the relevant templates. Use AWS Database Migration Service (AWS DMS) to collect data about the on-premises servers."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133022-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 675,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스에서 레거시 시스템을 실행하고 있습니다. 애플리케이션 코드는 수정할 수 없으며 시스템은 둘 이상의 인스턴스에서 실행될 수 없습니다. 솔루션 설계자는 시스템 복구 시간을 향상시킬 수 있는 탄력적인 솔루션을 설계해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company is running a legacy system on an Amazon EC2 instance. The application code cannot be modified, and the system cannot run on more than one instance. A solutions architect must design a resilient solution that can improve the recovery time for the system.\nWhat should the solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스에 대한 종료 방지 기능을 활성화합니다.",
        "B": "다중 AZ 배포를 위해 EC2 인스턴스를 구성합니다.",
        "C": "장애 발생 시 EC2 인스턴스를 복구하기 위해 Amazon CloudWatch 경보를 생성합니다.",
        "D": "스토리지 중복성을 위해 RAID 구성을 사용하는 두 개의 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 EC2 인스턴스를 시작합니다."
      },
      "eng": {
        "A": "Enable termination protection for the EC2 instance.",
        "B": "Configure the EC2 instance for Multi-AZ deployment.",
        "C": "Create an Amazon CloudWatch alarm to recover the EC2 instance in case of failure.",
        "D": "Launch the EC2 instance with two Amazon Elastic Block Store (Amazon EBS) volumes that use RAID configurations for storage redundancy."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133082-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 678,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스를 시작하기 위해 AWS 계정에 여러 Amazon 머신 이미지(AMI)를 저장합니다. AMI에는 회사 운영에 필요한 중요한 데이터와 구성이 포함되어 있습니다.\n회사는 실수로 삭제된 AMI를 빠르고 효율적으로 복구하는 솔루션을 구현하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company stores multiple Amazon Machine Images (AMIs) in an AWS account to launch its Amazon EC2 instances. The AMIs contain critical data and configurations that are necessary for the company’s operations. The company wants to implement a solution that will recover accidentally deleted AMIs quickly and efficiently.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AMI의 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. 스냅샷을 별도의 AWS 계정에 저장합니다.",
        "B": "모든 AMI를 주기적으로 다른 AWS 계정에 복사합니다.",
        "C": "휴지통 보관규칙을 생성합니다.",
        "D": "교차 지역 복제 기능이 있는 Amazon S3 버킷에 AMI를 업로드합니다."
      },
      "eng": {
        "A": "Create Amazon Elastic Block Store (Amazon EBS) snapshots of the AMIs. Store the snapshots in a separate AWS account.",
        "B": "Copy all AMIs to another AWS account periodically.",
        "C": "Create a retention rule in Recycle Bin.",
        "D": "Upload the AMIs to an Amazon S3 bucket that has Cross-Region Replication."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132951-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 687,
    "question": {
      "kor": "전 세계에 기자를 보유하고 있는 한 언론사는 AWS에서 방송 시스템을 호스팅하고 있습니다. 기자는 방송 시스템에 생방송을 보냅니다. 기자들은 전화기의 소프트웨어를 사용하여 RTMP(Real Time Messaging Protocol)를 통해 라이브 스트림을 보냅니다.\n솔루션 설계자는 보고자가 최고 품질의 스트림을 전송할 수 있는 기능을 제공하는 솔루션을 설계해야 합니다. 솔루션은 브로드캐스트 시스템에 대한 가속화된 TCP 연결을 다시 제공해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 사용해야 합니까?",
      "eng": "A news company that has reporters all over the world is hosting its broadcast system on AWS. The reporters send live broadcasts to the broadcast system.\nThe reporters use software on their phones to send live streams through the Real Time Messaging Protocol (RTMP).\nA solutions architect must design a solution that gives the reporters the ability to send the highest quality streams. The solution must provide accelerated TCP connections back to the broadcast system.\nWhat should the solutions architect use to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "아마존 클라우드프론트",
        "B": "AWS 글로벌 액셀러레이터",
        "C": "AWS 클라이언트 VPN",
        "D": "Amazon EC2 인스턴스 및 AWS 탄력적 IP 주소"
      },
      "eng": {
        "A": "Amazon CloudFront",
        "B": "AWS Global Accelerator",
        "C": "AWS Client VPN",
        "D": "Amazon EC2 instances and AWS Elastic IP addresses"
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/136812-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 697,
    "question": {
      "kor": "한 회사가 문서 관리 애플리케이션을 로 마이그레이션하고 AWS 있습니다. 애플리케이션은 Linux 서버에서 실행됩니다.\n회사는 애플리케이션을 Auto Scaling 그룹의 Amazon EC2 인스턴스로 마이그레이션합니다. 회사는 공유 스토리지 파일 시스템에 7TiB의 문서를 저장합니다. 외부 관계형 데이터베이스가 문서를 추적합니다.\n문서는 한 번 저장되며 언제든지 참조를 위해 여러 번 검색할 수 있습니다. 회사는 마이그레이션 도중 애플리케이션을 수정할 수 없습니다. 스토리지 솔루션은 가용성이 높아야 하며 시간에 따른 확장을 지원해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is migrating a document management application to AWS. The application runs on Linux servers.\nThe company will migrate the application to Amazon EC2 instances in an Auto Scaling group. The company stores 7 TiB of documents in a shared storage file system. An external relational database tracks the documents.\nDocuments are stored once and can be retrieved multiple times for reference at any time. The company cannot modify the application during the migration.\nThe storage solution must be highly available and must support scaling over time.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "향상된 네트워킹을 갖춘 EC2 인스턴스를 공유 NFS 스토리지 시스템으로 배포합니다. NFS 공유를 내보냅니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다.",
        "B": "S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon S3 버킷을 생성합니다. Auto Scaling 그룹의 EC2 인스턴스에 S3 버킷을 탑재합니다.",
        "C": "SFTP용 AWS 전송 및 Amazon S3 버킷을 사용하여 SFTP 서버 엔드포인트를 배포합니다. SFTP 서버에 연결하도록 Auto Scaling 그룹의 EC2 인스턴스를 구성합니다.",
        "D": "여러 가용 영역에 마운트 지점이 있는 Amazon EFS(Amazon Elastic File System) 파일 시스템을 생성합니다. EFS Standard-Infrequent Access(Standard-IA) 스토리지 클래스를 사용합니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다."
      },
      "eng": {
        "A": "Deploy an EC2 instance with enhanced networking as a shared NFS storage system. Export the NFS share. Mount the NFS share on the EC2 instances in the Auto Scaling group.",
        "B": "Create an Amazon S3 bucket that uses the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Mount the S3 bucket on the EC2 instances in the Auto Scaling group.",
        "C": "Deploy an SFTP server endpoint by using AWS Transfer for SFTP and an Amazon S3 bucket. Configure the EC2 instances in the Auto Scaling group to connect to the SFTP server.",
        "D": "Create an Amazon EFS (Amazon Elastic File System) file system with mount points in multiple Availability Zones. Use the EFS Standard-Infrequent Access (Standard-IA) storage class. Mount the NFS share on the EC2 instances in the Auto Scaling group."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 705,
    "question": {
      "kor": "회사는 회사 로컬 데이터 센터의 Kubernetes 환경에서 컨테이너를 실행합니다. 회사는 Amazon Elastic Kubernetes Service(Amazon EKS) 및 기타 AWS 관리형 서비스를 사용하려고 합니다. 데이터는 회사의 데이터 센터에 로컬로 유지되어야 하며 규정 준수를 유지하기 위해 원격 사이트나 클라우드에 저장할 수 없습니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs containers in a Kubernetes environment in the company's local data center. The company wants to use Amazon Elastic Kubernetes Service (Amazon EKS) and other AWS managed services. Data must remain locally in the company's data center and cannot be stored in any remote site or cloud to maintain compliance.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사의 데이터 센터에 AWS 로컬 영역을 배포합니다.",
        "B": "회사 데이터 센터에서 AWS Snowmobile을 사용합니다.",
        "C": "회사 데이터 센터에 AWS Outposts 랙을 설치합니다.",
        "D": "데이터 센터에 AWS Snowball Edge Storage Optimized 노드를 설치합니다."
      },
      "eng": {
        "A": "Deploy AWS Local Zones in the company's data center.",
        "B": "Use an AWS Snowmobile in the company's data center.",
        "C": "Install an AWS Outposts rack in the company's data center.",
        "D": "Install an AWS Snowball Edge Storage Optimized node in the data center."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135262-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 708,
    "question": {
      "kor": "한 대규모 국제 대학이 모든 컴퓨팅 서비스를 AWS 클라우드에 배포했습니다. 이러한 서비스에는 Amazon EC2, Amazon RDS 및 Amazon DynamoDB가 포함됩니다. 이 대학은 현재 인프라를 백업하기 위해 많은 사용자 정의 스크립트를 사용하고 있습니다. 그러나 대학에서는 AWS 기본 옵션을 사용하여 관리를 중앙 집중화하고 데이터 백업을 최대한 자동화하려고 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A large international university has deployed all of its compute services in the AWS Cloud. These services include Amazon EC2, Amazon RDS, and Amazon DynamoDB. The university currently relies on many custom scripts to back up its infrastructure. However, the university wants to centralize management and automate data backups as much as possible by using AWS native options.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Storage Gateway 테이프 게이트웨이 가상 테이프 라이브러리와 함께 타사 백업 소프트웨어를 사용하십시오.",
        "B": "AWS Backup을 사용하여 사용 중인 서비스에 대한 모든 백업을 구성하고 모니터링합니다.",
        "C": "AWS Config를 사용하여 일정에 따라 모든 데이터 소스의 스냅샷을 찍도록 수명 주기 관리를 설정합니다.",
        "D": "AWS 시스템 관리자 상태 관리자를 사용하여 백업 작업의 구성 및 모니터링을 관리합니다."
      },
      "eng": {
        "A": "Use third-party backup software with an AWS Storage Gateway tape gateway virtual tape library.",
        "B": "Use AWS Backup to configure and monitor all backups for the services in use.",
        "C": "Use AWS Config to set lifecycle management to take snapshots of all data sources on a schedule.",
        "D": "Use AWS Systems Manager State Manager to manage the configuration and monitoring of backup tasks."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/137928-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 716,
    "question": {
      "kor": "한 회사는 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS)에서 자체 관리형 Microsoft SQL Server를 실행합니다. EBS 볼륨의 일일 스냅샷이 생성됩니다.\n최근 만료된 모든 EBS 스냅샷을 삭제하는 스냅샷 정리 스크립트를 실행하는 동안 회사의 모든 EBS 스냅샷이 실수로 삭제되었습니다. 솔루션 아키텍트는 EBS 스냅샷을 무기한 보관하지 않고 데이터 손실을 방지하기 위해 아키텍처를 업데이트해야 합니다.\n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs a self-managed Microsoft SQL Server on Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS). Daily snapshots are taken of the EBS volumes. Recently, all the company's EBS snapshots were accidentally deleted while running a snapshot cleaning script that deletes all expired EBS snapshots. A solutions architect needs to update the architecture to prevent data loss without retaining EBS snapshots indefinitely.\nWhich solution will meet these requirements with the LEAST development effort?"
    },
    "choices": {
      "kor": {
        "A": "EBS 스냅샷 삭제를 거부하도록 사용자의 IAM 정책을 변경합니다.",
        "B": "매일 스냅샷을 완료한 후 EBS 스냅샷을 다른 AWS 리전에 복사합니다.",
        "C": "휴지통에 7일 EBS 스냅샷 보관 규칙을 생성하고 모든 스냅샷에 적용합니다.",
        "D": "EBS 스냅샷을 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 복사합니다."
      },
      "eng": {
        "A": "Change the IAM policy of the user to deny EBS snapshot deletion.",
        "B": "Copy the EBS snapshots to another AWS Region after completing the snapshots daily.",
        "C": "Create a 7-day EBS snapshot retention rule in the Recycle Bin and apply the rule for all snapshots.",
        "D": "Copy EBS snapshots to Amazon S3 Standard-Infrequent Access (S3 Standard-IA)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 718,
    "question": {
      "kor": "회사에서는 Microsoft SQL Server 데이터베이스를 사용합니다. 회사의 애플리케이션은 데이터베이스에 연결됩니다. 회사는 애플리케이션 코드를 최소한으로 변경하면서 Amazon Aurora PostgreSQL 데이터베이스로 마이그레이션하려고 합니다.\n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company uses a Microsoft SQL Server database. The company's applications are connected to the database. The company wants to migrate to an Amazon Aurora PostgreSQL database with minimal changes to the application code.\nWhich combination of steps will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "AWS SCT(AWS Schema Conversion Tool)를 사용하여 애플리케이션에서 SQL 쿼리를 다시 작성하십시오.",
        "B": "Aurora PostgreSQL에서 Babelfish를 활성화하여 애플리케이션에서 SQL 쿼리를 실행합니다.",
        "C": "AWS Schema Conversion Tool(AWS SCT) 및 AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스 스키마와 데이터를 마이그레이션합니다.",
        "D": "Amazon RDS Proxy를 사용하여 애플리케이션을 Aurora PostgreSQL에 연결합니다.",
        "E": "AWS Database Migration Service(AWS DMS)를 사용하여 애플리케이션에서 SQL 쿼리를 다시 작성합니다."
      },
      "eng": {
        "A": "Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications.",
        "B": "Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications.",
        "C": "Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS).",
        "D": "Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL.",
        "E": "Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 721,
    "question": {
      "kor": "회사는 AWS 클라우드에서 워크로드를 실행합니다. 회사는 보안 데이터를 중앙에서 수집하여 회사 전체의 보안을 평가하고 워크로드 보호를 개선하려고 합니다.\n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs workloads in the AWS Cloud. The company wants to centrally collect security data to assess security across the entire company and to improve workload protection.\nWhich solution will meet these requirements with the LEAST development effort?"
    },
    "choices": {
      "kor": {
        "A": "AWS Lake Formation에서 데이터 레이크를 구성합니다. AWS Glue 크롤러를 사용하여 보안 데이터를 데이터 레이크로 수집합니다.",
        "B": ".csv 형식으로 보안 데이터를 수집하도록 AWS Lambda 함수를 구성합니다. Amazon S3 버킷에 데이터를 업로드합니다.",
        "C": "보안 데이터를 수집하기 위해 Amazon Security Lake에 데이터 레이크를 구성합니다. Amazon S3 버킷에 데이터를 업로드합니다.",
        "D": "보안 데이터를 Amazon RDS 클러스터에 로드하도록 AWS Database Migration Service(AWS DMS) 복제 인스턴스를 구성합니다."
      },
      "eng": {
        "A": "Configure a data lake in AWS Lake Formation. Use AWS Glue crawlers to ingest the security data into the data lake.",
        "B": "Configure an AWS Lambda function to collect the security data in .csv format. Upload the data to an Amazon S3 bucket.",
        "C": "Configure a data lake in Amazon Security Lake to collect the security data. Upload the data to an Amazon S3 bucket.",
        "D": "Configure an AWS Database Migration Service (AWS DMS) replication instance to load the security data into an Amazon RDS cluster."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139811-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 722,
    "question": {
      "kor": "회사에 Amazon S3 데이터 레이크가 있습니다. 회사에는 데이터 레이크의 데이터를 변환하고 매일 데이터 웨어하우스에 로드하는 솔루션이 필요합니다. 데이터 웨어하우스에는 MPP(대량 병렬 처리) 기능이 있어야 합니다.\n그런 다음 데이터 분석가는 데이터에 대해 SQL 명령을 사용하여 기계 학습(ML) 모델을 생성하고 교육해야 합니다. 솔루션은 가능한 경우 서버리스 AWS 서비스를 사용해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has an Amazon S3 data lake. The company needs a solution that transforms the data from the data lake and loads the data into a data warehouse every day. The data warehouse must have massively parallel processing (MPP) capabilities. Data analysts then need to create and train machine learning (ML) models by using SQL commands on the data. The solution must use serverless AWS services wherever possible.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "매일 Amazon EMR 작업을 실행하여 데이터를 변환하고 Amazon Redshift에 데이터를 로드합니다. Amazon Redshift ML을 사용하여 ML 모델을 생성하고 교육합니다.",
        "B": "매일 Amazon EMR 작업을 실행하여 데이터를 변환하고 Amazon Aurora Serverless에 데이터를 로드합니다. Amazon Aurora ML을 사용하여 ML 모델을 생성하고 훈련하십시오.",
        "C": "매일 AWS Glue 작업을 실행하여 데이터를 변환하고 Amazon Redshift Serverless에 데이터를 로드합니다. Amazon Redshift ML을 사용하여 ML 모델을 생성하고 교육합니다.",
        "D": "매일 AWS Glue 작업을 실행하여 데이터를 변환하고 Amazon Athena 테이블에 데이터를 로드합니다. Amazon Athena ML을 사용하여 ML 모델을 생성하고 훈련합니다."
      },
      "eng": {
        "A": "Run a daily Amazon EMR job to transform the data and load the data into Amazon Redshift. Use Amazon Redshift ML to create and train the ML models.",
        "B": "Run a daily Amazon EMR job to transform the data and load the data into Amazon Aurora Serverless. Use Amazon Aurora ML to create and train the ML models.",
        "C": "Run a daily AWS Glue job to transform the data and load the data into Amazon Redshift Serverless. Use Amazon Redshift ML to create and train the ML models.",
        "D": "Run a daily AWS Glue job to transform the data and load the data into Amazon Athena tables. Use Amazon Athena ML to create and train the ML models."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135261-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 739,
    "question": {
      "kor": "한 회사에서 콘텐츠 관리 시스템을 제공하는 웹 애플리케이션을 구축하고 있습니다. 콘텐츠 관리 시스템은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. EC2 인스턴스는 여러 가용 영역에 걸쳐 Auto Scaling 그룹에서 실행됩니다. 사용자는 콘텐츠 관리 시스템에 파일, 블로그 및 기타 웹사이트 자산을 지속적으로 추가하고 업데이트하고 있습니다.\n솔루션 아키텍트는 모든 EC2 인스턴스가 지연 시간을 최소화하면서 최신 웹 사이트 콘텐츠를 공유하는 솔루션을 구현해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is building a web application that serves a content management system. The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones. Users are constantly adding and updating files, blogs, and other website assets in the content management system.\nA solutions architect must implement a solution in which all the EC2 instances share up-to-date website content with the least possible lag time.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "가장 최근에 시작된 EC2 인스턴스에서 웹 사이트 자산을 복사하려면 Auto Scaling 그룹 수명 주기 정책에서 EC2 사용자 데이터를 업데이트하세요. 최신 EC2 인스턴스에서만 웹 사이트 자산을 변경하도록 ALB를 구성합니다.",
        "B": "웹 사이트 자산을 Amazon Elastic File System(Amazon EFS) 파일 시스템에 복사합니다. EFS 파일 시스템을 로컬로 탑재하도록 각 EC2 인스턴스를 구성합니다. EFS 파일 시스템에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 애플리케이션을 구성합니다.",
        "C": "웹사이트 자산을 Amazon S3 버킷에 복사합니다. 각 EC2 인스턴스가 S3 버킷에서 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 웹 사이트 자산을 다운로드하는지 확인하십시오. 파일을 최신 상태로 유지하려면 매 시간마다 S3 sync 명령을 실행하세요.",
        "D": "웹 사이트 자산을 사용하여 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원합니다. 새 EC2 인스턴스가 시작되면 EBS 스냅샷을 보조 EBS 볼륨으로 연결합니다. 보조 EBS 볼륨에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 애플리케이션을 구성합니다."
      },
      "eng": {
        "A": "Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the website assets only in the newest EC2 instance.",
        "B": "Copy the website assets to an Amazon Elastic File System (Amazon EFS) file system. Configure each EC2 instance to mount the EFS file system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.",
        "C": "Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Elastic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.",
        "D": "Restore an Amazon Elastic Block Store (Amazon EBS) snapshot with the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/google/view/139090-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 746,
    "question": {
      "kor": "회사에서 기존 사용 비용을 AWS 운영 비용 대시보드에 추가하려고 합니다. 솔루션 설계자는 회사가 프로그래밍 방식으로 사용 비용에 액세스할 수 있는 솔루션을 추천해야 합니다. 회사는 현재 연도의 비용 데이터에 액세스하고 향후 12개월의 비용을 예측할 수 있어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to add its existing AWS usage cost to its operation cost dashboard. A solutions architect needs to recommend a solution that will give the company access to its usage cost programmatically. The company must be able to access cost data for the current year and forecast costs for the next 12 months.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "페이지 매김과 함께 AWS Cost Explorer API를 사용하여 사용 비용 관련 데이터에 액세스합니다.",
        "B": "다운로드 가능한 AWS Cost Explorer 보고서 .csv 파일을 사용하여 사용 비용 관련 데이터에 액세스합니다.",
        "C": "FTP를 통해 회사에 사용 비용 데이터를 전송하도록 AWS 예산 작업을 구성합니다.",
        "D": "사용 비용 데이터에 대한 AWS 예산 보고서를 생성합니다. SMTP를 통해 회사에 데이터를 보냅니다."
      },
      "eng": {
        "A": "Access usage cost-related data by using the AWS Cost Explorer API with pagination.",
        "B": "Access usage cost-related data by using downloadable AWS Cost Explorer report .csv files.",
        "C": "Configure AWS Budgets actions to send usage cost data to the company through FTP.",
        "D": "Create AWS Budgets reports for usage cost data. Send the data to the company through SMTP."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/111278-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 754,
    "question": {
      "kor": "마케팅 회사는 마케팅 캠페인을 통해 Amazon S3에서 대량의 새로운 클릭스트림 데이터를 받습니다. 회사는 Amazon S3의 클릭스트림 데이터를 신속하게 분석해야 합니다. 그런 다음 회사는 데이터 파이프라인에서 데이터를 추가로 처리할지 여부를 결정해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A marketing company receives a large amount of new clickstream data in Amazon S3 from a marketing campaign. The company needs to analyze the clickstream data in Amazon S3 quickly. Then the company needs to determine whether to process the data further in the data pipeline.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Spark 카탈로그에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 AWS Glue에서 작업을 구성합니다.",
        "B": "데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. 데이터를 쿼리하도록 Amazon Athena를 구성합니다.",
        "C": "Hive 메타스토어에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 Amazon EMR에서 Spark 작업을 구성합니다.",
        "D": "데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. SQL을 사용하여 데이터를 쿼리하도록 Amazon Kinesis Data Analytics를 구성합니다."
      },
      "eng": {
        "A": "Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data.",
        "B": "Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data.",
        "C": "Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data.",
        "D": "Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/129713-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 758,
    "question": {
      "kor": "한 회사는 Amazon Elastic Block Store(Amazon EBS)를 연결된 스토리지로 사용하는 Amazon EC2 인스턴스에 애플리케이션을 다시 호스팅할 계획입니다.\n솔루션 아키텍트는 새로 생성된 모든 Amazon EBS 볼륨이 기본적으로 암호화되도록 솔루션을 설계해야 합니다. 또한 솔루션은 암호화되지 않은 EBS 볼륨이 생성되는 것을 방지해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company plans to rehost an application to Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) as the attached storage.\nA solutions architect must design a solution to ensure that all newly created Amazon EBS volumes are encrypted by default. The solution must also prevent the creation of unencrypted EBS volumes.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "항상 새 EBS 볼륨을 암호화하도록 EC2 계정 속성을 구성합니다.",
        "B": "AWS Config를 사용하세요. 암호화된 볼륨 식별자를 구성합니다. 기본 AWS Key Management Service(AWS KMS) 키를 적용합니다.",
        "C": "EBS 볼륨의 암호화된 복사본을 생성하도록 AWS 시스템 관리자를 구성합니다. 암호화된 볼륨을 사용하도록 EC2 인스턴스를 재구성합니다.",
        "D": "AWS Key Management Service(AWS KMS)에서 고객 관리형 키를 생성합니다. 회사가 워크로드를 마이그레이션할 때 키를 사용하도록 AWS Migration Hub를 구성합니다."
      },
      "eng": {
        "A": "Configure the EC2 account attributes to always encrypt new EBS volumes.",
        "B": "Use AWS Config. Configure the encrypted-volumes identifier. Apply the default AWS Key Management Service (AWS KMS) key.",
        "C": "Configure AWS Systems Manager to create encrypted copies of the EBS volumes. Reconfigure the EC2 instances to use the encrypted volumes.",
        "D": "Create a customer managed key in AWS Key Management Service (AWS KMS). Configure AWS Migration Hub to use the key when the company migrates workloads."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/140296-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 768,
    "question": {
      "kor": "회사에서 PostgreSQL용 Amazon RDS를 사용하는 애플리케이션을 실행합니다. 애플리케이션은 평일 업무 시간에만 트래픽을 수신합니다. 회사는 이 사용량을 기반으로 비용을 최적화하고 운영 오버헤드를 줄이려고 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an application that uses Amazon RDS for PostgreSQL. The application receives traffic only on weekdays during business hours. The company wants to optimize costs and reduce operational overhead based on this usage.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS의 인스턴스 스케줄러를 사용하여 시작 및 중지 일정을 구성하십시오.",
        "B": "자동 백업을 끕니다. 데이터베이스의 매주 수동 스냅샷을 생성합니다.",
        "C": "최소 CPU 사용률을 기준으로 데이터베이스를 시작하고 중지하는 사용자 지정 AWS Lambda 함수를 생성합니다.",
        "D": "모든 Upfront 예약 DB 인스턴스를 구매합니다."
      },
      "eng": {
        "A": "Use the Instance Scheduler on AWS to configure start and stop schedules.",
        "B": "Turn off automatic backups. Create weekly manual snapshots of the database.",
        "C": "Create a custom AWS Lambda function to start and stop the database based on minimum CPU utilization.",
        "D": "Purchase All Upfront reserved DB instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/116924-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 771,
    "question": {
      "kor": "회사에는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행되는 내부 애플리케이션이 있습니다. EC2 인스턴스는 컴퓨팅에 최적화되어 있으며 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.\n회사는 EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨 전반에 걸쳐 비용 최적화를 식별하려고 합니다.\n가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an internal application that runs on Amazon EC2 instances in an Auto Scaling group. The EC2 instances are compute optimized and use Amazon Elastic Block Store (Amazon EBS) volumes.\nThe company wants to identify cost optimizations across the EC2 instances, the Auto Scaling group, and the EBS volumes.\nWhich solution will meet these requirements with the MOST operational efficiency?"
    },
    "choices": {
      "kor": {
        "A": "새로운 AWS 비용 및 사용 보고서를 생성합니다. EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항에 대한 보고서를 검색합니다.",
        "B": "새로운 Amazon CloudWatch 결제 알림을 생성합니다. EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항에 대한 경고 상태를 확인하세요.",
        "C": "EC2 인스턴스, Auto Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항을 위해 AWS Compute Optimizer를 구성합니다.",
        "D": "EC2 인스턴스에 대한 비용 권장 사항을 위해 AWS Compute Optimizer를 구성합니다. 새로운 AWS 비용 및 사용 보고서를 생성합니다. Auto Scaling 그룹 및 EBS 볼륨에 대한 비용 권장 사항에 대한 보고서를 검색합니다."
      },
      "eng": {
        "A": "Create a new AWS Cost and Usage Report. Search the report for cost recommendations for the EC2 instances, the Auto Scaling group, and the EBS volumes.",
        "B": "Create new Amazon CloudWatch billing alerts. Check the alert statuses for cost recommendations for the EC2 instances, the Auto Scaling group, and the EBS volumes.",
        "C": "Configure AWS Compute Optimizer for cost recommendations for the EC2 instances, the Auto Scaling group, and the EBS volumes.",
        "D": "Configure AWS Compute Optimizer for cost recommendations for the EC2 instances. Create a new AWS Cost and Usage Report. Search the report for cost recommendations for the Auto Scaling group and the EBS volumes."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 776,
    "question": {
      "kor": "한 회사가 여러 AWS 계정에 몇 페타바이트의 데이터를 저장합니다. 이 회사는 AWS Lake Formation을 사용하여 데이터 레이크를 관리합니다. 회사의 데이터 과학 팀은 분석 목적으로 회사의 엔지니어링 팀과 계정에서 선택한 데이터를 안전하게 공유하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company stores several petabytes of data across multiple AWS accounts. The company uses AWS Lake Formation to manage its data lake. The company's data science team wants to securely share selective data from its accounts with the company's engineering team for analytical purposes.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "필요한 데이터를 공통 계정에 복사하십시오. 해당 계정에서 IAM 액세스 역할을 생성합니다. 엔지니어링 팀 계정의 사용자를 신뢰할 수 있는 엔터티로 포함하는 권한 정책을 지정하여 액세스 권한을 부여합니다.",
        "B": "필요한 엔지니어링 팀 사용자가 데이터에 액세스할 수 있도록 데이터가 저장된 각 계정에서 Lake Formation 권한 부여 명령을 사용합니다.",
        "C": "AWS Data Exchange를 사용하여 필요한 데이터를 필요한 엔지니어링 팀 계정에 비공개로 게시합니다.",
        "D": "Lake Formation 태그 기반 액세스 제어를 사용하여 엔지니어링 팀 계정에 필요한 데이터에 대한 교차 계정 권한을 승인하고 부여합니다."
      },
      "eng": {
        "A": "Copy the required data to a common account. Create an IAM access role in that account. Grant access by specifying a permission policy that includes users from the engineering team accounts as trusted entities.",
        "B": "Use the Lake Formation permissions Grant command in each account where the data is stored to allow the required engineering team users to access the data.",
        "C": "Use AWS Data Exchange to privately publish the required data to the required engineering team accounts.",
        "D": "Use Lake Formation tag-based access control to authorize and grant cross-account permissions for the required data to the engineering team accounts."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109647-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 777,
    "question": {
      "kor": "한 회사에서 프로덕션 애플리케이션의 새 버전을 출시했습니다. 회사의 워크로드는 Amazon EC2, AWS Lambda, AWS Fargate 및 Amazon SageMaker를 사용합니다.\n이제 회사는 사용량이 안정된 상태이므로 워크로드 비용을 최적화하려고 합니다. 회사는 최소한의 저축 계획으로 가장 많은 서비스를 보장하기를 원합니다.\n이러한 요구 사항을 충족하는 저축 계획 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company has released a new version of its production application. The company's workload uses Amazon EC2, AWS Lambda, AWS Fargate, and Amazon SageMaker.\nThe company wants to cost optimize the workload now that usage is at a steady state. The company wants to cover the most services with the fewest savings plans.\nWhich combination of savings plans will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "Amazon EC2 및 SageMaker에 대한 EC2 인스턴스 Savings Plan을 구매하십시오.",
        "B": "Amazon EC2, Lambda 및 SageMaker에 대한 Compute Savings Plan을 구매하십시오.",
        "C": "SageMaker Savings Plan을 구매하세요.",
        "D": "Lambda, Fargate 및 Amazon EC2에 대한 Compute Savings Plan을 구매하십시오.",
        "E": "Amazon EC2 및 Fargate에 대한 EC2 인스턴스 Savings Plan을 구매하세요."
      },
      "eng": {
        "A": "Purchase an EC2 Instance Savings Plan for Amazon EC2 and SageMaker.",
        "B": "Purchase a Compute Savings Plan for Amazon EC2, Lambda, and SageMaker.",
        "C": "Purchase a SageMaker Savings Plan.",
        "D": "Purchase a Compute Savings Plan for Lambda, Fargate, and Amazon EC2.",
        "E": "Purchase an EC2 Instance Savings Plan for Amazon EC2 and Fargate."
      }
    },
    "category": [
      "Cost"
    ],
    "subcategory": [
      "Cost optimization",
      "SageMaker Savings Plan",
      "Compute Savings Plan"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139801-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 778,
    "question": {
      "kor": "AWS Organizations를 사용하는 회사는 30개의 서로 다른 AWS 계정에서 150개의 애플리케이션을 실행합니다. 회사는 AWS 비용 및 사용 보고서를 사용하여 마스터 계정에 새 보고서를 생성했습니다. 보고서는 데이터 수집 계정의 버킷에 복제된 Amazon S3 버킷으로 전달됩니다.\n회사의 고위 경영진은 이번 달 초부터 매일 NAT 게이트웨이 비용을 제공하는 사용자 정의 대시보드를 확인하려고 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company that uses AWS Organizations runs 150 applications across 30 different AWS accounts. The company used AWS Cost and Usage Report to create a new report in the management account. The report is delivered to an Amazon S3 bucket that is replicated to a bucket in the data collection account.\nThe company’s senior leadership wants to view a custom dashboard that provides NAT gateway costs each day starting at the beginning of the current month.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "요청된 테이블 시각적 개체가 포함된 Amazon QuickSight 대시보드를 공유하십시오. AWS DataSync를 사용하여 새 보고서를 쿼리하도록 QuickSight를 구성합니다.",
        "B": "요청된 테이블 시각적 개체가 포함된 Amazon QuickSight 대시보드를 공유합니다. Amazon Athena를 사용하여 새 보고서를 쿼리하도록 QuickSight를 구성합니다.",
        "C": "요청된 테이블 시각적 개체가 포함된 Amazon CloudWatch 대시보드를 공유합니다. AWS DataSync를 사용하여 새 보고서를 쿼리하도록 CloudWatch를 구성합니다.",
        "D": "요청된 테이블 시각적 개체가 포함된 Amazon CloudWatch 대시보드를 공유합니다. Amazon Athena를 사용하여 새 보고서를 쿼리하도록 CloudWatch를 구성합니다."
      },
      "eng": {
        "A": "Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use AWS DataSync to query the new report.",
        "B": "Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use Amazon Athena to query the new report.",
        "C": "Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use AWS DataSync to query the new report.",
        "D": "Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use Amazon Athena to query the new report."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 782,
    "question": {
      "kor": "회사는 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장합니다 회사는 모든 데이터를 5년간 보관하고 5년이 지나면 모든 데이터를 삭제해야 합니다. 회사는 또한 데이터베이스 내에서 수행되는 작업의 감사 로그를 무기한으로 유지해야 합니다. 현재 이 회사는 Aurora용으로 자동 백업을 구성했습니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company stores data in an Amazon Aurora PostgreSQL DB cluster. The company must store all the data for 5 years and must delete all the data after 5 years. The company also must indefinitely keep audit logs of actions that are performed within the database. Currently, the company has automated backups configured for Aurora.\nWhich combination of steps should a solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "DB 클러스터의 수동 스냅샷을 생성합니다.",
        "B": "자동 백업에 대한 수명 주기 정책을 만듭니다.",
        "C": "5년 동안 자동 백업 보존을 구성합니다.",
        "D": "DB 클러스터에 대한 Amazon CloudWatch Logs 내보내기를 구성합니다.",
        "E": "AWS Backup을 사용하여 백업을 수행하고 5년 동안 백업을 보관합니다."
      },
      "eng": {
        "A": "Take a manual snapshot of the DB cluster.",
        "B": "Create a lifecycle policy for the automated backups.",
        "C": "Configure automated backup retention for 5 years.",
        "D": "Configure an Amazon CloudWatch Logs export for the DB cluster.",
        "E": "Use AWS Backup to take the backups and to keep the backups for 5 years."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87629-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 806,
    "question": {
      "kor": "한 회사가 한 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 EC2 인스턴스를 두 번째 리전에 백업하려고 합니다. 또한 회사는 두 번째 리전에서 EC2 리소스를 프로비저닝하고 하나의 AWS 계정에서 중앙에서 EC2 인스턴스를 관리하기를 원합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs applications on Amazon EC2 instances in one AWS Region. The company wants to back up the EC2 instances to a second Region. The company also wants to provision EC2 resources in the second Region and manage the EC2 instances centrally from one AWS account.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "두 번째 지역에 비슷한 수의 EC2 인스턴스가 있는 재해 복구(DR) 계획을 만듭니다. 데이터 복제를 구성합니다.",
        "B": "EC2 인스턴스의 특정 시점 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. 주기적으로 스냅샷을 두 번째 리전에 복사합니다.",
        "C": "AWS Backup을 사용하여 백업 계획을 생성합니다. EC2 인스턴스의 두 번째 리전에 대한 교차 리전 백업을 구성합니다.",
        "D": "두 번째 리전에 비슷한 수의 EC2 인스턴스를 배포합니다. AWS DataSync를 사용하여 원본 리전에서 두 번째 리전으로 데이터를 전송합니다."
      },
      "eng": {
        "A": "Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region. Configure data replication.",
        "B": "Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.",
        "C": "Create a backup plan by using AWS Backup. Configure cross-Region backup to the second Region for the EC2 instances.",
        "D": "Deploy a similar number of EC2 instances in the second Region. Use AWS DataSync to transfer the data from the source Region to the second Region."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109523-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 814,
    "question": {
      "kor": "회사에서 온프레미스 애플리케이션을 AWS로 마이그레이션하고 있습니다. 회사는 Amazon Redshift를 솔루션으로 사용하려고 합니다.\n이 시나리오에서 Amazon Redshift에 적합한 사용 사례는 무엇입니까? (3개를 선택하세요.)",
      "eng": "A company is migrating an on-premises application to AWS. The company wants to use Amazon Redshift as a solution.\nWhich use cases are suitable for Amazon Redshift in this scenario? (Choose three.)"
    },
    "choices": {
      "kor": {
        "A": "기존의 컨테이너화된 이벤트 기반 애플리케이션으로 데이터에 액세스하기 위한 데이터 API 지원",
        "B": "클라이언트 측 및 서버 측 암호화 지원",
        "C": "지정된 시간 동안 애플리케이션이 활성 상태가 아닐 때 분석 워크로드 구축",
        "D": "백엔드 데이터베이스에 대한 부담을 줄이기 위한 데이터 캐싱",
        "E": "페타바이트 규모의 데이터와 분당 수천만 건의 요청을 지원하도록 전 세계적으로 확장",
        "F": "AWS Management Console을 사용하여 클러스터의 보조 복제본 생성"
      },
      "eng": {
        "A": "Supporting data APIs to access data with traditional, containerized, and event-driven applications",
        "B": "Supporting client-side and server-side encryption",
        "C": "Building analytics workloads during specified hours and when the application is not active",
        "D": "Caching data to reduce the pressure on the backend database",
        "E": "Scaling globally to support petabytes of data and tens of millions of requests per minute",
        "F": "Creating a secondary replica of the cluster by using the AWS Management Console"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109535-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "C",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 816,
    "question": {
      "kor": "컨설팅 회사는 전 세계 고객에게 전문 서비스를 제공합니다. 이 회사는 고객이 AWS에서 데이터를 신속하게 수집하고 분석할 수 있는 솔루션과 도구를 제공합니다. 회사는 고객이 셀프 서비스 목적으로 사용할 공통 솔루션 및 도구 집합을 중앙에서 관리하고 배포해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A consulting company provides professional services to customers worldwide. The company provides solutions and tools for customers to expedite gathering and analyzing data on AWS. The company needs to centrally manage and deploy a common set of solutions and tools for customers to use for self-service purposes.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "고객을 위한 AWS CloudFormation 템플릿을 생성합니다.",
        "B": "고객을 위한 AWS Service Catalog 제품을 만듭니다.",
        "C": "고객을 위한 AWS Systems Manager 템플릿을 생성합니다.",
        "D": "고객을 위한 AWS Config 항목을 생성합니다."
      },
      "eng": {
        "A": "Create AWS CloudFormation templates for the customers.",
        "B": "Create AWS Service Catalog products for the customers.",
        "C": "Create AWS Systems Manager templates for the customers.",
        "D": "Create AWS Config items for the customers."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109722-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 821,
    "question": {
      "kor": "회사에서 AWS 클라우드를 사용하여 온프레미스 DR(재해 복구) 구성을 개선하려고 합니다. 회사의 핵심 프로덕션 비즈니스 애플리케이션은 가상 머신(VM)에서 실행되는 Microsoft SQL Server Standard를 사용합니다. 애플리케이션의 RPO(복구 시점 목표)는 30초 이하이고 RTO(복구 시간 목표)는 60분입니다. DR 솔루션은 가능한 한 비용을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to use the AWS Cloud to improve its on-premises disaster recovery (DR) configuration. The company's core production business application uses Microsoft SQL Server Standard, which runs on a virtual machine (VM). The application has a recovery point objective (RPO) of 30 seconds or fewer and a recovery time objective (RTO) of 60 minutes. The DR solution needs to minimize costs wherever possible.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Always On 가용성 그룹과 함께 Microsoft SQL Server Enterprise를 사용하여 온프레미스 서버와 AWS 간에 다중 사이트 활성/활성 설정을 구성합니다.",
        "B": "AWS에서 SQL Server 데이터베이스용 웜 대기 Amazon RDS를 구성합니다. 변경 데이터 캡처(CDC)를 사용하도록 AWS DMS(AWS Database Migration Service)를 구성 합니다.",
        "C": "디스크 변경 사항을 AWS에 파일럿 라이트로 복제하도록 구성된 AWS Elastic Disaster Recovery를 사용합니다.",
        "D": "타사 백업 소프트웨어를 사용하여 매일 밤 백업을 캡처합니다. Amazon S3에 보조 백업 세트를 저장합니다."
      },
      "eng": {
        "A": "Configure a multi-site active/active setup between the on-premises server and AWS by using Microsoft SQL Server Enterprise with Always On availability groups.",
        "B": "Configure a warm standby Amazon RDS for SQL Server database on AWS. Configure AWS Database Migration Service (AWS DMS) to use change data capture (CDC).",
        "C": "Use AWS Elastic Disaster Recovery configured to replicate disk changes to AWS as a pilot light.",
        "D": "Use third-party backup software to capture backups every night. Store a secondary set of backups in Amazon S3."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/111301-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 824,
    "question": {
      "kor": "솔루션 설계자는 분석 애플리케이션을 관리합니다. 애플리케이션은 Amazon S3 버킷에 대량의 반구조화된 데이터를 저장합니다. 솔루션 설계자는 병렬 데이터 처리를 사용하여 데이터를 더 빠르게 처리하려고 합니다. 또한 솔루션 설계자는 Amazon Redshift 데이터베이스에 저장된 정보를 사용하여 데이터를 보강하려고 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A solutions architect manages an analytics application. The application stores large amounts of semistructured data in an Amazon S3 bucket. The solutions architect wants to use parallel data processing to process the data more quickly. The solutions architect also wants to use information that is stored in an Amazon Redshift database to enrich the data.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Athena를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 AWS Glue를 사용하여 S3 데이터를 보강합니다.",
        "B": "Amazon EMR을 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 Amazon EMR을 사용하여 S3 데이터를 보강합니다.",
        "C": "Amazon EMR을 사용하여 S3 데이터를 처리합니다. 데이터를 보강할 수 있도록 Amazon Kinesis Data Streams를 사용하여 S3 데이터를 Amazon Redshift로 이동합니다.",
        "D": "AWS Glue를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 AWS Lake Formation을 사용하여 S3 데이터를 보강합니다."
      },
      "eng": {
        "A": "Use Amazon Athena to process the S3 data. Use AWS Glue with the Amazon Redshift data to enrich the S3 data.",
        "B": "Use Amazon EMR to process the S3 data. Use Amazon EMR with the Amazon Redshift data to enrich the S3 data.",
        "C": "Use Amazon EMR to process the S3 data. Use Amazon Kinesis Data Streams to move the S3 data into Amazon Redshift so that the data can be enriched.",
        "D": "Use AWS Glue to process the S3 data. Use AWS Lake Formation with the Amazon Redshift data to enrich the S3 data."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117344-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 840,
    "question": {
      "kor": "회사의 인프라는 Amazon Elastic Block Store(Amazon EBS) 스토리지를 사용하는 수백 개의 Amazon EC2 인스턴스로 구성됩니다. 솔루션 아키텍트는 재해 발생 후 모든 EC2 인스턴스를 복구할 수 있는지 확인해야 합니다.\n최소한의 노력으로 이 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A company's infrastructure consists of hundreds of Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) storage. A solutions architect must ensure that every EC2 instance can be recovered after a disaster.\nWhat should the solutions architect do to meet this requirement with the LEAST amount of effort?"
    },
    "choices": {
      "kor": {
        "A": "각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. EBS 스토리지에서 새 EC2 인스턴스를 시작하려면 AWS CloudFormation 템플릿을 생성하세요.",
        "B": "각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. AWS Elastic Beanstalk를 사용하여 EC2 템플릿 기반으로 환경을 설정하고 EBS 스토리지를 연결하세요.",
        "C": "AWS Backup을 사용하여 전체 EC2 인스턴스 그룹에 대한 백업 계획을 설정합니다. AWS Backup API 또는 AWS CLI를 사용하면 여러 EC2 인스턴스의 복원 프로세스 속도를 높일 수 있습니다.",
        "D": "각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍고 Amazon 머신 이미지(AMI)를 복사하는 AWS Lambda 함수를 생성합니다. 복사된 AMI로 복원을 수행하고 EBS 스토리지를 연결하는 또 다른 Lambda 함수를 생성합니다."
      },
      "eng": {
        "A": "Take a snapshot of the EBS storage that is attached to each EC2 instance. Create an AWS CloudFormation template to launch new EC2 instances from the EBS storage.",
        "B": "Take a snapshot of the EBS storage that is attached to each EC2 instance. Use AWS Elastic Beanstalk to set the environment based on the EC2 template and attach the EBS storage.",
        "C": "Use AWS Backup to set up a backup plan for the entire group of EC2 instances. Use the AWS Backup API or the AWS CLI to speed up the restore process for multiple EC2 instances.",
        "D": "Create an AWS Lambda function to take a snapshot of the EBS storage that is attached to each EC2 instance and copy the Amazon Machine Images (AMIs). Create another Lambda function to perform the restores with the copied AMIs and attach the EBS storage."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 848,
    "question": {
      "kor": "한 회사에서는 us-east-1 리전에 볼륨으로 마운트된 SMB 파일 공유가 있는 Amazon EC2 인스턴스에 Amazon FSx for Windows File Server를 사용하려고 합니다. 회사는 계획된 시스템 유지 관리 또는 계획되지 않은 서비스 중단에 대해 5분의 복구 지점 목표(RPO)를 가지고 있습니다. 회사는 파일 시스템을 us-west-2 리전에 복제해야 합니다. 복제된 데이터는 5년 동안 어떤 사용자도 삭제해서는 안 됩니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company wants to use Amazon FSx for Windows File Server for its Amazon EC2 instances that have an SMB file share mounted as a volume in the useast- 1 Region. The company has a recovery point objective (RPO) of 5 minutes for planned system maintenance or unplanned service disruptions. The company needs to replicate the file system to the us-west-2 Region. The replicated data must not be deleted by any user for 5 years.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "단일 AZ 2 배포 유형을 사용하는 us-east-1에 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup을 사용하여 백업을 us-west-2에 복사하는 백업 규칙이 포함된 일일 백업 계획을 생성합니다. us-west-2의 대상 볼트에 대해 규정 준수 모드로 AWS Backup Vault Lock을 구성합니다. 최소 기간을 5년으로 구성합니다.",
        "B": "다중 AZ 배포 유형이 있는 us-east-1에 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup을 사용하여 백업을 us-west-2에 복사하는 백업 규칙이 포함된 일일 백업 계획을 생성합니다. us-west-2의 대상 볼트에 대해 거버넌스 모드에서 AWS Backup Vault Lock을 구성합니다. 최소 기간을 5년으로 구성합니다.",
        "C": "다중 AZ 배포 유형이 있는 us-east-1에 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup을 사용하여 백업을 us-west-2에 복사하는 백업 규칙이 포함된 일일 백업 계획을 생성합니다. us-west-2의 대상 볼트에 대해 규정 준수 모드로 AWS Backup Vault Lock을 구성합니다. 최소 기간을 5년으로 구성합니다.",
        "D": "단일 AZ 2 배포 유형이 있는 us-east-1에 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup을 사용하여 백업을 us-west-2에 복사하는 백업 규칙이 포함된 일일 백업 계획을 생성합니다. us-west-2의 대상 볼트에 대해 거버넌스 모드에서 AWS Backup Vault Lock을 구성합니다. 최소 기간을 5년으로 구성합니다."
      },
      "eng": {
        "A": "Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
        "B": "Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
        "C": "Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
        "D": "Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years."
      }
    },
    "category": [
      "Backup"
    ],
    "subcategory": [
      "FSx"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121219-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 852,
    "question": {
      "kor": "회사에서는 사용자에게 AWS 리소스에 대한 액세스 권한을 제공하려고 합니다. 이 회사에는 1,500명의 사용자가 있으며 회사 네트워크의 Active Directory 사용자 그룹을 통해 온프레미스 리소스에 대한 액세스를 관리합니다. 그러나 회사는 사용자가 리소스에 액세스하기 위해 다른 ID를 유지해야 하는 것을 원하지 않습니다. 솔루션 아키텍트는 온프레미스 리소스에 대한 액세스를 유지하면서 AWS 리소스에 대한 사용자 액세스를 관리해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company wants to provide users with access to AWS resources. The company has 1,500 users and manages their access to on-premises resources through Active Directory user groups on the corporate network. However, the company does not want users to have to maintain another identity to access the resources. A solutions architect must manage user access to the AWS resources while preserving access to the on-premises resources.\nWhat should the solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사의 각 사용자에 대해 IAM 사용자를 생성합니다. 각 사용자에게 적절한 정책을 연결합니다.",
        "B": "Active Directory 사용자 풀과 함께 Amazon Cognito를 사용하십시오. 적절한 정책이 연결된 역할을 생성합니다.",
        "C": "적절한 정책이 연결된 교차 계정 역할을 정의합니다. 역할을 Active Directory 그룹에 매핑합니다.",
        "D": "SAML(Security Assertion Markup Language) 2.0 기반 페더레이션을 구성합니다. 적절한 정책이 연결된 역할을 생성합니다. 역할을 Active Directory 그룹에 매핑합니다."
      },
      "eng": {
        "A": "Create an IAM user for each user in the company. Attach the appropriate policies to each user.",
        "B": "Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.",
        "C": "Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.",
        "D": "Configure Security Assertion Markup Language (SAML) 2.0-based federation. Create roles with the appropriate policies attached Map the roles to the Active Directory groups."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125336-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 854,
    "question": {
      "kor": "회사에서 두 개의 DNS 서버를 AWS로 마이그레이션하려고 합니다. 서버는 총 약 200개 영역을 호스팅하고 매일 평균 100만 건의 요청을 받습니다. 회사는 두 서버의 관리와 관련된 운영 오버헤드를 최소화하면서 가용성을 극대화하기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?",
      "eng": "A company wants to migrate two DNS servers to AWS. The servers host a total of approximately 200 zones and receive 1 million requests each day on average. The company wants to maximize availability while minimizing the operational overhead that is related to the management of the two servers.\nWhat should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Route 53 콘솔 가져오기 영역 파일에서 200개의 새로운 호스팅 영역을 생성합니다.",
        "B": "단일 대형 Amazon EC2 인스턴스 가져오기 영역 타일을 시작합니다. 가동 중지 시간에 대해 회사에 알리도록 Amazon CloudWatch 경보 및 알림을 구성합니다.",
        "C": "AWS Server Migration Service(AWS SMS)를 사용하여 서버를 AWS로 마이그레이션합니다. 가동 중지 시간에 대해 회사에 알리도록 Amazon CloudWatch 경보 및 알림을 구성합니다.",
        "D": "두 개의 가용 영역에 걸쳐 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 시작합니다. 영역 파일을 가져옵니다. Auto Scaling 그룹에 대해 원하는 용량을 1로, 최대 용량을 3으로 설정합니다. CPU 사용률에 따라 조정되도록 조정 경보를 구성합니다."
      },
      "eng": {
        "A": "Create 200 new hosted zones in the Amazon Route 53 console Import zone files.",
        "B": "Launch a single large Amazon EC2 instance Import zone tiles. Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.",
        "C": "Migrate the servers to AWS by using AWS Server Migration Service (AWS SMS). Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.",
        "D": "Launch an Amazon EC2 instance in an Auto Scaling group across two Availability Zones. Import zone files. Set the desired capacity to 1 and the maximum capacity to 3 for the Auto Scaling group. Configure scaling alarms to scale based on CPU utilization."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125541-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 857,
    "question": {
      "kor": "한 회사에서 대량의 데이터를 저장할 새로운 애플리케이션을 만들고 있습니다. 데이터는 매시간 분석되며 여러 가용 영역에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 수정됩니다.\n필요한 저장 공간의 양은 향후 6개월 동안 계속 증가할 것입니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 합니까?",
      "eng": "A company is creating a new application that will store a large amount of data. The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones. The needed amount of storage space will continue to grow for the next 6 months.\nWhich storage solution should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 Glacier에 데이터를 저장합니다. 애플리케이션 인스턴스에 대한 액세스를 허용하도록 S3 Glacier 볼트 정책을 업데이트합니다.",
        "B": "Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 애플리케이션 인스턴스에 EBS 볼륨을 탑재합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 애플리케이션 인스턴스에 파일 시스템을 마운트합니다.",
        "D": "애플리케이션 인스턴스 간에 공유되는 Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS 볼륨에 데이터를 저장합니다."
      },
      "eng": {
        "A": "Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.",
        "B": "Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.",
        "C": "Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.",
        "D": "Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125114-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 865,
    "question": {
      "kor": "한 회사에서 재무 검토를 위해 AWS 비용을 모니터링하려고 합니다. 클라우드 운영 팀은 모든 회원 계정에 대한 AWS 비용 및 사용 보고서를 쿼리하기 위해 AWS Organizations 마스터 계정의 아키텍처를 설계하고 있습니다. 팀은 한 달에 한 번씩 이 쿼리를 실행하고 청구서에 대한 자세한 분석을 제공해야 합니다.\n이러한 요구 사항을 충족하는 가장 확장 가능하고 비용 효율적인 방법은 무엇입니까?",
      "eng": "A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations management account to query AWS Cost and Usage Reports for all member accounts. The team must run this query once a month and provide a detailed analysis of the bill.\nWhich solution is the MOST scalable and cost-effective way to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "마스터 계정에서 비용 및 사용 보고서를 활성화합니다. Amazon Kinesis에 보고서를 전달합니다. 분석에는 Amazon EMR을 사용하십시오.",
        "B": "마스터 계정에서 비용 및 사용 보고서를 활성화합니다. Amazon S3에 보고서를 전달합니다. 분석을 위해 Amazon Athena를 사용합니다.",
        "C": "회원 계정에 대한 비용 및 사용 보고서를 활성화합니다. Amazon S3에 보고서 전달 분석을 위해 Amazon Redshift를 사용합니다.",
        "D": "회원 계정에 대한 비용 및 사용 보고서를 활성화합니다. Amazon Kinesis에 보고서를 전달합니다. Amazon QuickSight 토르 분석을 사용하십시오."
      },
      "eng": {
        "A": "Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.",
        "B": "Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.",
        "C": "Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3 Use Amazon Redshift for analysis.",
        "D": "Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight tor analysis."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125580-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 870,
    "question": {
      "kor": "한 게임 회사에서 VoIP(Voice over IP) 기능이 포함된 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 전 세계 사용자에게 트래픽을 제공합니다. 애플리케이션은 AWS 리전 전체에 걸쳐 자동화된 장애 조치를 통해 가용성이 높아야 합니다. 회사는 사용자 장치의 IP 주소 캐싱에 의존하지 않고 사용자의 대기 시간을 최소화하려고 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A gaming company is building an application with Voice over IP capabilities. The application will serve traffic to users across the world. The application needs to be highly available with an automated failover across AWS Regions. The company wants to minimize the latency of users without relying on IP address caching on user devices.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "상태 확인과 함께 AWS Global Accelerator를 사용하십시오.",
        "B": "지리적 위치 라우팅 정책과 함께 Amazon Route 53을 사용하십시오.",
        "C": "여러 오리진을 포함하는 Amazon CloudFront 배포를 생성합니다.",
        "D": "경로 기반 라우팅을 사용하는 Application Load Balancer를 생성합니다."
      },
      "eng": {
        "A": "Use AWS Global Accelerator with health checks.",
        "B": "Use Amazon Route 53 with a geolocation routing policy.",
        "C": "Create an Amazon CloudFront distribution that includes multiple origins.",
        "D": "Create an Application Load Balancer that uses path-based routing."
      }
    },
    "category": [
      "Workload Distribution"
    ],
    "subcategory": [
      "Global Accelerator"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 873,
    "question": {
      "kor": "회사에는 매일 6시간 동안 실행되는 대규모 데이터 워크로드가 있습니다. 프로세스가 실행되는 동안 회사는 데이터를 잃을 수 없습니다. 솔루션 아키텍트는 이 중요한 데이터 워크로드를 지원하기 위해 Amazon EMR 클러스터 구성을 설계하고 있습니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a large data workload that runs for 6 hours each day. The company cannot lose any data while the process is running. A solutions architect is designing an Amazon EMR cluster configuration to support this critical data workload.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "온디맨드 인스턴스의 기본 노드와 코어 노드, 스팟 인스턴스의 작업 노드를 실행하는 장기 실행 클러스터를 구성합니다.",
        "B": "온디맨드 인스턴스의 기본 노드와 코어 노드, 스팟 인스턴스의 작업 노드를 실행하는 임시 클러스터를 구성합니다.",
        "C": "온디맨드 인스턴스의 기본 노드와 스팟 인스턴스의 핵심 노드 및 작업 노드를 실행하는 임시 클러스터를 구성합니다.",
        "D": "온디맨드 인스턴스의 기본 노드, 스팟 인스턴스의 코어 노드, 스팟 인스턴스의 작업 노드를 실행하는 장기 실행 클러스터를 구성합니다."
      },
      "eng": {
        "A": "Configure a long-running cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.",
        "B": "Configure a transient cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.",
        "C": "Configure a transient cluster that runs the primary node on an On-Demand Instance and the core nodes and task nodes on Spot Instances.",
        "D": "Configure a long-running cluster that runs the primary node on an On-Demand Instance, the core nodes on Spot Instances, and the task nodes on Spot Instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125591-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 876,
    "question": {
      "kor": "회사는 AWS Cost Explorer를 사용하여 AWS 비용을 모니터링합니다. 회사는 Amazon Elastic Block Store(Amazon EBS) 스토리지 및 스냅샷 비용이 매달 증가한다는 사실을 알아냈습니다. 그러나 회사는 매달 EBS 스토리지를 추가로 구매하지 않습니다. 회사는 현재 스토리지 사용량에 맞게 월별 비용을 최적화하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses AWS Cost Explorer to monitor its AWS costs. The company notices that Amazon Elastic Block Store (Amazon EBS) storage and snapshot costs increase every month. However, the company does not purchase additional EBS storage every month. The company wants to optimize monthly costs for its current storage usage.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon CloudWatch Logs의 로그를 사용하여 Amazon EBS의 스토리지 활용도를 모니터링하십시오. Amazon EBS 탄력적 볼륨을 사용하여 EBS 볼륨의 크기를 줄입니다.",
        "B": "사용자 정의 스크립트를 사용하여 공간 사용량을 모니터링합니다. Amazon EBS 탄력적 볼륨을 사용하여 EBS 볼륨의 크기를 줄입니다.",
        "C": "만료되거나 사용되지 않은 모든 스냅샷을 삭제하여 스냅샷 비용을 줄입니다.",
        "D": "중요하지 않은 스냅샷을 모두 삭제합니다. Amazon Data Lifecycle Manager를 사용하여 회사의 스냅샷 정책 요구 사항에 따라 스냅샷을 생성하고 관리합니다."
      },
      "eng": {
        "A": "Use logs in Amazon CloudWatch Logs to monitor the storage utilization of Amazon EBS. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.",
        "B": "Use a custom script to monitor space usage. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.",
        "C": "Delete all expired and unused snapshots to reduce snapshot costs.",
        "D": "Delete all nonessential snapshots. Use Amazon Data Lifecycle Manager to create and manage the snapshots according to the company's snapshot policy requirements."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/126865-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 879,
    "question": {
      "kor": "회사는 전 세계에 고객을 두고 있습니다. 회사는 자동화를 사용하여 시스템과 네트워크 인프라를 보호하기를 원합니다. 회사의 보안 팀은 인프라에 대한 모든 증분 변경 사항을 추적하고 감사할 수 있어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has customers located across the world. The company wants to use automation to secure its systems and network infrastructure. The company's security team must be able to track and audit all incremental changes to the infrastructure.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Organizations를 사용하여 인프라를 설정하십시오. AWS Config를 사용하여 변경 사항을 추적하세요.",
        "B": "AWS CloudFormation을 사용하여 인프라를 설정하십시오. AWS Config를 사용하여 변경 사항을 추적하세요.",
        "C": "AWS Organizations를 사용하여 인프라를 설정합니다. AWS Service Catalog를 사용하여 변경 사항을 추적합니다.",
        "D": "AWS CloudFormation을 사용하여 인프라를 설정하십시오. AWS Service Catalog를 사용하여 변경 사항을 추적합니다."
      },
      "eng": {
        "A": "Use AWS Organizations to set up the infrastructure. Use AWS Config to track changes.",
        "B": "Use AWS CloudFormation to set up the infrastructure. Use AWS Config to track changes.",
        "C": "Use AWS Organizations to set up the infrastructure. Use AWS Service Catalog to track changes.",
        "D": "Use AWS CloudFormation to set up the infrastructure. Use AWS Service Catalog to track changes."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/128070-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 896,
    "question": {
      "kor": "회사는 VPC에서 3티어 애플리케이션을 실행합니다. 데이터베이스 계층은 MySQL DB 인스턴스용 Amazon RDS를 사용합니다.\n이 회사는 RDS for MySQL DB 인스턴스를 Amazon Aurora PostgreSQL DB 클러스터로 마이그레이션할 계획입니다. 회사에는 새 데이터베이스로 마이그레이션하는 동안 발생하는 데이터 변경 사항을 복제하는 솔루션이 필요합니다.\n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company runs a three-tier application in a VPC. The database tier uses an Amazon RDS for MySQL DB instance.\nThe company plans to migrate the RDS for MySQL DB instance to an Amazon Aurora PostgreSQL DB cluster. The company needs a solution that replicates the data changes that happen during the migration to the new database.\nWhich combination of steps will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "AWS Database Migration Service(AWS DMS) 스키마 변환을 사용하여 데이터베이스 객체를 변환합니다.",
        "B": "AWS DMS(AWS Database Migration Service) 스키마 변환을 사용하여 RDS for MySQL DB 인스턴스에 Aurora PostgreSQL 읽기 전용 복제본을 생성합니다.",
        "C": "RDS for MySQL DB 인스턴스에 대한 Aurora MySQL 읽기 전용 복제본을 구성합니다.",
        "D": "변경 데이터 캡처(CDC)를 사용하여 AWS Database Migration Service(AWS DMS) 작업을 정의하여 데이터를 마이그레이션합니다.",
        "E": "복제 지연 시간이 0일 때 Aurora PostgreSQL 읽기 전용 복제본을 독립형 Aurora PostgreSQL DB 클러스터로 승격합니다."
      },
      "eng": {
        "A": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to transform the database objects.",
        "B": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to create an Aurora PostgreSQL read replica on the RDS for MySQL DB instance.",
        "C": "Configure an Aurora MySQL read replica for the RDS for MySQL DB instance.",
        "D": "Define an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) to migrate the data.",
        "E": "Promote the Aurora PostgreSQL read replica to a standalone Aurora PostgreSQL DB cluster when the replica lag is zero."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132870-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 897,
    "question": {
      "kor": "회사는 ALB(Application Load Balancer)를 사용하여 애플리케이션을 인터넷에 제공하고 있습니다. 회사는 애플리케이션 전체에서 비정상적인 트래픽 액세스 패턴을 발견합니다. 솔루션 설계자는 회사가 이러한 이상 현상을 더 잘 이해할 수 있도록 인프라에 대한 가시성을 향상해야 합니다.\n이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?",
      "eng": "A company is using an Application Load Balancer (ALB) to present its application to the internet. The company finds abnormal traffic access patterns across the application. A solutions architect needs to improve visibility into the infrastructure to help the company understand these abnormalities better.\nWhat is the MOST operationally efficient solution that meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Athena에서 AWS CloudTrail 로그용 테이블을 생성합니다. 관련 정보에 대한 쿼리를 만듭니다.",
        "B": "Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. Amazon Athena에서 테이블을 생성하고 로그를 쿼리합니다.",
        "C": "Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. 텍스트 편집기에서 각 파일을 열고 각 줄에서 관련 정보를 검색하세요.",
        "D": "전용 Amazon EC2 인스턴스에서 Amazon EMR을 사용하여 ALB에 직접 쿼리하여 트래픽 액세스 로그 정보를 얻습니다."
      },
      "eng": {
        "A": "Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant information.",
        "B": "Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.",
        "C": "Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line for the relevant information.",
        "D": "Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire traffic access log information."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132874-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 899,
    "question": {
      "kor": "회사는 Amazon EC2, AWS Fargate 및 AWS Lambda를 사용하여 회사의 AWS 계정에서 여러 워크로드를 실행합니다. 회사는 Compute Savings Plan을 최대한 활용하기를 원합니다. 회사는 Compute Savings Plans 적용 범위가 줄어들면 알림을 받기를 원합니다.\n가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses Amazon EC2, AWS Fargate, and AWS Lambda to run multiple workloads in the company's AWS account. The company wants to fully make use of its Compute Savings Plans. The company wants to receive notification when coverage of the Compute Savings Plans drops.\nWhich solution will meet these requirements with the MOST operational efficiency?"
    },
    "choices": {
      "kor": {
        "A": "AWS 예산을 사용하여 Savings Plans에 대한 일일 예산을 생성합니다. 적절한 이메일 메시지 수신자에게 알림을 보내려면 적용 범위 임계값으로 예산을 구성하십시오.",
        "B": "Savings Plans에 대한 적용 범위 보고서를 실행하는 Lambda 함수를 생성합니다. Amazon Simple Email Service(Amazon SES)를 사용하여 해당 이메일 메시지 수신자에게 보고서를 이메일로 보냅니다.",
        "C": "Savings Plans 예산에 대한 AWS 예산 보고서를 생성합니다. 빈도를 매일로 설정하세요.",
        "D": "Savings Plans 알림 구독을 만듭니다. 모든 알림 옵션을 활성화합니다. 알림을 받으려면 이메일 주소를 입력하세요."
      },
      "eng": {
        "A": "Create a daily budget for the Savings Plans by using AWS Budgets. Configure the budget with a coverage threshold to send notifications to the appropriate email message recipients.",
        "B": "Create a Lambda function that runs a coverage report against the Savings Plans. Use Amazon Simple Email Service (Amazon SES) to email the report to the appropriate email message recipients.",
        "C": "Create an AWS Budgets report for the Savings Plans budget. Set the frequency to daily.",
        "D": "Create a Savings Plans alert subscription. Enable all notification options. Enter an email address to receive notifications."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132888-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 900,
    "question": {
      "kor": "회사의 애플리케이션은 Apache Hadoop 및 Apache Spark를 사용하여 온프레미스에서 데이터를 처리합니다. 기존 인프라는 확장이 불가능하고 관리가 복잡합니다.\n솔루션 설계자는 운영 복잡성을 줄이는 확장 가능한 솔루션을 설계해야 합니다. 솔루션은 온프레미스에서 데이터 처리를 유지해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company’s applications use Apache Hadoop and Apache Spark to process data on premises. The existing infrastructure is not scalable and is complex to manage.\nA solutions architect must design a scalable solution that reduces operational complexity. The solution must keep the data processing on premises.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Site-to-Site VPN을 사용하여 온프레미스 Hadoop 분산 파일 시스템(HDFS) 데이터 및 애플리케이션에 액세스하십시오. Amazon EMR 클러스터를 사용하여 데이터를 처리 합니다.",
        "B": "AWS DataSync를 사용하여 온프레미스 Hadoop 분산 파일 시스템(HDFS) 클러스터에 연결합니다. 데이터를 처리할 Amazon EMR 클러스터를 생성합니다.",
        "C": "Apache Hadoop 애플리케이션과 Apache Spark 애플리케이션을 AWS Outposts의 Amazon EMR 클러스터로 마이그레이션합니다. EMR 클러스터를 사용하여 데이터를 처리 합니다.",
        "D": "AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. 데이터를 처리할 Amazon EMR 클러스터를 생성합니다."
      },
      "eng": {
        "A": "Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS) data and application. Use an Amazon EMR cluster to process the data.",
        "B": "Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS) cluster. Create an Amazon EMR cluster to process the data.",
        "C": "Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.",
        "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon EMR cluster to process the data."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132891-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 911,
    "question": {
      "kor": "회사는 온프레미스 Oracle 관계형 데이터베이스에 데이터를 저장합니다. 회사는 분석을 위해 Amazon Aurora PostgreSQL에서 데이터를 사용할 수 있도록 해야 합니다. 회사는 AWS Site-to-Site VPN 연결을 사용하여 온프레미스 네트워크를 AWS에 연결합니다.\n회사는 Aurora PostgreSQL로 마이그레이션하는 동안 소스 데이터베이스에 발생하는 변경 사항을 캡처해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company stores data in an on-premises Oracle relational database. The company needs to make the data available in Amazon Aurora PostgreSQL for analysis. The company uses an AWS Site-to-Site VPN connection to connect its on-premises network to AWS.\nThe company must capture the changes that occur to the source database during the migration to Aurora PostgreSQL.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS SCT(AWS Schema Conversion Tool)를 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS) 전체 로드 마이그레이션 작업을 사용하여 데이터를 마이그레이션합니다.",
        "B": "AWS DataSync를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL로 가져옵니다.",
        "C": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS)를 사용하여 기존 데이터를 마이그레이션하고 지속적인 변경 사항을 복제합니다.",
        "D": "AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL로 가져옵니다."
      },
      "eng": {
        "A": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use the AWS Database Migration Service (AWS DMS) full-load migration task to migrate the data.",
        "B": "Use AWS DataSync to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension.",
        "C": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use AWS Database Migration Service (AWS DMS) to migrate the existing data and replicate the ongoing changes.",
        "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132999-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 915,
    "question": {
      "kor": "회사에는 참조 데이터 세트가 포함된 Amazon Elastic File System(Amazon EFS) 파일 시스템이 있습니다. 회사에는 데이터 세트를 읽어야 하는 Amazon EC2 인스턴스에 애플리케이션이 있습니다. 그러나 애플리케이션은 데이터세트를 변경할 수 없어야 합니다. 회사는 IAM 액세스 제어를 사용하여 애플리케이션이 데이터 세트를 수정하거나 삭제하지 못하도록 방지하려고 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has an Amazon Elastic File System (Amazon EFS) file system that contains a reference dataset. The company has applications on Amazon EC2 instances that need to read the dataset. However, the applications must not be able to change the dataset. The company wants to use IAM access control to prevent the applications from being able to modify or delete the dataset.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스 내에서 읽기 전용 모드로 EFS 파일 시스템을 탑재합니다.",
        "B": "EC2 인스턴스에 연결된 IAM 역할에 대한 elasticfilesystem:ClientWrite 작업을 거부하는 EFS 파일 시스템에 대한 리소스 정책을 생성합니다.",
        "C": "EFS 파일 시스템에서 elasticfilesystem:ClientWrite 작업을 거부하는 EFS 파일 시스템에 대한 ID 정책을 생성합니다.",
        "D": "각 애플리케이션에 대한 EFS 액세스 포인트를 생성합니다. POSIX(Portable Operating System Interface) 파일 권한을 사용하여 루트 디렉터리의 파일에 대한 읽기 전용 액세스를 허용합니다."
      },
      "eng": {
        "A": "Mount the EFS file system in read-only mode from within the EC2 instances.",
        "B": "Create a resource policy for the EFS file system that denies the elasticfilesystem:ClientWrite action to the IAM roles that are attached to the EC2 instances.",
        "C": "Create an identity policy for the EFS file system that denies the elasticfilesystem:ClientWrite action on the EFS file system.",
        "D": "Create an EFS access point for each application. Use Portable Operating System Interface (POSIX) file permissions to allow read-only access to files in the root directory."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133011-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 917,
    "question": {
      "kor": "한 회사가 AWS 클라우드에서 실험적인 워크로드를 실행하려고 합니다. 회사에는 클라우드 지출에 대한 예산이 있습니다. 회사의 CFO는 각 부서의 클라우드 지출 책임에 대해 우려하고 있습니다. CFO는 지출 임계값이 예산의 60%에 도달하면 알림을 받기를 원합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company wants to run its experimental workloads in the AWS Cloud. The company has a budget for cloud spending. The company's CFO is concerned about cloud spending accountability for each department. The CFO wants to receive notification when the spending threshold reaches 60% of the budget.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS 리소스의 비용 할당 태그를 사용하여 소유자에게 레이블을 지정합니다. AWS 예산에서 사용 예산을 생성합니다. 지출이 예산의 60%를 초과할 때 알림을 받을 수 있도록 경고 임계값을 추가합니다.",
        "B": "AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. AWS 비용 이상 탐지를 사용하면 지출이 예산의 60%를 초과할 때 경고 임계값 알림을 생성할 수 있습니다.",
        "C": "AWS 리소스의 비용 할당 태그를 사용하여 소유자에게 레이블을 지정합니다. AWS Trusted Advisor의 AWS Support API를 사용하면 지출이 예산의 60%를 초과할 때 경고 임계값 알림을 생성할 수 있습니다.",
        "D": "AWS Cost Explorer 예측을 사용하여 리소스 소유자를 결정합니다. AWS 예산에서 사용 예산을 생성합니다. 지출이 예산의 60%를 초과할 때 알림을 받을 수 있도록 경고 임계값을 추가합니다."
      },
      "eng": {
        "A": "Use cost allocation tags on AWS resources to label owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget.",
        "B": "Use AWS Cost Explorer forecasts to determine resource owners. Use AWS Cost Anomaly Detection to create alert threshold notifications when spending exceeds 60% of the budget.",
        "C": "Use cost allocation tags on AWS resources to label owners. Use AWS Support API on AWS Trusted Advisor to create alert threshold notifications when spending exceeds 60% of the budget.",
        "D": "Use AWS Cost Explorer forecasts to determine resource owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133015-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 922,
    "question": {
      "kor": "회사에서는 모바일 앱 사용을 추적하기 위해 보고서를 분석하고 생성하려고 합니다. 이 앱은 인기가 높으며 글로벌 사용자 기반을 보유하고 있습니다. 회사는 맞춤형 보고서 작성 프로그램을 사용하여 애플리케이션 사용량을 분석합니다.\n프로그램은 매월 마지막 주에 여러 보고서를 생성합니다. 프로그램은 각 보고서를 생성하는 데 10분 미만이 소요됩니다. 회사에서는 매월 마지막 주 외에 보고서를 생성하는 프로그램을 거의 사용하지 않습니다. 회사는 보고서를 요청할 때 최소한의 시간에 보고서를 생성하려고 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to analyze and generate reports to track the usage of its mobile app. The app is popular and has a global user base. The company uses a custom report building program to analyze application usage.\nThe program generates multiple reports during the last week of each month. The program takes less than 10 minutes to produce each report. The company rarely uses the program to generate reports outside of the last week of each month The company wants to generate reports in the least amount of time when the reports are requested.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EC2 온디맨드 인스턴스를 사용하여 프로그램을 실행합니다. 보고서가 요청되면 EC2 인스턴스를 시작하는 Amazon EventBridge 규칙을 생성합니다. 매월 마지막 주에 EC2 인스턴스를 지속적으로 실행합니다.",
        "B": "AWS Lambda에서 프로그램을 실행합니다. 보고서가 요청될 때 Lambda 함수를 실행하는 Amazon EventBridge 규칙을 생성합니다.",
        "C": "Amazon Elastic Container Service(Amazon ECS)에서 프로그램을 실행합니다. 보고서가 요청되면 프로그램을 실행하도록 Amazon ECS를 예약합니다.",
        "D": "Amazon EC2 스팟 인스턴스를 사용하여 프로그램을 실행합니다. 보고서가 요청되면 EC2 인스턴스를 시작하는 Amazon EventBndge 규칙을 생성합니다. 매월 마지막 주에 EC2 인스턴스를 지속적으로 실행합니다."
      },
      "eng": {
        "A": "Run the program by using Amazon EC2 On-Demand Instances. Create an Amazon EventBridge rule to start the EC2 instances when reports are requested. Run the EC2 instances continuously during the last week of each month.",
        "B": "Run the program in AWS Lambda. Create an Amazon EventBridge rule to run a Lambda function when reports are requested.",
        "C": "Run the program in Amazon Elastic Container Service (Amazon ECS). Schedule Amazon ECS to run the program when reports are requested.",
        "D": "Run the program by using Amazon EC2 Spot Instances. Create an Amazon EventBndge rule to start the EC2 instances when reports are requested. Run the EC2 instances continuously during the last week of each month."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133033-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 926,
    "question": {
      "kor": "회사는 AWS Batch 작업을 사용하여 일일 판매 프로세스를 실행합니다. 회사에는 AWS Batch 작업이 성공할 때 타사 보고 애플리케이션을 호출하는 서버리스 솔루션이 필요합니다. 보고 애플리케이션에는 사용자 이름과 비밀번호 인증을 사용하는 HTTP API 인터페이스가 있습니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company uses an AWS Batch job to run its end-of-day sales process. The company needs a serverless solution that will invoke a third-party reporting application when the AWS Batch job is successful. The reporting application has an HTTP API interface that uses username and password authentication.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "수신되는 AWS Batch 작업 SUCCEEDED 이벤트와 일치하도록 Amazon EventBridge 규칙을 구성합니다. 사용자 이름과 비밀번호를 사용하여 타사 API를 EventBridge API 대상으로 구성합니다. API 대상을 EventBridge 규칙 대상으로 설정합니다.",
        "B": "수신되는 AWS Batch 작업 SUCCEEDED 이벤트와 일치하도록 Amazon EventBridge Scheduler를 구성합니다. 사용자 이름과 암호를 사용하여 타사 API를 호출하도록 AWS Lambda 함수를 구성합니다. Lambda 함수를 EventBridge 규칙 대상으로 설정합니다.",
        "C": "Amazon API Gateway REST API에 작업 SUCCEEDED 이벤트를 게시하도록 AWS Batch 작업을 구성합니다. 사용자 이름과 비밀번호를 사용하여 타사 API를 호출하도록 API Gateway REST API에서 HTTP 프록시 통합을 구성합니다.",
        "D": "Amazon API Gateway REST API에 작업 SUCCEEDED 이벤트를 게시하도록 AWS Batch 작업을 구성합니다. API Gateway REST API에서 AWS Lambda 함수에 대한 프록시 통합을 구성합니다. 사용자 이름과 암호를 사용하여 타사 API를 호출하도록 Lambda 함수를 구성합니다."
      },
      "eng": {
        "A": "Configure an Amazon EventBridge rule to match incoming AWS Batch job SUCCEEDED events. Configure the third-party API as an EventBridge API destination with a username and password. Set the API destination as the EventBridge rule target.",
        "B": "Configure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events. Configure an AWS Lambda function to invoke the third-party API by using a username and password. Set the Lambda function as the EventBridge rule target.",
        "C": "Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure an HTTP proxy integration on the API Gateway REST API to invoke the third-party API by using a username and password.",
        "D": "Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure a proxy integration on the API Gateway REST API to an AWS Lambda function. Configure the Lambda function to invoke the third-party API by using a username and password."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135695-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 928,
    "question": {
      "kor": "한 회사에서 Amazon Managed Grafana를 시각화 도구로 설정하려고 합니다. 회사는 Amazon RDS 데이터베이스의 데이터를 하나의 데이터 소스로 시각화하려고 합니다. 회사에는 인터넷을 통해 데이터가 노출되지 않는 보안 솔루션이 필요합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company wants to set up Amazon Managed Grafana as its visualization tool. The company wants to visualize data from its Amazon RDS database as one data source. The company needs a secure solution that will not expose the data over the internet.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "VPC 없이 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 대한 퍼블릭 엔드포인트를 만듭니다. Amazon Managed Grafana에서 퍼블릭 엔드포인트를 데이터 소스로 구성합니다.",
        "B": "VPC에 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 대한 프라이빗 엔드포인트를 만듭니다. Amazon Managed Grafana에서 프라이빗 엔드포인트를 데이터 소스로 구성합니다.",
        "C": "VPC 없이 Amazon Managed Grafana 작업 공간을 생성합니다. AWS PrivateLink 엔드포인트를 생성하여 Amazon Managed Grafana와 Amazon RDS 간의 연결을 설정 합니다. Amazon Managed Grafana에서 Amazon RDS를 데이터 소스로 설정합니다.",
        "D": "VPC에서 Amazon Managed Grafana 작업 공간을 생성합니다. RDS 데이터베이스에 대한 퍼블릭 엔드포인트를 만듭니다. Amazon Managed Grafana에서 퍼블릭 엔드포인트를 데이터 소스로 구성합니다."
      },
      "eng": {
        "A": "Create an Amazon Managed Grafana workspace without a VPC. Create a public endpoint for the RDS database. Configure the public endpoint as a data source in Amazon Managed Grafana.",
        "B": "Create an Amazon Managed Grafana workspace in a VPC. Create a private endpoint for the RDS database. Configure the private endpoint as a data source in Amazon Managed Grafana.",
        "C": "Create an Amazon Managed Grafana workspace without a VPC. Create an AWS PrivateLink endpoint to establish a connection between Amazon Managed Grafana and Amazon RDS. Set up Amazon RDS as a data source in Amazon Managed Grafana.",
        "D": "Create an Amazon Managed Grafana workspace in a VPC. Create a public endpoint for the RDS database. Configure the public endpoint as a data source in Amazon Managed Grafana."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135697-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 929,
    "question": {
      "kor": "솔루션 아키텍트는 뒤의 개별 대상 그룹에 있는 여러 인스턴스에서 웹 애플리케이션을 ALB(Application Load Balancer) Amazon EC2 실행합니다. 사용자는 공개 웹사이트를 통해 애플리케이션에 접근할 수 있습니다.\n솔루션 아키텍트는 엔지니어가 웹 사이트의 개발 버전을 사용하여 하나의 특정 개발 EC2 인스턴스에 액세스하여 애플리케이션의 새로운 기능을 테스트할 수 있도록 허용하려고 합니다. 솔루션 아키텍트는 Amazon Route 53 호스팅 영역을 사용하여 엔지니어에게 개발 인스턴스에 대한 액세스 권한을 제공하려고 합니다. 개발 인스턴스가 교체되더라도 솔루션은 자동으로 개발 인\n스턴스로 라우팅되어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A solutions architect runs a web application on multiple Amazon EC2 instances that are in individual target groups behind an Application Load Balancer (ALB). Users can reach the application through a public website.\nThe solutions architect wants to allow engineers to use a development version of the website to access one specific development EC2 instance to test new features for the application. The solutions architect wants to use an Amazon Route 53 hosted zone to give the engineers access to the development instance. The solution must automatically route to the development instance even if the development instance is replaced.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "ALB에 값이 설정된 개발 웹 사이트에 대한 A 레코드를 생성합니다. 개발 웹 사이트에 대한 요청을 개발 인스턴스가 포함된 대상 그룹에 전달하는 리스너 규칙을 ALB에 생성합니다.",
        "B": "퍼블릭 IP 주소를 사용하여 개발 인스턴스를 다시 생성합니다. 개발 인스턴스의 퍼블릭 IP 주소로 설정된 값을 갖는 개발 웹 사이트에 대한 A 레코드를 생성합니다.",
        "C": "ALB에 값이 설정된 개발 웹 사이트에 대한 A 레코드를 생성합니다. ALB에 리스너 규칙을 생성하여 개발 웹 사이트에 대한 요청을 개발 인스턴스의 공용 IP 주소로 리디렉션합니다.",
        "D": "모든 인스턴스를 동일한 대상 그룹에 배치합니다. 개발 웹 사이트에 대한 A 레코드를 만듭니다. 값을 ALB로 설정합니다. 개발 웹 사이트에 대한 요청을 대상 그룹에 전달하는 리스너 규칙",
        "E": "을 ALB에 생성합니다."
      },
      "eng": {
        "A": "Create an A Record for the development website that has the value set to the ALB. Create a listener rule on the ALB that forwards requests for the development website to the target group that contains the development instance.",
        "B": "Recreate the development instance with a public IP address. Create an A Record for the development website that has the value set to the public IP address of the development instance.",
        "C": "Create an A Record for the development website that has the value set to the ALB. Create a listener rule on the ALB to redirect requests for the development website to the public IP address of the development instance.",
        "D": "Place all the instances in the same target group. Create an A Record for the development website. Set the value to the ALB. Create a listener rule on the ALB that forwards requests for the development website to the target group."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135726-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 943,
    "question": {
      "kor": "한 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에 영구 데이터를 저장하는 여러 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 관리형\n서비스 솔루션을 사용하여 데이터를 다른 AWS 리전에 복제해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an application on several Amazon EC2 instances that store persistent data on an Amazon Elastic File System (Amazon EFS) file system.\nThe company needs to replicate the data to another AWS Region by using an AWS managed service solution.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "EFS-EFS 백업 솔루션을 사용하여 데이터를 다른 지역의 EFS 파일 시스템에 복제하십시오.",
        "B": "야간 스크립트를 실행하여 EFS 파일 시스템의 데이터를 Amazon S3 버킷으로 복사합니다. S3 버킷에서 S3 교차 리전 복제를 활성화합니다.",
        "C": "다른 지역에 VPC를 생성합니다. 지역 간 VPC 피어를 설정합니다. 야간 rsync를 실행하여 원래 리전의 데이터를 새 리전으로 복사합니다.",
        "D": "AWS 백업을 사용하여 매일 백업을 수행하고 이를 다른 리전에 복제하는 규칙으로 백업 계획을 생성합니다. 백업 계획에 EFS 파일 시스템 리소스를 할당합니다."
      },
      "eng": {
        "A": "Use the EFS-to-EFS backup solution to replicate the data to an EFS file system in another Region.",
        "B": "Run a nightly script to copy data from the EFS file system to an Amazon S3 bucket. Enable S3 Cross-Region Replication on the S3 bucket.",
        "C": "Create a VPC in another Region. Establish a cross-Region VPC peer. Run a nightly rsync to copy data from the original Region to the new Region.",
        "D": "Use AWS Backup to create a backup plan with a rule that takes a daily backup and replicates it to another Region. Assign the EFS file system resource to the backup plan."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/137845-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 947,
    "question": {
      "kor": "한 대기업은 전 세계에 위치한 개발자에게 개발 목적으로 별도의 제한된 크기의 관리형 PostgreSQL 데이터베이스를 제공하려고 합니다. 데이터베이스의 볼륨이 적습니다. 개발자는 적극적으로 작업할 때만 데이터베이스가 필요합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A large company wants to provide its globally located developers separate, limited size, managed PostgreSQL databases for development purposes. The databases will be low volume. The developers need the databases only when they are actively working.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "개발자에게 별도의 Amazon Aurora 인스턴스를 시작할 수 있는 기능을 제공하십시오. 근무일이 끝나면 Aurora 인스턴스를 종료하고 다음 근무일이 시작될 때 Aurora 인스턴스를 시작하는 프로세스를 설정하십시오.",
        "B": "Amazon Aurora 인스턴스 시작에 대한 크기 제한을 적용하는 AWS Service Catalog 제품을 개발합니다. 개발자에게 개발 데이터베이스가 필요할 때 제품을 시작할 수 있는 액세스 권한을 부여하십시오.",
        "C": "Amazon Aurora 서버리스 클러스터를 생성합니다. 기본 용량 설정으로 클러스터에서 데이터베이스를 시작하는 AWS Service Catalog 제품을 개발합니다. 개발자에게 제품에 대한 액세스 권한을 부여합니다.",
        "D": "AWS Trusted Advisor가 유휴 Amazon RDS 데이터베이스를 확인하는지 모니터링합니다. 식별된 유휴 RDS 데이터베이스를 종료하는 프로세스를 생성합니다."
      },
      "eng": {
        "A": "Give the developers the ability to launch separate Amazon Aurora instances. Set up a process to shut down Aurora instances at the end of the workday and to start Aurora instances at the beginning of the next workday.",
        "B": "Develop an AWS Service Catalog product that enforces size restrictions for launching Amazon Aurora instances. Give the developers access to launch the product when they need a development database.",
        "C": "Create an Amazon Aurora Serverless cluster. Develop an AWS Service Catalog product to launch databases in the cluster with the default capacity settings. Grant the developers access to the product.",
        "D": "Monitor AWS Trusted Advisor checks for idle Amazon RDS databases. Create a process to terminate identified idle RDS databases."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/google/view/139065-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 948,
    "question": {
      "kor": "한 회사가 Amazon Aurora 데이터베이스에 연결되는 Amazon EC2 인스턴스 그룹을 실행할 계획입니다. 이 회사는 EC2 인스턴스와 Aurora DB 클러스터를 배포하기 위해 AWS CloudFormation 템플릿을 구축했습니다. 회사는 인스턴스가 안전한 방식으로 데이터베이스에 인증되도록 허용하려고 합니다. 회사는 정적 데이터베이스 자격 증명을 유지하고 싶지 않습니다.\n최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is planning to run a group of Amazon EC2 instances that connect to an Amazon Aurora database. The company has built an AWS\nCloudFormation template to deploy the EC2 instances and the Aurora DB cluster. The company wants to allow the instances to authenticate to the database in a secure way. The company does not want to maintain static database credentials.\nWhich solution meets these requirements with the LEAST operational effort?"
    },
    "choices": {
      "kor": {
        "A": "사용자 이름과 비밀번호를 사용하여 데이터베이스 사용자를 생성합니다. CloudFormation 템플릿에 데이터베이스 사용자 이름과 비밀번호에 대한 매개변수를 추가합니다. 인스턴스가 시작될 때 매개변수를 EC2 인스턴스에 전달합니다.",
        "B": "사용자 이름과 비밀번호를 사용하여 데이터베이스 사용자를 생성합니다. AWS Systems Manager Parameter Store에 사용자 이름과 암호를 저장합니다. Parameter Store에서 데이터베이스 자격 증명을 검색하도록 EC2 인스턴스를 구성합니다.",
        "C": "IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. IAM 인증에 사용할 데이터베이스 사용자를 생성합니다. 인스턴스의 애플리케이션이 데이터베이스에 액세스할 수 있도록 역할을 EC2 인스턴스와 연결합니다.",
        "D": "IAM 사용자와 함께 IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. IAM 사용자와 일치하는 이름을 가진 데이터베이스 사용자를 생성합니다. IAM 사용자를 EC2 인스턴스와 연결하여 인스턴스의 애플리케이션이 데이터베이스에 액세스할 수 있도록 합니다."
      },
      "eng": {
        "A": "Create a database user with a user name and password. Add parameters for the database user name and password to the CloudFormation template. Pass the parameters to the EC2 instances when the instances are launched.",
        "B": "Create a database user with a user name and password. Store the user name and password in AWS Systems Manager Parameter Store. Configure the EC2 instances to retrieve the database credentials from Parameter Store.",
        "C": "Configure the DB cluster to use IAM database authentication. Create a database user to use with IAM authentication. Associate a role with the EC2 instances to allow applications on the instances to access the database.",
        "D": "Configure the DB cluster to use IAM database authentication with an IAM user. Create a database user that has a name that matches the IAM user. Associate the IAM user with the EC2 instances to allow applications on the instances to access the database."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/google/view/139091-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 956,
    "question": {
      "kor": "회사는 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하여 Amazon EC2 인스턴스에서 프로덕션 워크로드를 실행합니다. 솔루션 설계자는 현재 EBS 볼륨 비용을 분석하고 최적화를 권장해야 합니다. 권장 사항에는 예상 월별 저축 기회가 포함되어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs its production workload on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) volumes. A solutions architect needs to analyze the current EBS volume cost and to recommend optimizations. The recommendations need to include estimated monthly saving opportunities.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Inspector 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 생성하십시오.",
        "B": "AWS 시스템 관리자 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 결정합니다.",
        "C": "Amazon CloudWatch 지표 보고를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 결정합니다.",
        "D": "AWS Compute Optimizer를 사용하여 최적화를 위한 EBS 볼륨 권장 사항을 생성합니다."
      },
      "eng": {
        "A": "Use Amazon Inspector reporting to generate EBS volume recommendations for optimization.",
        "B": "Use AWS Systems Manager reporting to determine EBS volume recommendations for optimization.",
        "C": "Use Amazon CloudWatch metrics reporting to determine EBS volume recommendations for optimization.",
        "D": "Use AWS Compute Optimizer to generate EBS volume recommendations for optimization."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/137854-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 961,
    "question": {
      "kor": "회사는 AWS Organizations에 사업부를 위한 전용 AWS 계정을 생성합니다. 최근에는 할당된 계정 소유자가 아닌 사업부 계정의 루트 사용자 이메일 주소로 중요한 알림이 전송되었습니다. 회사는 청구, 운영 또는 보안의 알림 범주에 따라 향후 모든 알림을 다른 직원에게 보낼 수 있기를 원합니다.\n이러한 요구 사항을 가장 안전하게 충족하는 솔루션은 무엇입니까?",
      "eng": "A company creates dedicated AWS accounts in AWS Organizations for its business units. Recently, an important notification was sent to the root user email address of a business unit account instead of the assigned account owner. The company wants to ensure that all future notifications can be sent to different employees based on the notification categories of billing, operations, or security.\nWhich solution will meet these requirements MOST securely?"
    },
    "choices": {
      "kor": {
        "A": "회사에서 관리하는 단일 이메일 주소를 사용하도록 각 AWS 계정을 구성합니다. 모든 계정 소유자가 이메일 계정에 액세스하여 알림을 받을 수 있는지 확인하십시오. 각 사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 목록을 사용하여 각 AWS 계정에 대한 대체 연락처를 구성합니다.",
        "B": "회사가 관리하는 각 사업부에 대해 서로 다른 이메일 배포 목록을 사용하도록 각 AWS 계정을 구성합니다. 경고에 응답할 수 있는 관리자 이메일 주소로 각 배포 목록을 구성합니다. 각 사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 목록을 사용하여 각 AWS 계정에 대한 대체 연락처를 구성합니다.",
        "C": "각 AWS 계정 루트 사용자 이메일 주소를 각 사업부에서 한 사람의 개별 회사 관리 이메일 주소로 구성합니다. 각 사업부의 결제 팀, 보안 팀 및 운영 팀에 대한 해당 배포 목록을 사용하여 각 AWS 계정에 대한 대체 연락처를 구성합니다.",
        "D": "중앙 집중식 사서함으로 이동하는 이메일 별칭을 사용하도록 각 AWS 계정 루트 사용자를 구성합니다. 청구 팀, 보안 팀 및 운영 팀에 대해 각각 단일 비즈니스 관리 이메일 배포 목록을 사용하여 각 계정에 대한 대체 연락처를 구성합니다."
      },
      "eng": {
        "A": "Configure each AWS account to use a single email address that the company manages. Ensure that all account owners can access the email account to receive notifications. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
        "B": "Configure each AWS account to use a different email distribution list for each business unit that the company manages. Configure each distribution list with administrator email addresses that can respond to alerts. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
        "C": "Configure each AWS account root user email address to be the individual company managed email address of one person from each business unit. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
        "D": "Configure each AWS account root user to use email aliases that go to a centralized mailbox. Configure alternate contacts for each account by using a single business managed email distribution list each for the billing team, the security team, and the operations team."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139746-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 963,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스와 AWS Lambda 함수를 사용하여 애플리케이션을 실행합니다. EC2 인스턴스는 VPC의 프라이빗 서브넷에서 실행됩니다. 애플리케이션이 작동하려면 Lambda 함수가 EC2 인스턴스에 대한 직접 네트워크 액세스가 필요합니다.\n신청은 1년 동안 진행됩니다. 애플리케이션이 사용하는 Lambda 함수의 수는 1년 동안 증가합니다. 회사는 모든 애플리케이션 리소스에 대한 비용을 최소화해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs its application by using Amazon EC2 instances and AWS Lambda functions. The EC2 instances run in private subnets of a VPC. The Lambda functions need direct network access to the EC2 instances for the application to work.\nThe application will run for 1 year. The number of Lambda functions that the application uses will increase during the 1-year period. The company must minimize costs on all application resources.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "EC2 Instance Savings Plan을 구매하세요. EC2 인스턴스가 포함된 프라이빗 서브넷에 Lambda 함수를 연결합니다.",
        "B": "EC2 인스턴스 Savings Plan을 구매하세요. EC2 인스턴스가 실행되는 동일한 VPC의 새 퍼블릭 서브넷에 Lambda 함수를 연결합니다.",
        "C": "Compute Savings Plan을 구매하세요. EC2 인스턴스가 포함된 프라이빗 서브넷에 Lambda 함수를 연결합니다.",
        "D": "Compute Savings Plan을 구매하세요. Lambda 서비스 VPC에 Lambda 함수를 유지합니다."
      },
      "eng": {
        "A": "Purchase an EC2 Instance Savings Plan. Connect the Lambda functions to the private subnets that contain the EC2 instances.",
        "B": "Purchase an EC2 Instance Savings Plan. Connect the Lambda functions to new public subnets in the same VPC where the EC2 instances run.",
        "C": "Purchase a Compute Savings Plan. Connect the Lambda functions to the private subnets that contain the EC2 instances.",
        "D": "Purchase a Compute Savings Plan. Keep the Lambda functions in the Lambda service VPC."
      }
    },
    "category": [
      "Cost"
    ],
    "subcategory": [
      "EC2 Instance Savings Plan",
      "Compute Savings Plan",
      "Lambda"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/138489-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 964,
    "question": {
      "kor": "한 회사가 AWS Control Tower를 사용하여 AWS에 다중 계정 전략을 배포했습니다. 회사는 각 개발자에게 개별 AWS 계정을 제공했습니다. 회사는 개발자에게 발생하는 AWS 리소스 비용을 제한하기 위한 제어 기능을 구현하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has deployed a multi-account strategy on AWS by using AWS Control Tower. The company has provided individual AWS accounts to each of its developers. The company wants to implement controls to limit AWS resource costs that the developers incur.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "각 개발자에게 CostCenter 키와 개발자 이름 값이 있는 태그를 사용하여 모든 리소스에 태그를 지정하도록 지시합니다. 필수 태그 AWS Config 관리형 규칙을 사용하여 태그를 확인하세요. 태그가 없는 리소스를 종료하는 AWS Lambda 함수를 생성합니다. 지출을 모니터링하기 위해 각 개발자에게 일일 보고서를 보내도록 AWS Cost Explorer를 구성합니다.",
        "B": "AWS 예산을 사용하여 각 개발자 계정에 대한 예산을 설정합니다. 실제 및 예측 값에 대한 예산 알림을 설정하여 할당된 예산을 초과하거나 초과할 것으로 예상되는 경우 개발자에게 알립니다. AWS Budgets 작업을 사용하여 개발자의 IAM 역할에 DenyAll 정책을 적용하면 할당된 예산에 도달할 때 추가 리소스가 시작되는 것을 방지할 수 있습니다.",
        "C": "AWS Cost Explorer를 사용하여 각 개발자 계정의 비용을 모니터링하고 보고합니다. 지출을 모니터링하기 위해 각 개발자에게 일일 보고서를 보내도록 Cost Explorer를 구성합니다. AWS 비용 이상 탐지를 사용하여 비정상적인 지출을 탐지하고 알림을 제공합니다.",
        "D": "AWS Service Catalog를 사용하면 개발자가 제한된 비용 범위 내에서 리소스를 시작할 수 있습니다. 각 AWS 계정에 AWS Lambda 함수를 생성하여 각 근무일이 끝나면 리소스 실행을 중지합니다. 각 근무일이 시작될 때 리소스를 재개하도록 Lambda 함수를 구성합니다."
      },
      "eng": {
        "A": "Instruct each developer to tag all their resources with a tag that has a key of CostCenter and a value of the developer's name. Use the required-tags AWS Config managed rule to check for the tag. Create an AWS Lambda function to terminate resources that do not have the tag. Configure AWS Cost Explorer to send a daily report to each developer to monitor their spending.",
        "B": "Use AWS Budgets to establish budgets for each developer account. Set up budget alerts for actual and forecast values to notify developers when they exceed or expect to exceed their assigned budget. Use AWS Budgets actions to apply a DenyAll policy to the developer's IAM role to prevent additional resources from being launched when the assigned budget is reached.",
        "C": "Use AWS Cost Explorer to monitor and report on costs for each developer account. Configure Cost Explorer to send a daily report to each developer to monitor their spending. Use AWS Cost Anomaly Detection to detect anomalous spending and provide alerts.",
        "D": "Use AWS Service Catalog to allow developers to launch resources within a limited cost range. Create AWS Lambda functions in each AWS account to stop running resources at the end of each work day. Configure the Lambda functions to resume the resources at the start of each work day."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139799-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  }
]