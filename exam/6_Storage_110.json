[
  {
    "idx": 193,
    "question": {
      "kor": "한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리를 위해 가능한 최대 I/O 성능을 갖춘 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 내구성이 뛰어난 스토리지, 더 이상 사용하지 않는 아카이브 미디어에 대한 요구 사항을 충족하기 위해 900TB의 스토리지가 필요합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 추천해야 하는 서비스 세트는 무엇입니까?",
      "eng": "A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.\nWhich set of services should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "최대 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier",
        "B": "최대 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, 아카이브 스토리지를 위한 Amazon S3 Glacier",
        "C": "최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, 아카이브 스토리지를 위한 Amazon S3",
        "D": "최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier"
      },
      "eng": {
        "A": "Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage",
        "B": "Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage",
        "C": "Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage",
        "D": "Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Basic",
      "EBS",
      "EC2 instance store",
      "S3",
      "S3 Glacier"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85432-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 258,
    "question": {
      "kor": "회사는 비디오 콘텐츠를 게시하고 모든 모바일 플랫폼에서 사용할 수 있도록 트랜스코딩하는 온라인 서비스를 제공합니다. 애플리케이션 아키텍처는 Amazon Elastic File System(Amazon EFS) Standard를 사용하여 여러 Amazon EC2 Linux 인스턴스가 처리를 위해 비디오 콘텐츠에 액세스할 수 있도록 비디오를 수집하고 저장합니다. 시간이 지남에 따라 서비스의 인기가 높아짐에 따라 스토리지 비용이 너무 비싸졌습니다.\n가장 비용 효율적인 스토리지 솔루션은 무엇입니까?",
      "eng": "A company provides an online service for posting video content and transcoding it for use by any mobile platform. The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing. As the popularity of the service has grown over time, the storage costs have become too expensive.\nWhich storage solution is MOST cost-effective?"
    },
    "choices": {
      "kor": {
        "A": "파일용 AWS Storage Gateway를 사용하여 동영상 콘텐츠를 저장하고 처리합니다.",
        "B": "볼륨에 AWS Storage Gateway를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.",
        "C": "Amazon EFS를 사용하여 비디오 콘텐츠를 저장합니다. 처리가 완료되면 파일을 Amazon Elastic Block Store(Amazon EBS)로 전송합니다.",
        "D": "동영상 콘텐츠 저장을 위해 Amazon S3를 사용합니다. 처리를 위해 파일을 서버에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 임시로 이동합니다."
      },
      "eng": {
        "A": "Use AWS Storage Gateway for files to store and process the video content.",
        "B": "Use AWS Storage Gateway for volumes to store and process the video content.",
        "C": "Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).",
        "D": "Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Basic",
      "EBS",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99509-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 866,
    "question": {
      "kor": "한 회사는 다양한 브랜드에 대해 AWS에서 여러 웹 사이트를 운영하고 있습니다. 각 웹사이트는 매일 수십 기가바이트의 웹 트래픽 로그를 생성합니다. 솔루션 설계자는 회사 개발자가 회사 전체 웹사이트의 트래픽 패턴을 분석할 수 있는 능력을 제공하기 위해 확장 가능한 솔루션을 설계해야 합니다. 개발자의 이 분석은 몇 달에 걸쳐 일주일에 한 번씩 요청 시 수행됩니다. 솔루션은 표준 SQL을 사용한 쿼리를 지원해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3에 로그를 저장합니다. Amazon Athena 토르 분석을 사용하세요.",
        "B": "Amazon RDS에 로그를 저장합니다. 분석을 위해 데이터베이스 클라이언트를 사용합니다.",
        "C": "Amazon OpenSearch Service에 로그를 저장합니다. 분석을 위해 OpenSearch 서비스를 사용하세요.",
        "D": "Amazon EMR 클러스터에 로그를 저장합니다. SQL 기반 분석을 위해 지원되는 오픈 소스 프레임워크를 사용합니다."
      },
      "eng": {
        "A": "Store the logs in Amazon S3. Use Amazon Athena tor analysis.",
        "B": "Store the logs in Amazon RDS. Use a database client for analysis.",
        "C": "Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis.",
        "D": "Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL-based analysis."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Basic",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125581-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 82,
    "question": {
      "kor": "회사에서 대량의 생산 데이터를 동일한 AWS 리전의 테스트 환경으로 복제하는 기능을 개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon EC2 인스턴스에 저장됩니다. 복제된 데이터에 대한 수정은 생산 환경에 영향을 미치지 않아야 합니다. 이 데이터에 액세스하는 소프트웨어에는 지속적으로 높은 I/O 성능이 필요합니다.\n솔루션 설계자는 프로덕션 데이터를 테스트 환경으로 복제하는 데 필요한 시간을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to improve its ability to clone large amounts of production data into a test environment in the same AWS Region. The data is stored in Amazon EC2 instances on Amazon Elastic Block Store (Amazon EBS) volumes. Modifications to the cloned data must not affect the production environment.\nThe software that accesses this data requires consistently high I/O performance.\nA solutions architect needs to minimize the time that is required to clone the production data into the test environment.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 테스트 환경의 EC2 인스턴스 스토어 볼륨에 스냅샷을 복원합니다.",
        "B": "EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS 볼륨의 EBS 스냅샷을 생성합니다. 프로덕션 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "C": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 새 EBS 볼륨을 생성하고 초기화합니다. 프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 새 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "D": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 기능을 켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경에서 새 EBS 볼륨을 EC2 인스턴스에 연결합니다."
      },
      "eng": {
        "A": "Take EBS snapshots of the production EBS volumes. Restore the snapshots onto EC2 instance store volumes in the test environment.",
        "B": "Configure the production EBS volumes to use the EBS Multi-Attach feature. Take EBS snapshots of the production EBS volumes. Attach the production EBS volumes to the EC2 instances in the test environment.",
        "C": "Take EBS snapshots of the production EBS volumes. Create and initialize new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment before restoring the volumes from the production EBS snapshots.",
        "D": "Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EBS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 61,
    "question": {
      "kor": "회사의 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 카탈로그의 가용성이 높고 카탈로그가 안정적인 위치에 저장되기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company's website uses an Amazon EC2 instance store for its catalog of items. The company wants to make sure that the catalog is highly available and that the catalog is stored in a durable location.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Redis용 Amazon ElastiCache로 카탈로그를 이동합니다.",
        "B": "더 큰 인스턴스 저장소가 있는 더 큰 EC2 인스턴스를 배포합니다.",
        "C": "인스턴스 스토어에서 Amazon S3 Glacier Deep Archive로 카탈로그를 이동합니다.",
        "D": "카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다."
      },
      "eng": {
        "A": "Move the catalog to Amazon ElastiCache for Redis.",
        "B": "Deploy a larger EC2 instance with a larger instance store.",
        "C": "Move the catalog from the instance store to Amazon S3 Glacier Deep Archive.",
        "D": "Move the catalog to an Amazon Elastic File System (Amazon EFS) file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 74,
    "question": {
      "kor": "회사에서 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 수십 기가바이트에서 수백 테라바이트에 이르는 다양한 크기의 출력 파일을 생성합니다. 애플리\n케이션 데이터는 표준 파일 시스템 구조에 저장되어야 합니다. 회사는 자동으로 확장되는 솔루션을 원합니다. 가용성이 높고 최소한의 운영 오버헤드가 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to migrate its on-premises application to AWS. The application produces output files that vary in size from tens of gigabytes to hundreds of terabytes. The application data must be stored in a standard file system structure. The company wants a solution that scales automatically. is highly available, and requires minimum operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic Container Service(Amazon ECS)에서 컨테이너로 실행되도록 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon S3를 사용합니다.",
        "B": "Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너로 실행되도록 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon Elastic Block Store(Amazon EBS)를 사용합니다.",
        "C": "다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 스토리지에 Amazon Elastic File System(Amazon EFS)을 사용합니다.",
        "D": "다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon Elastic Block Store(Amazon EBS)를 사용합니다."
      },
      "eng": {
        "A": "Migrate the application to run as containers on Amazon Elastic Container Service (Amazon ECS). Use Amazon S3 for storage.",
        "B": "Migrate the application to run as containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Block Store (Amazon EBS) for storage.",
        "C": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.",
        "D": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic Block Store (Amazon EBS) for storage."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS",
      "auto scaling",
      "availability"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 113,
    "question": {
      "kor": "회사는 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 둘 다 Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 한 하위 집합 또는 다른 하위 집합을 볼 수 있지만 동시에 모든 문서를 볼 수는 없다고 보고했습니다.\n사용자가 모든 문서를 한 번에 볼 수 있도록 하기 위해 솔루션 설계자는 무엇을 제안해야 합니까?",
      "eng": "A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.\nWhat should a solutions architect propose to ensure users see all of their documents at once?"
    },
    "choices": {
      "kor": {
        "A": "두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다.",
        "B": "문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 구성",
        "C": "두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 새 문서를 Amazon EFS에 저장하도록 애플리케이션 수정",
        "D": "두 서버 모두에 요청을 보내도록 Application Load Balancer를 구성합니다. 올바른 서버에서 각 문서 반환"
      },
      "eng": {
        "A": "Copy the data so both EBS volumes contain all the documents",
        "B": "Configure the Application Load Balancer to direct a user to the server with the documents",
        "C": "Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS",
        "D": "Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 387,
    "question": {
      "kor": "회사에서 Amazon Elastic Container Service(Amazon ECS)를 사용할 컨테이너화된 애플리케이션을 설계하고 있습니다. 애플리케이션은 내구성이 뛰어나고 RPO(복구 지점 목표)가 8시간인 다른 AWS 리전에 데이터를 복구할 수 있는 공유 파일 시스템에 액세스해야 합니다. 파일 시스템은 리전 내의 각 가용 영역에 탑재 대상을 제공해야 합니다.\n솔루션 설계자는 AWS Backup을 사용하여 다른 리전에 대한 복제를 관리하려고 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is designing a containerized application that will use Amazon Elastic Container Service (Amazon ECS). The application needs to access a shared file system that is highly durable and can recover data to another AWS Region with a recovery point objective (RPO) of 8 hours. The file system needs to provide a mount target m each Availability Zone within a Region.\nA solutions architect wants to use AWS Backup to manage the replication to another Region.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "다중 AZ 배포가 있는 Windows 파일 서버용 Amazon FSx",
        "B": "다중 AZ 배포가 있는 NetApp ONTAP용 Amazon FSx",
        "C": "표준 스토리지 클래스가 있는 Amazon Elastic File System(Amazon EFS)",
        "D": "OpenZFS용 Amazon FSx"
      },
      "eng": {
        "A": "Amazon FSx for Windows File Server with a Multi-AZ deployment",
        "B": "Amazon FSx for NetApp ONTAP with a Multi-AZ deployment",
        "C": "Amazon Elastic File System (Amazon EFS) with the Standard storage class",
        "D": "Amazon FSx for OpenZFS"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109456-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 351,
    "question": {
      "kor": "솔루션 설계자는 고객 사례 파일을 저장할 시스템을 설계해야 합니다. 파일은 핵심 회사 자산이며 중요합니다. 파일 수는 시간이 지남에 따라 증가합니다.\n파일은 Amazon EC2 인스턴스에서 실행되는 여러 애플리케이션 서버에서 동시에 액세스할 수 있어야 합니다. 솔루션에는 중복성이 내장되어 있어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A solutions architect needs to design a system to store client case files. The files are core company assets and are important. The number of files will grow over time.\nThe files must be simultaneously accessible from multiple application servers that run on Amazon EC2 instances. The solution must have built-in redundancy.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic File System(Amazon EFS)",
        "B": "Amazon Elastic Block Store(Amazon EBS)",
        "C": "Amazon S3 Glacier Deep 아카이브",
        "D": "AWS 백업"
      },
      "eng": {
        "A": "Amazon Elastic File System (Amazon EFS)",
        "B": "Amazon Elastic Block Store (Amazon EBS)",
        "C": "Amazon S3 Glacier Deep Archive",
        "D": "AWS Backup"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95024-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 390,
    "question": {
      "kor": "회사에서 해당 애플리케이션을 위한 스토리지 솔루션을 찾고 있습니다. 솔루션은 가용성과 확장성이 높아야 합니다. 또한 솔루션은 기본 프로토콜을 통해 AWS 및 온프레미스의 여러 Linux 인스턴스에 의해 마운트될 수 있고 최소 크기 요구 사항이 없는 파일 시스템으로 작동해야 합니다. 회사는 온프레미스 네트워크에서 VPC로 액세스하기 위해 사이트 간 VPN을 설정했습니다.\n이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?",
      "eng": "A company seeks a storage solution for its application. The solution must be highly available and scalable. The solution also must function as a file system be mountable by multiple Linux instances in AWS and on premises through native protocols, and have no minimum size requirements. The company has set up a Site-to-Site VPN for access from its on-premises network to its VPC.\nWhich storage solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon FSx 다중 AZ 배포",
        "B": "Amazon Elastic Block Store(Amazon EBS) 다중 연결 볼륨",
        "C": "탑재 대상이 여러 개인 Amazon Elastic File System(Amazon EFS)",
        "D": "단일 탑재 대상 및 여러 액세스 지점이 있는 Amazon Elastic File System(Amazon EFS)"
      },
      "eng": {
        "A": "Amazon FSx Multi-AZ deployments",
        "B": "Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes",
        "C": "Amazon Elastic File System (Amazon EFS) with multiple mount targets",
        "D": "Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109665-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 651,
    "question": {
      "kor": "솔루션 설계자는 여러 가용 영역에 배포되는 웹 애플리케이션용 공유 스토리지 솔루션을 설계하고 있습니다. 웹 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. 회사는 내용을 수시로 변경할 계획입니다. 솔루션은 변경사항이 발생하는 즉시 새 콘텐츠를 반환하는 강력한 일관성을 가져야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones. The web application runs on Amazon EC2 instances that are in an Auto Scaling group. The company plans to make frequent changes to the content. The solution must have strong consistency in returning the new content as soon as the changes occur.\nWhich solutions meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "개별 EC2 인스턴스에 탑재된 AWS Storage Gateway 볼륨 게이트웨이 iSCSI(Internet Small Computer Systems Interface) 블록 스토리지를 사용합니다.",
        "B": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 개별 EC2 인스턴스에 EFS 파일 시스템을 탑재합니다.",
        "C": "공유 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 개별 EC2 인스턴스에 EBS 볼륨을 탑재합니다.",
        "D": "AWS DataSync를 사용하여 Auto Scaling 그룹의 EC2 호스트 간에 데이터를 지속적으로 동기화합니다.",
        "E": "웹 콘텐츠를 저장할 Amazon S3 버킷을 생성합니다. Cache-Control 헤더의 메타데이터를 no-cache로 설정합니다. Amazon CloudFront를 사용하여 콘텐츠를 제공합니다."
      },
      "eng": {
        "A": "Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.",
        "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.",
        "C": "Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.",
        "D": "Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.",
        "E": "Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132853-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 697,
    "question": {
      "kor": "한 회사가 문서 관리 애플리케이션을 AWS로 마이그레이션하고 있습니다. 애플리케이션은 Linux 서버에서 실행됩니다.\n회사는 애플리케이션을 Auto Scaling 그룹의 Amazon EC2 인스턴스로 마이그레이션합니다. 회사는 공유 스토리지 파일 시스템에 7TiB의 문서를 저장합니다. 외부 관계형 데이터베이스가 문서를 추적합니다.\n문서는 한 번 저장되며 언제든지 참조를 위해 여러 번 검색할 수 있습니다. 회사는 마이그레이션 도중 애플리케이션을 수정할 수 없습니다. 스토리지 솔루션은 가용성이 높아야 하며 시간에 따른 확장을 지원해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is migrating a document management application to AWS. The application runs on Linux servers.\nThe company will migrate the application to Amazon EC2 instances in an Auto Scaling group. The company stores 7 TiB of documents in a shared storage file system. An external relational database tracks the documents.\nDocuments are stored once and can be retrieved multiple times for reference at any time. The company cannot modify the application during the migration.\nThe storage solution must be highly available and must support scaling over time.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "향상된 네트워킹을 갖춘 EC2 인스턴스를 공유 NFS 스토리지 시스템으로 배포합니다. NFS 공유를 내보냅니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다.",
        "B": "S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon S3 버킷을 생성합니다. Auto Scaling 그룹의 EC2 인스턴스에 S3 버킷을 탑재합니다.",
        "C": "SFTP용 AWS 전송 및 Amazon S3 버킷을 사용하여 SFTP 서버 엔드포인트를 배포합니다. SFTP 서버에 연결하도록 Auto Scaling 그룹의 EC2 인스턴스를 구성합니다.",
        "D": "여러 가용 영역에 마운트 지점이 있는 Amazon EFS(Amazon Elastic File System) 파일 시스템을 생성합니다. EFS Standard-Infrequent Access(Standard-IA) 스토리지 클래스를 사용합니다. Auto Scaling 그룹의 EC2 인스턴스에 NFS 공유를 탑재합니다."
      },
      "eng": {
        "A": "Deploy an EC2 instance with enhanced networking as a shared NFS storage system. Export the NFS share. Mount the NFS share on the EC2 instances in the Auto Scaling group.",
        "B": "Create an Amazon S3 bucket that uses the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Mount the S3 bucket on the EC2 instances in the Auto Scaling group.",
        "C": "Deploy an SFTP server endpoint by using AWS Transfer for SFTP and an Amazon S3 bucket. Configure the EC2 instances in the Auto Scaling group to connect to the SFTP server.",
        "D": "Create an Amazon EFS (Amazon Elastic File System) file system with mount points in multiple Availability Zones. Use the EFS Standard-Infrequent Access (Standard-IA) storage class. Mount the NFS share on the EC2 instances in the Auto Scaling group."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "EFS"
    ],
    "rote_memorization": false,
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 10,
    "question": {
      "kor": "회사는 Amazon DynamoDB를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 실행합니다. 데이터 손상의 경우 솔루션 설계자는 15분의 RPO(복구 지점 목표)와 1시간의 RTO(복구 시간 목표)를 충족하는 솔루션을 설계해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company runs a shopping application that uses Amazon DynamoDB to store customer information. In case of data corruption, a solutions architect needs to design a solution that meets a recovery point objective (RPO) of 15 minutes and a recovery time objective (RTO) of 1 hour.\nWhat should the solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB 전역 테이블을 구성합니다. RPO 복구의 경우 애플리케이션이 다른 AWS 리전을 가리키도록 합니다.",
        "B": "DynamoDB 특정 시점으로 복구를 구성합니다. RPO 복구를 위해 원하는 시점으로 복원합니다.",
        "C": "매일 DynamoDB 데이터를 Amazon S3 Glacier로 내보냅니다. RPO 복구를 위해 S3 Glacier에서 DynamoDB로 데이터를 가져옵니다.",
        "D": "15분마다 DynamoDB 테이블에 대한 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 예약합니다. RPO 복구의 경우 EBS 스냅샷을 사용하여 DynamoDB 테이블을 복원합니다."
      },
      "eng": {
        "A": "Configure DynamoDB global tables. For RPO recovery, point the application to a different AWS Region.",
        "B": "Configure DynamoDB point-in-time recovery. For RPO recovery, restore to the desired point in time.",
        "C": "Export the DynamoDB data to Amazon S3 Glacier on a daily basis. For RPO recovery, import the data from S3 Glacier to DynamoDB.",
        "D": "Schedule Amazon Elastic Block Store (Amazon EBS) snapshots for the DynamoDB table every 15 minutes. For RPO recovery, restore the DynamoDB table by using the EBS snapshot."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "recovery point objective",
      "recovery time objective"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85603-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 51,
    "question": {
      "kor": "회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 관심이 있습니다. 테이블은 대부분의 아침에 사용되지 않습니다. 저녁에는 읽기 및 쓰기 트래픽을 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur, they will happen very quickly.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.",
        "B": "글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.",
        "C": "프로비저닝된 용량과 Auto Scaling으로 DynamoDB 테이블을 생성합니다.",
        "D": "프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 글로벌 테이블로 구성합니다."
      },
      "eng": {
        "A": "Create a DynamoDB table in on-demand capacity mode.",
        "B": "Create a DynamoDB table with a global secondary index.",
        "C": "Create a DynamoDB table with provisioned capacity and auto scaling.",
        "D": "Create a DynamoDB table in provisioned capacity mode, and configure it as a global table."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "mode",
      "scaling"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 181,
    "question": {
      "kor": "엔터테인먼트 회사는 Amazon DynamoDB를 사용하여 미디어 메타데이터를 저장하고 있습니다. 애플리케이션이 읽기 집약적이며 지연이 발생합니다. 회사에는 추가 운영 오버헤드를 처리할 직원이 없으며 애플리케이션을 재구성하지 않고 DynamoDB의 성능 효율성을 개선해야 합니다.\n이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "An entertainment company is using Amazon DynamoDB to store media metadata. The application is read intensive and experiencing delays. The company does not have staff to handle additional operational overhead and needs to improve the performance efficiency of DynamoDB without reconfiguring the application.\nWhat should a solutions architect recommend to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "Redis용 Amazon ElastiCache를 사용합니다.",
        "B": "Amazon DynamoDB Accelerator(DAX)를 사용합니다.",
        "C": "DynamoDB 전역 테이블을 사용하여 데이터를 복제합니다.",
        "D": "자동 검색이 활성화된 Memcached용 Amazon ElastiCache를 사용합니다."
      },
      "eng": {
        "A": "Use Amazon ElastiCache for Redis.",
        "B": "Use Amazon DynamoDB Accelerator (DAX).",
        "C": "Replicate data by using DynamoDB global tables.",
        "D": "Use Amazon ElastiCache for Memcached with Auto Discovery enabled."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "DAX"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87572-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 235,
    "question": {
      "kor": "기상 스타트업 회사는 사용자에게 날씨 데이터를 온라인으로 판매하는 맞춤형 웹 애플리케이션을 보유하고 있습니다. 이 회사는 Amazon DynamoDB를 사용하여 데이터를 저장하고 새로운 날씨 이벤트가 기록될 때마다 4개의 내부 팀 관리자에게 경고를 보내는 새로운 서비스를 구축하려고 합니다. 회사는 이 새로운 서비스가 현재 애플리케이션의 성능에 영향을 미치는 것을 원하지 않습니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application.\nWhat should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB 트랜잭션을 사용하여 새 이벤트 데이터를 테이블에 씁니다. 내부 팀에 알리도록 트랜잭션을 구성합니다.",
        "B": "현재 애플리케이션이 4개의 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시하도록 합니다. 각 팀이 하나의 주제를 구독하도록 합니다.",
        "C": "테이블에서 Amazon DynamoDB 스트림을 활성화합니다. 트리거를 사용하여 팀이 구독할 수 있는 단일 Amazon Simple Notification Service(Amazon SNS) 주제에 씁니다.",
        "D": "각 레코드에 사용자 정의 속성을 추가하여 새 항목에 플래그를 지정합니다. 새 항목이 있는지 매분 테이블을 스캔하고 팀이 구독할 수 있는 Amazon Simple Queue Service(Amazon SQS) 대기열에 알리는 cron 작업을 작성합니다."
      },
      "eng": {
        "A": "Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.",
        "B": "Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.",
        "C": "Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.",
        "D": "Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe."
      }
    },
    "category": [
      "Database"
    ],
    "subcategory": [
      "DynamoDB Streams"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102169-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 250,
    "question": {
      "kor": "회사는 웨어러블 장치를 사용하는 많은 참가자로부터 데이터를 수집합니다. 회사는 데이터를 Amazon DynamoDB 테이블에 저장하고 애플리케이션을 사용하여 데이터를 분석합니다. 데이터 워크로드는 일정하고 예측 가능합니다. 회사는 DynamoDB에 대한 예상 예산 이하를 유지하려고 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "프로비저닝 모드와 DynamoDB Standard-Infrequent Access(DynamoDB Standard-IA)를 사용합니다. 예상 워크로드에 대한 용량을 예약합니다.",
        "B": "프로비저닝 모드를 사용합니다. RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 지정합니다.",
        "C": "주문형 모드를 사용합니다. 읽기 용량 단위(RCU) 및 쓰기 용량 단위(WCU)를 워크로드의 변경 사항을 수용할 수 있을 만큼 높게 설정합니다.",
        "D": "주문형 모드를 사용합니다. 예약 용량이 있는 RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 지정합니다."
      },
      "eng": {
        "A": "Use provisioned mode and DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA). Reserve capacity for the forecasted workload.",
        "B": "Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).",
        "C": "Use on-demand mode. Set the read capacity units (RCUs) and write capacity units (WCUs) high enough to accommodate changes in the workload.",
        "D": "Use on-demand mode. Specify the read capacity units (RCUs) and write capacity units (WCUs) with reserved capacity."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "capacity mode"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100222-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 252,
    "question": {
      "kor": "회사에서 Oracle 데이터베이스를 AWS로 마이그레이션하려고 합니다. 데이터베이스는 지리 코드로 식별되는 고해상도 지리 정보 시스템(GIS) 이미지 수백만 개가 포함된 단일 테이블로 구성됩니다.\n자연 재해가 발생하면 몇 분마다 수만 개의 이미지가 업데이트됩니다. 각 지리적 코드에는 연결된 단일 이미지 또는 행이 있습니다. 회사는 이러한 이벤트 중에 가용성과 확장성이 뛰어난 솔루션을 원합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code.\nWhen a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events.\nWhich solution meets these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "이미지와 지리적 코드를 데이터베이스 테이블에 저장합니다. Amazon RDS 다중 AZ DB 인스턴스에서 실행되는 Oracle을 사용합니다.",
        "B": "Amazon S3 버킷에 이미지를 저장합니다. 지리적 코드를 키로, 이미지 S3 URL을 값으로 사용하여 Amazon DynamoDB를 사용합니다.",
        "C": "Amazon DynamoDB 테이블에 이미지와 지리적 코드를 저장합니다. 부하가 높은 시간 동안 DynamoDB Accelerator(DAX)를 구성합니다.",
        "D": "Amazon S3 버킷에 이미지를 저장합니다. 지리 코드와 이미지 S3 URL을 데이터베이스 테이블에 저장합니다. Amazon RDS 다중 AZ DB 인스턴스에서 실행되는 Oracle을 사용합니다."
      },
      "eng": {
        "A": "Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.",
        "B": "Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.",
        "C": "Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.",
        "D": "Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi- AZ DB instance."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102136-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 256,
    "question": {
      "kor": "한 회사에서 Auto Scaling 그룹의 클라이언트와 서버 간의 통신에 UDP를 사용하는 실시간 멀티플레이어 게임을 개발하고 있습니다. 하루 동안 수요가 급증할 것으로 예상되므로 게임 서버 플랫폼은 그에 따라 적응해야 합니다. 개발자는 개입 없이 확장되는 데이터베이스 솔루션에 게이머 점수 및 기타 비관계형 데이터를 저장하기를 원합니다.\n솔루션 설계자는 어떤 솔루션을 추천해야 합니까?",
      "eng": "A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention.\nWhich solution should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "트래픽 분산에는 Amazon Route 53을 사용하고 데이터 저장에는 Amazon Aurora Serverless를 사용합니다.",
        "B": "트래픽 분산을 위해 Network Load Balancer를 사용하고 데이터 저장을 위해 주문형 Amazon DynamoDB를 사용합니다.",
        "C": "트래픽 분산을 위해 Network Load Balancer를 사용하고 데이터 저장을 위해 Amazon Aurora Global Database를 사용합니다.",
        "D": "트래픽 분산을 위해 Application Load Balancer를 사용하고 데이터 저장을 위해 Amazon DynamoDB 전역 테이블을 사용합니다."
      },
      "eng": {
        "A": "Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.",
        "B": "Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.",
        "C": "Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.",
        "D": "Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "NLB",
      "capacity mode"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102143-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 264,
    "question": {
      "kor": "한 회사가 AWS에서 멀티플레이어 게임 애플리케이션을 호스팅합니다. 회사는 애플리케이션이 밀리초 미만의 대기 시간으로 데이터를 읽고 기록 데이터에 대해 일회성 쿼리를 실행하기를 원합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "자주 액세스하는 데이터에는 Amazon RDS를 사용합니다. 주기적으로 사용자 지정 스크립트를 실행하여 데이터를 Amazon S3 버킷으로 내보냅니다.",
        "B": "데이터를 Amazon S3 버킷에 직접 저장합니다. S3 수명 주기 정책을 구현하여 오래된 데이터를 장기 저장을 위해 S3 Glacier Deep Archive로 이동합니다. Amazon Athena를 사용하여 Amazon S3의 데이터에 대해 일회성 쿼리를 실행합니다.",
        "C": "자주 액세스하는 데이터의 경우 DynamoDB Accelerator(DAX)와 함께 Amazon DynamoDB를 사용합니다. DynamoDB 테이블 내보내기를 사용하여 데이터를 Amazon S3 버킷으로 내보냅니다. Amazon Athena를 사용하여 Amazon S3의 데이터에 대해 일회성 쿼리를 실행합니다.",
        "D": "자주 액세스하는 데이터에는 Amazon DynamoDB를 사용합니다. Amazon Kinesis Data Streams로 스트리밍을 켭니다. Amazon Kinesis Data Firehose를 사용하여 Kinesis Data Streams에서 데이터를 읽습니다. 레코드를 Amazon S3 버킷에 저장합니다."
      },
      "eng": {
        "A": "Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.",
        "B": "Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.",
        "C": "Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.",
        "D": "Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "DAX",
      "Athena"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102119-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 321,
    "question": {
      "kor": "회사는 대규모 Amazon EC2 인스턴스 플릿에서 애플리케이션을 실행합니다. 애플리케이션은 항목을 읽고 Amazon DynamoDB 테이블에 씁니다. DynamoDB 테이블의 크기는 지속적으로 증가하지만 애플리케이션에는 지난 30일 동안의 데이터만 필요합니다. 회사는 비용과 개발 노력을 최소화하는 솔루션이 필요합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs an application on a large fleet of Amazon EC2 instances. The application reads and writes entries into an Amazon DynamoDB table. The size of the DynamoDB table continuously grows, but the application needs only data from the last 30 days. The company needs a solution that minimizes cost and development effort.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS CloudFormation 템플릿을 사용하여 전체 솔루션을 배포합니다. 30일마다 CloudFormation 스택을 재배포하고 원래 스택을 삭제합니다.",
        "B": "AWS Marketplace에서 모니터링 애플리케이션을 실행하는 EC2 인스턴스를 사용합니다. Amazon DynamoDB Streams를 사용하여 테이블에 새 항목이 생성될 때 타임스탬프를 저장하도록 모니터링 애플리케이션을 구성합니다. EC2 인스턴스에서 실행되는 스크립트를 사용하여 30일보다 오래된 타임스탬프가 있는 항목을 삭제합니다.",
        "C": "테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출하도록 Amazon DynamoDB Streams를 구성합니다. 테이블에서 30일보다 오래된 항목을 삭제하도록 Lambda 함수를 구성합니다.",
        "D": "애플리케이션을 확장하여 현재 타임스탬프에 30일을 더한 값을 테이블에 생성된 각 새 항목에 추가하는 속성을 추가합니다. 속성을 TTL 속성으로 사용하도록 DynamoDB를 구성합니다."
      },
      "eng": {
        "A": "Use an AWS CloudFormation template to deploy the complete solution. Redeploy the CloudFormation stack every 30 days, and delete the original stack.",
        "B": "Use an EC2 instance that runs a monitoring application from AWS Marketplace. Configure the monitoring application to use Amazon DynamoDB Streams to store the timestamp when a new item is created in the table. Use a script that runs on the EC2 instance to delete items that have a timestamp that is older than 30 days.",
        "C": "Configure Amazon DynamoDB Streams to invoke an AWS Lambda function when a new item is created in the table. Configure the Lambda function to delete items in the table that are older than 30 days.",
        "D": "Extend the application to add an attribute that has a value of the current timestamp plus 30 days to each new item that is created in the table. Configure DynamoDB to use the attribute as the TTL attribute."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "TTL"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89140-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 439,
    "question": {
      "kor": "한 회사에서 Amazon DynamoDB를 데이터베이스 계층으로 사용하는 서버리스 애플리케이션을 배포했습니다. 응용 프로그램의 사용자가 크게 증가했습니다. 이 회사는 데이터베이스 응답 시간을 밀리초에서 마이크로초로 개선하고 데이터베이스에 대한 요청을 캐시하기를 원합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company deployed a serverless application that uses Amazon DynamoDB as a database layer. The application has experienced a large increase in users.\nThe company wants to improve database response time from milliseconds to microseconds and to cache requests to the database.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB 가속기(DAX)를 사용합니다.",
        "B": "데이터베이스를 Amazon Redshift로 마이그레이션합니다.",
        "C": "데이터베이스를 Amazon RDS로 마이그레이션합니다.",
        "D": "Redis용 Amazon ElastiCache를 사용합니다."
      },
      "eng": {
        "A": "Use DynamoDB Accelerator (DAX).",
        "B": "Migrate the database to Amazon Redshift.",
        "C": "Migrate the database to Amazon RDS.",
        "D": "Use Amazon ElastiCache for Redis."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "DAX"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117038-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 456,
    "question": {
      "kor": "회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 관심이 있습니다. 테이블은 대부분의 아침에 사용되지 않습니다. 저녁에는 읽기 및 쓰기 트래픽을 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur, they will happen very quickly.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.",
        "B": "글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.",
        "C": "프로비저닝된 용량과 Auto Scaling으로 DynamoDB 테이블을 생성합니다.",
        "D": "프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 글로벌 테이블로 구성합니다."
      },
      "eng": {
        "A": "Create a DynamoDB table in on-demand capacity mode.",
        "B": "Create a DynamoDB table with a global secondary index.",
        "C": "Create a DynamoDB table with provisioned capacity and auto scaling.",
        "D": "Create a DynamoDB table in provisioned capacity mode, and configure it as a global table."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "capacity mode"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 469,
    "question": {
      "kor": "회사의 웹 사이트는 매일 수백만 건의 요청을 처리하며 요청 수는 계속 증가하고 있습니다. 솔루션 설계자는 웹 애플리케이션의 응답 시간을 개선해야 합니다. 솔루션 설계자는 애플리케이션이 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 지연 시간을 줄여야 한다고 결정합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company's website handles millions of requests each day, and the number of requests continues to increase. A solutions architect needs to improve the response time of the web application. The solutions architect determines that the application needs to decrease latency when retrieving product details from the Amazon DynamoDB table.\nWhich solution will meet these requirements with the LEAST amount of operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB Accelerator(DAX) 클러스터를 설정합니다. DAX를 통해 모든 읽기 요청을 라우팅합니다.",
        "B": "DynamoDB 테이블과 웹 애플리케이션 사이에 Redis용 Amazon ElastiCache를 설정합니다. Redis를 통해 모든 읽기 요청을 라우팅합니다.",
        "C": "DynamoDB 테이블과 웹 애플리케이션 사이에 Amazon ElastiCache for Memcached를 설정합니다. Memcached를 통해 모든 읽기 요청을 라우팅합니다.",
        "D": "테이블에 Amazon DynamoDB 스트림을 설정하고 AWS Lambda가 테이블에서 읽고 Amazon ElastiCache를 채우도록 합니다. ElastiCache를 통해 모든 읽기 요청을 라우팅 합니다."
      },
      "eng": {
        "A": "Set up a DynamoDB Accelerator (DAX) cluster. Route all read requests through DAX.",
        "B": "Set up Amazon ElastiCache for Redis between the DynamoDB table and the web application. Route all read requests through Redis.",
        "C": "Set up Amazon ElastiCache for Memcached between the DynamoDB table and the web application. Route all read requests through Memcached.",
        "D": "Set up Amazon DynamoDB Streams on the table, and have AWS Lambda read from the table and populate Amazon ElastiCache. Route all read requests through ElastiCache."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "DAX"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117022-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 482,
    "question": {
      "kor": "회사는 AWS 클라우드에서 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon DynamoDB 테이블과 함께 Auto Scaling 그룹의 Elastic Load Balancer 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다. 회사는 다운타임을 최소화하면서 다른 AWS 리전에서 애플리케이션을 사용할 수 있기를 원합니다.\n가동 중지 시간을 최소화하면서 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A company hosts its application in the AWS Cloud. The application runs on Amazon EC2 instances behind an Elastic Load Balancer in an Auto Scaling group and with an Amazon DynamoDB table. The company wants to ensure the application can be made available in anotherAWS Region with minimal downtime.\nWhat should a solutions architect do to meet these requirements with the LEAST amount of downtime?"
    },
    "choices": {
      "kor": {
        "A": "재해 복구 지역에 Auto Scaling 그룹과 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.",
        "B": "필요할 때 시작할 EC2 인스턴스, 로드 밸런서 및 DynamoDB 테이블을 생성하기 위해 AWS CloudFormation 템플릿을 생성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.",
        "C": "AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스와 필요할 때 실행할 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.",
        "D": "재해 복구 지역에서 Auto Scaling 그룹 및 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 재해 복구 로드 밸런서를 가리키는 Amazon Route 53을 업데이트하는 AWS Lambda 함수를 트리거하는 Amazon CloudWatch 경보를 생성합니다."
      },
      "eng": {
        "A": "Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "B": "Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be launched when needed Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "C": "Create an AWS CloudFormation template to create EC2 instances and a load balancer to be launched when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "D": "Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger an AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "ASG"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109294-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 508,
    "question": {
      "kor": "회사에 Amazon DynamoDB 기반 데이터 저장소가 있는 모바일 채팅 애플리케이션이 있습니다. 사용자는 가능한 한 짧은 대기 시간으로 새 메시지를 읽기를 원합니다. 솔루션 설계자는 최소한의 애플리케이션 변경이 필요한 최적의 솔루션을 설계해야 합니다.\n솔루션 설계자는 어떤 방법을 선택해야 합니까?",
      "eng": "A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes.\nWhich method should the solutions architect select?"
    },
    "choices": {
      "kor": {
        "A": "새 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. DAX 끝점을 사용하도록 코드를 업데이트합니다.",
        "B": "증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 복제본을 추가합니다. 읽기 전용 복제본의 읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다.",
        "C": "DynamoDB의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 DynamoDB 엔드포인트를 계속 사용합니다.",
        "D": "Redis 캐시용 Amazon ElastiCache를 애플리케이션 스택에 추가합니다. DynamoDB 대신 Redis 캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다."
      },
      "eng": {
        "A": "Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.",
        "B": "Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas.",
        "C": "Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.",
        "D": "Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "DAX"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109454-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 548,
    "question": {
      "kor": "게임 회사는 Amazon DynamoDB를 사용하여 지리적 위치, 플레이어 데이터 및 순위표와 같은 사용자 정보를 저장합니다. 회사는 최소한의 코딩으로 Amazon S3 버킷에 대한 지속적인 백업을 구성해야 합니다. 백업은 애플리케이션의 가용성에 영향을 미치지 않아야 하며 테이블에 대해 정의된 읽기 용량 단위(RCU)에 영향을 주지 않아야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A gaming company uses Amazon DynamoDB to store user information such as geographic location, player data, and leaderboards. The company needs to configure continuous backups to an Amazon S3 bucket with a minimal amount of coding. The backups must not affect availability of the application and must not affect the read capacity units (RCUs) that are defined for the table.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EMR 클러스터를 사용합니다. Apache Hive 작업을 생성하여 Amazon S3에 데이터를 백업합니다.",
        "B": "연속 백업을 통해 DynamoDB에서 Amazon S3로 직접 데이터를 내보냅니다. 테이블에 대해 지정 시간 복구를 설정합니다.",
        "C": "Amazon DynamoDB 스트림을 구성합니다. 스트림을 사용하고 데이터를 Amazon S3 버킷으로 내보내는 AWS Lambda 함수를 생성합니다.",
        "D": "정기적으로 데이터베이스 테이블에서 Amazon S3로 데이터를 내보내는 AWS Lambda 함수를 생성합니다. 테이블에 대해 지정 시간 복구를 설정합니다."
      },
      "eng": {
        "A": "Use an Amazon EMR cluster. Create an Apache Hive job to back up the data to Amazon S3.",
        "B": "Export the data directly from DynamoDB to Amazon S3 with continuous backups. Turn on point-in-time recovery for the table.",
        "C": "Configure Amazon DynamoDB Streams. Create an AWS Lambda function to consume the stream and export the data to an Amazon S3 bucket.",
        "D": "Create an AWS Lambda function to export the data from the database tables to Amazon S3 on a regular basis. Turn on point-in-time recovery for the table."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109577-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 580,
    "question": {
      "kor": "한 회사에서 Amazon EC2 인스턴스에서 실행할 새 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 백엔드 데이터 스토리지에 Amazon DynamoDB를 사용합니다. 애플리케이션 트래픽은 예측할 수 없습니다. 회사는 데이터베이스에 대한 응용 프로그램 읽기 및 쓰기 처리량이 보통에서 높을 것으로 예상합니다. 회사는 애플리케이션 트래픽에 대응하여 확장해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 DynamoDB 테이블 구성은 무엇입니까?",
      "eng": "A company is designing a new web application that will run on Amazon EC2 Instances. The application will use Amazon DynamoDB for backend data storage. The application traffic will be unpredictable. The company expects that the application read and write throughput to the database will be moderate to high. The company needs to scale in response to application traffic.\nWhich DynamoDB table configuration will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB 표준 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB를 구성합니다. DynamoDB Auto Scaling을 정의된 최대 용량으로 설정합니다.",
        "B": "DynamoDB Standard 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB를 구성합니다.",
        "C": "DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB를 구성합니다. DynamoDB Auto Scaling을 정의된 최대 용량으로 설정합니다.",
        "D": "DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB를 구성합니다."
      },
      "eng": {
        "A": "Configure DynamoDB with provisioned read and write by using the DynamoDB Standard table class. Set DynamoDB auto scaling to a maximum defined capacity.",
        "B": "Configure DynamoDB in on-demand mode by using the DynamoDB Standard table class.",
        "C": "Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity.",
        "D": "Configure DynamoDB in on-demand mode by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "capacity mode",
      "class"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109539-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 622,
    "question": {
      "kor": "내장형 NoSQL 데이터베이스가 포함된 회사의 웹 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 작동합니다. 이러한 인스턴스는 단일 가용 영역으로 제한된 Amazon EC2 Auto Scaling 그룹 내에 있습니다. 트래픽 증가로 인해 애플리케이션은 고가용성을 달성해야 하며 데이터베이스는 최종 일관성을 유지해야 합니다.\n이러한 요구 사항을 충족하면서 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
      "eng": "A company's web application, containing an embedded NoSQL database, operates on Amazon EC2 instances behind an Application Load Balancer (ALB).\nThese instances are within an Amazon EC2 Auto Scaling group, confined to a single Availability Zone. Due to increased traffic, the application must achieve high availability, and the database needs to maintain eventual consistency.\nWhat solution minimizes operational overhead while meeting these requirements?"
    },
    "choices": {
      "kor": {
        "A": "ALB를 Network Load Balancer로 교체하고 내장형 NoSQL 데이터베이스를 EC2 인스턴스의 복제 서비스와 함께 유지합니다.",
        "B": "ALB를 Network Load Balancer로 교체하고 AWS Database Migration Service(AWS DMS)를 사용하여 내장형 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.",
        "C": "EC2 인스턴스의 복제 서비스와 함께 내장된 NoSQL 데이터베이스를 유지하면서 3개의 가용 영역에서 EC2 인스턴스를 활용하도록 Auto Scaling 그룹을 수정합니다.",
        "D": "3개의 가용 영역에서 EC2 인스턴스를 활용하고 AWS Database Migration Service(AWS DMS)를 사용하여 내장된 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션하도록 Auto Scaling 그룹을 수정합니다."
      },
      "eng": {
        "A": "Replace the ALB with a Network Load Balancer and maintain the embedded NoSQL database with its replication service on the EC2 instances.",
        "B": "Replace the ALB with a Network Load Balancer and migrate the embedded NoSQL database to Amazon DynamoDB using AWS Database Migration Service (AWS DMS).",
        "C": "Modify the Auto Scaling group to utilize EC2 instances across three Availability Zones while maintaining the embedded NoSQL database with its replication service on the EC2 instances.",
        "D": "Modify the Auto Scaling group to utilize EC2 instances across three Availability Zones and migrate the embedded NoSQL database to Amazon DynamoDB using AWS Database Migration Service (AWS DMS)."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "ASG"
    ],
    "rote_memorization": false,
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 642,
    "question": {
      "kor": "한 회사가 AWS에서 쇼핑 애플리케이션을 구축하고 있습니다. 애플리케이션은 매달 한 번씩 변경되고 트래픽 양에 따라 확장되어야 하는 카탈로그를 제공합니다. 회사는 애플리케이션의 대기 시간이 최소화되기를 원합니다. 각 사용자 장바구니의 데이터는 가용성이 높아야 합니다. 사용자의 연결이 끊어졌다가 다시 연결되더라도 사용자 세션 데이터를 사용할 수 있어야 합니다.\n장바구니 데이터가 항상 보존되도록 솔루션 설계자는 무엇을 해야 합니까?",
      "eng": "A company is building a shopping application on AWS. The application offers a catalog that changes once each month and needs to scale with traffic volume. The company wants the lowest possible latency from the application. Data from each user's shopping cart needs to be highly available. User session data must be available even if the user is disconnected and reconnects.\nWhat should a solutions architect do to ensure that the shopping cart data is preserved at all times?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Aurora의 카탈로그에 액세스하기 위해 고정 세션 기능(세션 선호도)을 활성화하도록 Application Load Balancer를 구성합니다.",
        "B": "Amazon DynamoDB의 카탈로그 데이터와 사용자 세션의 장바구니 데이터를 캐시하도록 Redis용 Amazon ElastiCache를 구성합니다.",
        "C": "Amazon DynamoDB의 카탈로그 데이터와 사용자 세션의 장바구니 데이터를 캐시하도록 Amazon OpenSearch Service를 구성합니다.",
        "D": "카탈로그 및 장바구니를 위한 Amazon Elastic Block Store(Amazon EBS) 스토리지로 Amazon EC2 인스턴스를 구성합니다. 자동 스냅샷을 구성합니다."
      },
      "eng": {
        "A": "Configure an Application Load Balancer to enable the sticky sessions feature (session affinity) for access to the catalog in Amazon Aurora.",
        "B": "Configure Amazon ElastiCache for Redis to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.",
        "C": "Configure Amazon OpenSearch Service to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.",
        "D": "Configure an Amazon EC2 instance with Amazon Elastic Block Store (Amazon EBS) storage for the catalog and shopping cart. Configure automated snapshots."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "ElastiCache",
      "caching"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132857-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 652,
    "question": {
      "kor": "회사는 회사 AWS 계정의 Amazon DynamoDB 테이블에 중요한 데이터를 저장합니다. IT 관리자가 실수로 DynamoDB 테이블을 삭제했습니다. 삭제로 인해 상당한 데이터 손실이 발생하고 회사 운영이 중단되었습니다. 회사는 앞으로 이러한 유형의 중단을 방지하기를 원합니다.\n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company stores critical data in Amazon DynamoDB tables in the company's AWS account. An IT administrator accidentally deleted a DynamoDB table.\nThe deletion caused a significant loss of data and disrupted the company's operations. The company wants to prevent this type of disruption in the future.\nWhich solution will meet this requirement with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS CloudTrail에서 추적을 구성합니다. 삭제 작업에 대한 Amazon EventBridge 규칙을 생성합니다. 삭제된 DynamoDB 테이블을 자동으로 복원하는 AWS Lambda 함수를 생성합니다.",
        "B": "DynamoDB 테이블에 대한 백업 및 복원 계획을 생성합니다. DynamoDB 테이블을 수동으로 복구합니다.",
        "C": "DynamoDB 테이블에 대한 삭제 방지를 구성합니다.",
        "D": "DynamoDB 테이블에서 특정 시점 복구를 활성화합니다."
      },
      "eng": {
        "A": "Configure a trail in AWS CloudTrail. Create an Amazon EventBridge rule for delete actions. Create an AWS Lambda function to automatically restore deleted DynamoDB tables.",
        "B": "Create a backup and restore plan for the DynamoDB tables. Recover the DynamoDB tables manually.",
        "C": "Configure deletion protection on the DynamoDB tables.",
        "D": "Enable point-in-time recovery on the DynamoDB tables."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132907-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 883,
    "question": {
      "kor": "회사에서는 Amazon DynamoDB 테이블을 사용하는 애플리케이션에 대한 테스트를 수행합니다. 테스트는 일주일에 한 번 4시간 동안 진행됩니다. 회사는 테스트 중에 애플리케이션이 매초 테이블에 대해 수행하는 읽기 및 쓰기 작업 수를 알고 있습니다. 회사는 현재 다른 사용 사례에 DynamoDB를 사용하지 않습니다. 솔루션 설계자는 테이블 비용을 최적화해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company performs tests on an application that uses an Amazon DynamoDB table. The tests run for 4 hours once a week. The company knows how many read and write operations the application performs to the table each second during the tests. The company does not currently use DynamoDB for any other use case. A solutions architect needs to optimize the costs for the table.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "주문형 모드를 선택하세요. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다.",
        "B": "프로비저닝 모드를 선택합니다. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다.",
        "C": "1년 기간 동안 DynamoDB 예약 용량을 구매합니다.",
        "D": "3년 기간 동안 DynamoDB 예약 용량을 구매하세요."
      },
      "eng": {
        "A": "Choose on-demand mode. Update the read and write capacity units appropriately.",
        "B": "Choose provisioned mode. Update the read and write capacity units appropriately.",
        "C": "Purchase DynamoDB reserved capacity for a 1-year term.",
        "D": "Purchase DynamoDB reserved capacity for a 3-year term."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB",
      "capacity mode"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/129711-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 892,
    "question": {
      "kor": "회사에는 내장형 NoSQL 데이터베이스가 포함된 웹 애플리케이션이 있습니다. 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 단일 가용 영역의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다.\n최근 트래픽이 증가함에 따라 애플리케이션의 가용성이 높아야 하고 데이터베이스가 최종 일관성을 유지해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a web application that includes an embedded NoSQL database. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group in a single Availability Zone.\nA recent increase in traffic requires the application to be highly available and for the database to be eventually consistent.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "ALB를 Network Load Balancer로 교체합니다. EC2 인스턴스의 복제 서비스를 통해 내장형 NoSQL 데이터베이스를 유지 관리합니다.",
        "B": "ALB를 Network Load Balancer로 교체합니다. AWS Database Migration Service(AWS DMS)를 사용하여 내장형 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.",
        "C": "3개의 가용 영역에서 EC2 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다. EC2 인스턴스의 복제 서비스를 통해 내장형 NoSQL 데이터베이스를 유지 관리합니다.",
        "D": "세 개의 가용 영역에서 EC2 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다. AWS Database Migration Service(AWS DMS)를 사용하여 내장형 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다."
      },
      "eng": {
        "A": "Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with its replication service on the EC2 instances.",
        "B": "Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS).",
        "C": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the embedded NoSQL database with its replication service on the EC2 instances.",
        "D": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS)."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "DynamoDB"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132855-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 700,
    "question": {
      "kor": "소셜 미디어 회사는 사용자 프로필, 관계 및 상호 작용에 대한 데이터베이스를 AWS 클라우드에 저장하려고 합니다. 회사에는 데이터베이스의 변경 사항을 모니터링하는 애플리케이션이 필요합니다. 애플리케이션은 데이터 엔터티 간의 관계를 분석하고 사용자에게 권장 사항을 제공해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Neptune을 사용하여 정보를 저장합니다. Amazon Kinesis Data Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
        "B": "Amazon Neptune을 사용하여 정보를 저장합니다. Neptune Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
        "C": "Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. Amazon Kinesis Data Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
        "D": "Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. Neptune Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다."
      },
      "eng": {
        "A": "Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database.",
        "B": "Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.",
        "C": "Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database.",
        "D": "Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Neptune"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125113-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 753,
    "question": {
      "kor": "한 회사는 보안 위험을 초래하는 리소스에 대한 정책을 식별하고 시행하기 위해 IT 인프라 맵을 구축하려고 합니다. 회사의 보안팀은 IT 인프라 맵의 데이터를 쿼리하고 보안 위험을 신속하게 식별할 수 있어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to build a map of its IT infrastructure to identify and enforce policies on resources that pose security risks. The company's security team must be able to query data in the IT infrastructure map and quickly identify security risks.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon RDS를 사용하여 데이터를 저장합니다. SQL을 사용하여 데이터를 쿼리하여 보안 위험을 식별합니다.",
        "B": "Amazon Neptune을 사용하여 데이터를 저장합니다. SPARQL을 사용하여 데이터를 쿼리하여 보안 위험을 식별합니다.",
        "C": "Amazon Redshift를 사용하여 데이터를 저장합니다. SQL을 사용하여 데이터를 쿼리하여 보안 위험을 식별합니다.",
        "D": "Amazon DynamoDB를 사용하여 데이터를 저장합니다. PartiQL을 사용하여 데이터를 쿼리하여 보안 위험을 식별합니다."
      },
      "eng": {
        "A": "Use Amazon RDS to store the data. Use SQL to query the data to identify security risks.",
        "B": "Use Amazon Neptune to store the data. Use SPARQL to query the data to identify security risks.",
        "C": "Use Amazon Redshift to store the data. Use SQL to query the data to identify security risks.",
        "D": "Use Amazon DynamoDB to store the data. Use PartiQL to query the data to identify security risks."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Neptune"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/137910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 940,
    "question": {
      "kor": "회사에는 5TB의 데이터 세트가 있습니다. 데이터 세트는 1백만 개의 사용자 프로필과 1천만 개의 연결로 구성됩니다. 사용자 프로필에는 다대다 관계와 같은 연결이 있습니다. 회사에는 최대 5개 수준까지 상호 연결을 찾기 위한 효율적인 성능 방법이 필요합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has 5 TB of datasets. The datasets consist of 1 million user profiles and 10 million connections. The user profiles have connections as many-tomany relationships. The company needs a performance efficient way to find mutual connections up to five levels.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 버킷을 사용하여 데이터 세트를 저장합니다. Amazon Athena를 사용하여 SQL JOIN 쿼리를 수행하여 연결을 찾습니다.",
        "B": "Amazon Neptune을 사용하여 에지 및 꼭짓점과 함께 데이터 세트를 저장합니다. 데이터를 쿼리하여 연결을 찾습니다.",
        "C": "Amazon S3 버킷을 사용하여 데이터세트를 저장합니다. Amazon QuickSight를 사용하여 연결을 시각화합니다.",
        "D": "Amazon RDS를 사용하여 여러 테이블이 포함된 데이터 세트를 저장합니다. SQL JOIN 쿼리를 수행하여 연결을 찾습니다."
      },
      "eng": {
        "A": "Use an Amazon S3 bucket to store the datasets. Use Amazon Athena to perform SQL JOIN queries to find connections.",
        "B": "Use Amazon Neptune to store the datasets with edges and vertices. Query the data to find connections.",
        "C": "Use an Amazon S3 bucket to store the datasets. Use Amazon QuickSight to visualize connections.",
        "D": "Use Amazon RDS to store the datasets with multiple tables. Perform SQL JOIN queries to find connections."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Neptune"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/136957-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 919,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스에서 실행되는 사용자 지정 애플리케이션에서 회계 기록을 유지 관리합니다. 회사는 애플리케이션 데이터의 개발 및 유지 관리를 위해 데이터를 AWS 관리형 서비스로 마이그레이션해야 합니다. 솔루션에는 최소한의 운영 지원이 필요하고 데이터 변경 사항에 대해 변경할 수 없고 암호화 방식으로 검증 가능한 로그를 제공해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company maintains its accounting records in a custom application that runs on Amazon EC2 instances. The company needs to migrate the data to an AWS managed service for development and maintenance of the application data. The solution must require minimal operational support and provide immutable, cryptographically verifiable logs of data changes.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "애플리케이션의 레코드를 Amazon Redshift 클러스터로 복사합니다.",
        "B": "애플리케이션의 레코드를 Amazon Neptune 클러스터에 복사합니다.",
        "C": "애플리케이션의 레코드를 Amazon Timestream 데이터베이스로 복사합니다.",
        "D": "애플리케이션의 레코드를 Amazon Quantum Ledger Database(Amazon QLDB) 원장으로 복사합니다."
      },
      "eng": {
        "A": "Copy the records from the application into an Amazon Redshift cluster.",
        "B": "Copy the records from the application into an Amazon Neptune cluster.",
        "C": "Copy the records from the application into an Amazon Timestream database.",
        "D": "Copy the records from the application into an Amazon Quantum Ledger Database (Amazon QLDB) ledger."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "QLDB"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133018-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 36,
    "question": {
      "kor": "회사는 데이터 센터에서 SMB 파일 서버를 실행하고 있습니다. 파일 서버는 파일이 생성된 후 처음 며칠 동안 자주 액세스되는 대용량 파일을 저장합니다. 7일 후에는 파일에 거의 액세스하지 않습니다.\n총 데이터 크기는 증가하고 있으며 회사의 총 스토리지 용량에 근접합니다. 솔루션 설계자는 가장 최근에 액세스한 파일에 대한 짧은 대기 시간 액세스를 잃지 않고 회사의 사용 가능한 스토리지 공간을 늘려야 합니다. 솔루션 설계자는 향후 스토리지 문제를 방지하기 위해 파일 수명 주기 관리도 제공해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is running an SMB file server in its data center. The file server stores large files that are accessed frequently for the first few days after the files are created. After 7 days the files are rarely accessed.\nThe total data size is increasing and is close to the company's total storage capacity. A solutions architect must increase the company's available storage space without losing low-latency access to the most recently accessed files. The solutions architect must also provide file lifecycle management to avoid future storage issues.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 SMB 파일 서버에서 AWS로 7일보다 오래된 데이터를 복사합니다.",
        "B": "Amazon S3 File Gateway를 생성하여 회사의 스토리지 공간을 확장합니다. 7일 후에 데이터를 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책을 생성합니다.",
        "C": "Amazon FSx for Windows File Server 파일 시스템을 생성하여 회사의 스토리지 공간을 확장합니다.",
        "D": "각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3에 액세스합니다. 7일 후에 데이터를 S3 Glacier Flexible Retrieval로 전환하는 S3 수명 주기 정책을 생성합니다."
      },
      "eng": {
        "A": "Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.",
        "B": "Create an Amazon S3 File Gateway to extend the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.",
        "C": "Create an Amazon FSx for Windows File Server file system to extend the company's storage space.",
        "D": "Install a utility on each user's computer to access Amazon S3. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "File gateway",
      "Storage Gateway",
      "S3",
      "lifecycle policies"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84680-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 791,
    "question": {
      "kor": "회사의 데이터 센터에 노후화된 어레이가 있습니다. 어레이는 공유 및 공유를 클라이언트 NAS(Network-Attached Storage) NAS SMB NFS 워크스테이션에 제공합니다. 회사는 새 NAS 어레이를 구매하기를 원하지 않습니다. 회사는 또한 NAS 어레이의 지원 계약을 갱신하는 데 드는 비용을 원하지 않습니다. 일부 데이터는 자주 액세스되지만 대부분의 데이터는 비활성 상태입니다.\n솔루션 설계자는 데이터를 Amazon S3로 마이그레이션하고 S3 수명 주기 정책을 사용하며 클라이언트 워크스테이션에 대해 동일한 모양과 느낌을 유지하는 솔루션을 구현해야 합니다. 솔루션 설계자는 AWS Storage Gateway를 솔루션의 일부로 식별했습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 스토리지 게이트웨이를 프로비저닝해야 합니까?",
      "eng": "A company has an aging network-attached storage (NAS) array in its data center. The NAS array presents SMB shares and NFS shares to client workstations. The company does not want to purchase a new NAS array. The company also does not want to incur the cost of renewing the NAS array’s support contract. Some of the data is accessed frequently, but much of the data is inactive.\nA solutions architect needs to implement a solution that migrates the data to Amazon S3, uses S3 Lifecycle policies, and maintains the same look and feel for the client workstations. The solutions architect has identified AWS Storage Gateway as part of the solution.\nWhich type of storage gateway should the solutions architect provision to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "볼륨 게이트웨이",
        "B": "테이프 게이트웨이",
        "C": "Amazon FSx 파일 게이트웨이",
        "D": "Amazon S3 파일 게이트웨이"
      },
      "eng": {
        "A": "File Gateway",
        "B": "Volume Gateway",
        "C": "Tape Gateway",
        "D": "Amazon FSx File Gateway"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "File gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100220-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 795,
    "question": {
      "kor": "회사에는 매일 수백 개의 보고서를 생성하는 비즈니스 시스템이 있습니다. 비즈니스 시스템은 보고서를 CSV 형식으로 네트워크 공유에 저장합니다. 회사는 분석을 위해 이 데이터를 거의 실 시간으로 AWS 클라우드에 저장해야 합니다.\n최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a business system that generates hundreds of reports each day. The business system saves the reports to a network share in CSV format.\nThe company needs to store this data in the AWS Cloud in near-real time for analysis.\nWhich solution will meet these requirements with the LEAST administrative overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 파일을 Amazon S3로 전송합니다. 매일 끝날 때 실행되는 예약된 작업을 만듭니다.",
        "B": "Amazon S3 파일 게이트웨이를 생성합니다. S3 파일 게이트웨이에서 새 네트워크 공유를 사용하도록 비즈니스 시스템을 업데이트합니다.",
        "C": "AWS DataSync를 사용하여 파일을 Amazon S3로 전송합니다. 자동화 워크플로에서 DataSync API를 사용하는 애플리케이션을 생성합니다.",
        "D": "SFTP용 AWS 전송 엔드포인트를 배포합니다. 네트워크 공유에서 새 파일을 확인하고 SFTP를 사용하여 새 파일을 업로드하는 스크립트를 만듭니다."
      },
      "eng": {
        "A": "Use AWS DataSync to transfer the files to Amazon S3. Create a scheduled task that runs at the end of each day.",
        "B": "Create an Amazon S3 File Gateway. Update the business system to use a new network share from the S3 File Gateway.",
        "C": "Use AWS DataSync to transfer the files to Amazon S3. Create an application that uses the DataSync API in the automation workflow.",
        "D": "Deploy an AWS Transfer for SFTP endpoint. Create a script that checks for new files on the network share and uploads the new files by using SFTP."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "File gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/103452-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 453,
    "question": {
      "kor": "한 회사는 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일서버는 회사가 자주 접속하는 대용량 파일을 파일 생성일로부터 최대 7일까지 저장합니다. 7일이 지나면 회사는 최대 24시간의 검색 시간으로 파일에 액세스할 수 있어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs an SMB file server in its data center. The file server stores large files that the company frequently accesses for up to 7 days after the file creation date. After 7 days, the company needs to be able to access the files with a maximum retrieval time of 24 hours.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 SMB 파일 서버에서 AWS로 7일보다 오래된 데이터를 복사합니다.",
        "B": "회사의 저장 공간을 늘리려면 Amazon S3 파일 게이트웨이를 생성합니다. 7일 후에 데이터를 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책을 생성합니다.",
        "C": "회사의 저장 공간을 늘리기 위해 Amazon FSx 파일 게이트웨이를 생성합니다. 7일 후에 데이터를 전환하는 Amazon S3 수명 주기 정책을 생성합니다.",
        "D": "각 사용자에 대해 Amazon S3에 대한 액세스를 구성합니다. 7일 후에 데이터를 S3 Glacier 유연한 검색으로 전환하는 S3 수명 주기 정책을 생성합니다."
      },
      "eng": {
        "A": "Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.",
        "B": "Create an Amazon S3 File Gateway to increase the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.",
        "C": "Create an Amazon FSx File Gateway to increase the company's storage space. Create an Amazon S3 Lifecycle policy to transition the data after 7 days.",
        "D": "Configure access to Amazon S3 for each user. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "File Gateway",
      "SMB file server",
      "lifecycle policies",
      "Storage Class"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/129714-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 249,
    "question": {
      "kor": "주로 온프레미스에서 애플리케이션 서버를 실행하는 회사가 AWS로 마이그레이션하기로 결정했습니다. 회사는 온프레미스에서 iSCSI(Internet Small Computer Systems Interface) 스토리지를 확장해야 할 필요성을 최소화하려고 합니다. 회사는 최근에 액세스한 데이터만 로컬에 저장하기를 원합니다.\n회사는 이러한 요구 사항을 충족하기 위해 어떤 AWS 솔루션을 사용해야 합니까?",
      "eng": "A company that primarily runs its application servers on premises has decided to migrate to AWS. The company wants to minimize its need to scale its Internet Small Computer Systems Interface (iSCSI) storage on premises. The company wants only its recently accessed data to remain stored locally.\nWhich AWS solution should the company use to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 파일 게이트웨이",
        "B": "AWS Storage Gateway 테이프 게이트웨이",
        "C": "AWS Storage Gateway 볼륨 게이트웨이 저장 볼륨",
        "D": "AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨"
      },
      "eng": {
        "A": "Amazon S3 File Gateway",
        "B": "AWS Storage Gateway Tape Gateway",
        "C": "AWS Storage Gateway Volume Gateway stored volumes",
        "D": "AWS Storage Gateway Volume Gateway cached volumes"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99611-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 275,
    "question": {
      "kor": "회사에는 수명이 다한 온프레미스 볼륨 백업 솔루션이 있습니다. 회사는 를 새로운 백업 솔루션의 일부로 사용하고 에 백업되는 동안 AWS AWS 모든 데이터에 대한 로컬 액세스를 유지하려고 합니다. 회사는 AWS에 백업된 데이터가 자동으로 안전하게 전송되기를 원합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has an on-premises volume backup solution that has reached its end of life. The company wants to use AWS as part of a new backup solution and wants to maintain local access to all the data while it is backed up on AWS. The company wants to ensure that the data backed up on AWS is automatically and securely transferred.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Snowball을 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 Snowball S3 엔드포인트를 탑재하도록 온프레미스 시스템을 구성합니다.",
        "B": "AWS Snowball Edge를 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 데이터에 대한 로컬 액세스를 제공합니다.",
        "C": "AWS Storage Gateway를 사용하고 캐시된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 로컬로 캐시할 데이터 비율을 구성합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 게이트웨이 스토리지 볼륨을 마운트합니다.",
        "D": "AWS Storage Gateway를 사용하고 저장된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 게이트웨이 스토리지 볼륨을 마운트합니다."
      },
      "eng": {
        "A": "Use AWS Snowball to migrate data out of the on-premises solution to Amazon S3. Configure on-premises systems to mount the Snowball S3 endpoint to provide local access to the data.",
        "B": "Use AWS Snowball Edge to migrate data out of the on-premises solution to Amazon S3. Use the Snowball Edge file interface to provide on-premises systems with local access to the data.",
        "C": "Use AWS Storage Gateway and configure a cached volume gateway. Run the Storage Gateway software appliance on premises and configure a percentage of data to cache locally. Mount the gateway storage volumes to provide local access to the data.",
        "D": "Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99692-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 322,
    "question": {
      "kor": "회사는 기본 온프레미스 파일 스토리지 볼륨에 대한 재해 복구 계획을 구현하려고 합니다. 파일 스토리지 볼륨은 로컬 스토리지 서버의 iSCSI(Internet Small Computer Systems Interface) 장치에서 마운트됩니다. 파일 스토리지 볼륨은 수백 테라바이트(TB)의 데이터를 보유합니다.\n회사는 최종 사용자가 대기 시간 없이 온프레미스 시스템의 모든 파일 유형에 즉시 액세스할 수 있기를 원합니다.\n회사의 기존 인프라를 최소한으로 변경하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data.\nThe company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency.\nWhich solution will meet these requirements with the LEAST amount of change to the company's existing infrastructure?"
    },
    "choices": {
      "kor": {
        "A": "온프레미스에서 호스팅되는 가상 머신(VM)으로 Amazon S3 파일 게이트웨이를 프로비저닝합니다. 로컬 캐시를 10TB로 설정합니다. NFS 프로토콜을 통해 파일에 액세스하도록 기존 애플리케이션을 수정합니다. 재해에서 복구하려면 Amazon EC2 인스턴스를 프로비저닝하고 파일이 포함된 S3 버킷을 탑재합니다.",
        "B": "AWS Storage Gateway 테이프 게이트웨이를 프로비저닝합니다. 데이터 백업 솔루션을 사용하여 모든 기존 데이터를 가상 테이프 라이브러리에 백업합니다. 초기 백업이 완료된 후 야간에 실행되도록 데이터 백업 솔루션을 구성합니다. 재해에서 복구하려면 Amazon EC2 인스턴스를 프로비저닝하고 가상 테이프 라이브러리의 볼륨에서 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 데이터를 복원합니다.",
        "C": "AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨을 프로비저닝합니다. 로컬 캐시를 10TB로 설정합니다. iSCSI를 사용하여 볼륨 게이트웨이 캐싱 볼륨을 기존 파일 서버에 마운트하고 모든 파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 예약된 스냅샷을 구성합니다. 재해에서 복구하려면 스냅샷을 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 복원하고 EBS 볼륨을 Amazon EC2 인스턴스에 연결합니다.",
        "D": "기존 파일 스토리지 볼륨과 동일한 양의 디스크 공간으로 AWS Storage Gateway 볼륨 게이트웨이 저장 볼륨을 프로비저닝합니다. iSCSI를 사용하여 볼륨 게이트웨이 저장 볼륨을 기존 파일 서버에 마운트하고 모든 파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 예약된 스냅샷을 구성합니다. 재해에서 복구하려면 스냅샷을 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 복원하고 EBS 볼륨을 Amazon EC2 인스턴스에 연결합니다."
      },
      "eng": {
        "A": "Provision an Amazon S3 File Gateway as a virtual machine (VM) that is hosted on premises. Set the local cache to 10 TB. Modify existing applications to access the files through the NFS protocol. To recover from a disaster, provision an Amazon EC2 instance and mount the S3 bucket that contains the files.",
        "B": "Provision an AWS Storage Gateway tape gateway. Use a data backup solution to back up all existing data to a virtual tape library. Configure the data backup solution to run nightly after the initial backup is complete. To recover from a disaster, provision an Amazon EC2 instance and restore the data to an Amazon Elastic Block Store (Amazon EBS) volume from the volumes in the virtual tape library.",
        "C": "Provision an AWS Storage Gateway Volume Gateway cached volume. Set the local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.",
        "D": "Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99711-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 404,
    "question": {
      "kor": "회사의 비용에 대한 최근 분석에서는 백업 비용을 줄여야 할 필요성이 강조되었습니다. 회사의 최고 정보 책임자는 온프레미스 백업 인프라를 IT 단순화하고 물리적 백업 테이프 사용을 제거하여 비용을 절감하고자 합니다. 회사는 온프레미스 백업 애플리케이션 및 워크플로우에 대한 기존 투자를 보존해야 합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information officer wants to simplify the onpremises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다.",
        "B": "NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템을 설정합니다.",
        "C": "iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템을 설정합니다.",
        "D": "iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다."
      },
      "eng": {
        "A": "Set up AWS Storage Gateway to connect with the backup applications using the NFS interface.",
        "B": "Set up an Amazon EFS file system that connects with the backup applications using the NFS interface.",
        "C": "Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface.",
        "D": "Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/116975-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 539,
    "question": {
      "kor": "의학 연구실에서 새로운 연구와 관련된 데이터를 생성합니다. 연구소는 온프레미스 파일 기반 애플리케이션을 위해 전국의 클리닉에 최소한의 대기 시간으로 데이터를 제공하고자 합니다. 데이터 파일은 각 클리닉에 대한 읽기 전용 권한이 있는 Amazon S3 버킷에 저장됩니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A medical research lab produces data that is related to a new study. The lab wants to make the data available with minimum latency to clinics across the country for their on-premises, file-based applications. The data files are stored in an Amazon S3 bucket that has read-only permissions for each clinic.\nWhat should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "각 클리닉에서 온프레미스로 AWS Storage Gateway 파일 게이트웨이를 가상 머신(VM)으로 배포합니다.",
        "B": "처리를 위해 AWS DataSync를 사용하여 각 클리닉의 온프레미스 애플리케이션으로 파일을 마이그레이션합니다.",
        "C": "각 클리닉에서 온프레미스로 AWS Storage Gateway 볼륨 게이트웨이를 가상 머신(VM)으로 배포합니다.",
        "D": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 각 클리닉의 온프레미스 서버에 연결합니다."
      },
      "eng": {
        "A": "Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic",
        "B": "Migrate the files to each clinic’s on-premises applications by using AWS DataSync for processing.",
        "C": "Deploy an AWS Storage Gateway volume gateway as a virtual machine (VM) on premises at each clinic.",
        "D": "Attach an Amazon Elastic File System (Amazon EFS) file system to each clinic’s on-premises servers."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95002-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 560,
    "question": {
      "kor": "회사는 온프레미스 서버를 사용하여 애플리케이션을 호스팅합니다. 회사의 저장 용량이 부족합니다. 애플리케이션은 블록 스토리지와 NFS 스토리지를 모두 사용합니다. 회사는 기존 애플리케이션을 재설계하지 않고 로컬 캐싱을 지원하는 고성능 솔루션이 필요합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company uses on-premises servers to host its applications. The company is running out of storage capacity. The applications use both block storage and NFS storage. The company needs a high-performing solution that supports local caching without re-architecting its existing applications.\nWhich combination of actions should a solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3를 온프레미스 서버에 파일 시스템으로 탑재합니다.",
        "B": "NFS 스토리지를 대체할 AWS Storage Gateway 파일 게이트웨이를 배포합니다.",
        "C": "AWS Snowball Edge를 배포하여 온프레미스 서버에 NFS 마운트를 프로비저닝합니다.",
        "D": "블록 스토리지를 대체할 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다.",
        "E": "Amazon Elastic File System(Amazon EFS) 볼륨을 배포하고 온프레미스 서버에 탑재합니다."
      },
      "eng": {
        "A": "Mount Amazon S3 as a file system to the on-premises servers.",
        "B": "Deploy an AWS Storage Gateway file gateway to replace NFS storage.",
        "C": "Deploy AWS Snowball Edge to provision NFS mounts to on-premises servers.",
        "D": "Deploy an AWS Storage Gateway volume gateway to replace the block storage.",
        "E": "Deploy Amazon Elastic File System (Amazon EFS) volumes and mount them to on-premises servers."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109552-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 610,
    "question": {
      "kor": "한 제약회사에서 신약을 개발하고 있습니다. 지난 몇 달 동안 회사에서 생성되는 데이터의 양이 기하급수적으로 증가했습니다. 회사의 연구원들은 최소한의 지연으로 즉시 사용할 수 있도록 전체 데이터 세트의 하위 집합을 정기적으로 요구합니다. 그러나 전체 데이터 세트에 매일 액세스할 필요는 없습니다. 현재 모든 데이터는 온프레미스 스토리지 어레이에 상주하고 있으며 회사는\n지속적인 자본 비용을 줄이고 싶어합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 합니까?",
      "eng": "A pharmaceutical company is developing a new drug. The volume of data that the company generates has grown exponentially over the past few months.\nThe company's researchers regularly require a subset of the entire dataset to be immediately available with minimal lag. However, the entire dataset does not need to be accessed on a daily basis. All the data currently resides in on-premises storage arrays, and the company wants to reduce ongoing capital expenses.\nWhich storage solution should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 예약된 cron 작업으로 실행하여 지속적으로 데이터를 Amazon S3 버킷으로 마이그레이션합니다.",
        "B": "Amazon S3 버킷을 대상 스토리지로 사용하여 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 데이터를 Storage Gateway 어플라이언스로 마이그레이션합니다.",
        "C": "Amazon S3 버킷을 대상 스토리지로 사용하여 캐시된 볼륨이 있는 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 데이터를 Storage Gateway 어플라이언스로 마이그레이션합니다.",
        "D": "온프레미스 환경에서 AWS로 AWS Site-to-Site VPN 연결을 구성합니다. Amazon Elastic File System(Amazon EFS) 파일 시스템으로 데이터를 마이그레이션합니다."
      },
      "eng": {
        "A": "Run AWS DataSync as a scheduled cron job to migrate the data to an Amazon S3 bucket on an ongoing basis.",
        "B": "Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
        "C": "Deploy an AWS Storage Gateway volume gateway with cached volumes with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
        "D": "Configure an AWS Site-to-Site VPN connection from the on-premises environment to AWS. Migrate data to an Amazon Elastic File System (Amazon EFS) file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 677,
    "question": {
      "kor": "회사에 스토리지 용량이 부족한 온프레미스 데이터 센터가 있습니다. 회사는 대역폭 비용을 최소화하면서 스토리지 인프라를 AWS로 마이그레이션하려고 합니다. 솔루션은 추가 비용 없이 데이터를 즉시 검색할 수 있어야 합니다.\n이러한 요구 사항을 어떻게 충족할 수 있습니까?",
      "eng": "A company has an on-premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs. The solution must allow for immediate retrieval of data at no additional cost.\nHow can these requirements be met?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 Glacier Vault를 배포하고 빠른 검색을 활성화합니다. 워크로드에 대해 프로비저닝된 검색 용량을 활성화합니다.",
        "B": "캐시된 볼륨을 사용하여 AWS Storage Gateway를 배포합니다. Storage Gateway를 사용하면 자주 액세스하는 데이터 하위 집합의 복사본을 로컬에 보관하면서 Amazon S3에 데이터를 저장할 수 있습니다.",
        "C": "저장된 볼륨을 사용하여 AWS Storage Gateway를 배포하여 데이터를 로컬에 저장합니다. Storage Gateway를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기식으로 백업합니다.",
        "D": "AWS Direct Connect를 배포하여 온프레미스 데이터 센터에 연결합니다. 데이터를 로컬에 저장하도록 AWS Storage Gateway를 구성합니다. Storage Gateway를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기식으로 백업합니다."
      },
      "eng": {
        "A": "Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.",
        "B": "Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.",
        "C": "Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.",
        "D": "Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 710,
    "question": {
      "kor": "소셜 미디어 회사에는 데이터를 수집하고 처리하는 워크로드가 있습니다. 워크로드는 온프레미스 NFS 스토리지에 데이터를 저장합니다. 데이터 저장소는 회사의 확장되는 비즈니스 요구 사항을 충족할 만큼 빠르게 확장할 수 없습니다. 회사는 현재 데이터 스토어를 AWS로 마이그레이션하려고 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A social media company has workloads that collect and process data. The workloads store the data in on-premises NFS storage. The data store cannot scale fast enough to meet the company’s expanding business needs. The company wants to migrate the current data store to AWS.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "AWS Storage Gateway 볼륨 게이트웨이를 설정합니다. Amazon S3 수명 주기 정책을 사용하여 데이터를 적절한 스토리지 클래스로 전환합니다.",
        "B": "AWS Storage Gateway Amazon S3 파일 게이트웨이를 설정합니다. Amazon S3 수명 주기 정책을 사용하여 데이터를 적절한 스토리지 클래스로 전환합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) Standard-Infrequent Access(Standard-IA) 스토리지 클래스를 사용합니다. 빈번하지 않은 액세스 수명주기 정책을 활성화합니다.",
        "D": "One Zone-Infrequent Access(One Zone-IA) 스토리지 클래스를 사용합니다. Amazon Elastic File System(Amazon EFS) 빈번하지 않은 액세스 수명주기 정책을 활성화합니다."
      },
      "eng": {
        "A": "Set up an AWS Storage Gateway Volume Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.",
        "B": "Set up an AWS Storage Gateway Amazon S3 File Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.",
        "C": "Use the Amazon Elastic File System (Amazon EFS) Standard-Infrequent Access (Standard-IA) storage class. Activate the infrequent access lifecycle policy.",
        "D": "Use the Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA) storage class. Activate the infrequent access lifecycle policy."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135263-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 715,
    "question": {
      "kor": "회사에는 매일 수백 개의 파일을 생성하는 온프레미스 비즈니스 애플리케이션이 있습니다. 이러한 파일은 SMB 파일 공유에 저장되며 애플리케이션 서버에 대한 지연 시간이 짧은 연결이 필요합니다. 새로운 회사 정책에는 애플리케이션에서 생성된 모든 파일을 AWS에 복사해야 한다고 명시되어 있습니다. AWS에 대한 VPN 연결이 이미 있습니다.\n애플리케이션 개발 팀은 애플리케이션을 AWS로 이동하는 데 필요한 코드를 수정할 시간이 없습니다.\n애플리케이션이 파일을 AWS에 복사할 수 있도록 솔루션 아키텍트는 어떤 서비스를 권장해야 합니까?",
      "eng": "A company has an on-premises business application that generates hundreds of files each day. These files are stored on an SMB file share and require a low-latency connection to the application servers. A new company policy states all application-generated files must be copied to AWS. There is already a VPN connection to AWS.\nThe application development team does not have time to make the necessary code modifications to move the application to AWS.\nWhich service should a solutions architect recommend to allow the application to copy files to AWS?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic File System(Amazon EFS)",
        "B": "Windows 파일 서버용 Amazon FSx",
        "C": "AWS 스노우볼",
        "D": "AWS 스토리지 게이트웨이"
      },
      "eng": {
        "A": "Amazon Elastic File System (Amazon EFS)",
        "B": "Amazon FSx for Windows File Server",
        "C": "AWS Snowball",
        "D": "AWS Storage Gateway"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/138083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 720,
    "question": {
      "kor": "회사에는 온프레미스 ISCSI(Internet Small Computer Systems Interface) 네트워크 스토리지 서버가 여러 대 있습니다. 회사는 AWS 클라우드로 이동하여 이러한 서버의 수를 줄이고 싶어합니다. 솔루션 설계자는 자주 사용되는 데이터에 대한 짧은 대기 시간 액세스를 제공하고 최소한의 인프라 변경으로 온프레미스 서버에 대한 종속성을 줄여야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 파일 게이트웨이를 배포합니다.",
        "B": "Amazon S3에 대한 백업과 함께 Amazon Elastic Block Store(Amazon EBS) 스토리지를 배포합니다.",
        "C": "저장된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다.",
        "D": "캐시된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다."
      },
      "eng": {
        "A": "Deploy an Amazon S3 File Gateway.",
        "B": "Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.",
        "C": "Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.",
        "D": "Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "Storage Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121170-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 765,
    "question": {
      "kor": "일기 예보 회사는 밀리초 미만의 대기 시간으로 수백 기가바이트의 데이터를 처리해야 합니다. 이 회사는 데이터 센터에 HPC(고성능 컴퓨팅) 환경을 보유하고 있으며 예측 기능을 확장하려고 합니다.\n솔루션 설계자는 대량의 지속적인 처리량을 처리할 수 있는 고가용성 클라우드 스토리지 솔루션을 식별해야 합니다. 솔루션에 저장된 파일은 전체 데이터 세트에 동시에 액세스하고 처리하는 수천 개의 컴퓨팅 인스턴스에 액세스할 수 있어야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities.\nA solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset.\nWhat should the solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Lustre 스크래치 파일 시스템에는 Amazon FSx를 사용합니다.",
        "B": "Lustre 영구 파일 시스템에는 Amazon FSx를 사용합니다.",
        "C": "버스팅 처리량 모드와 함께 Amazon Elastic File System(Amazon EFS)을 사용합니다.",
        "D": "프로비저닝된 처리량 모드와 함께 Amazon Elastic File System(Amazon EFS)을 사용합니다."
      },
      "eng": {
        "A": "Use Amazon FSx for Lustre scratch file systems.",
        "B": "Use Amazon FSx for Lustre persistent file systems.",
        "C": "Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode.",
        "D": "Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125586-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 290,
    "question": {
      "kor": "회사에서 재무 위험 모델링을 위해 AWS에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 합니다. 회사의 HPC 워크로드는 Linux에서 실행됩니다. 각 HPC 워크플로는 수백 개의 Amazon EC2 스팟 인스턴스에서 실행되고 수명이 짧으며 궁극적으로 분석 및 향후 장기적 사용을 위해 영구 스토리지에 저장되는 수천 개의 출력 파일을 생성합니다.\n이 회사는 모든 EC2 인스턴스에서 데이터를 처리할 수 있도록 온프레미스 데이터를 장기 영구 스토리지로 복사할 수 있는 클라우드 스토리지 솔루션을 찾고 있습니다. 솔루션은 또한 데이터 세트와 출력 파일을 읽고 쓰기 위해 영구 스토리지와 통합된 고성능 파일 시스템이어야 합니다.\n이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?",
      "eng": "A company wants to use high performance computing (HPC) infrastructure on AWS for financial risk modeling. The company’s HPC workloads run on Linux.\nEach HPC workflow runs on hundreds of Amazon EC2 Spot Instances, is short-lived, and generates thousands of output files that are ultimately stored in persistent storage for analytics and long-term future use.\nThe company seeks a cloud storage solution that permits the copying of on-premises data to long-term persistent storage to make data available for processing by all EC2 instances. The solution should also be a high performance file system that is integrated with persistent storage to read and write datasets and output files.\nWhich combination of AWS services meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3와 통합된 Amazon FSx for Lustre",
        "B": "Amazon S3와 통합된 Windows 파일 서버용 Amazon FSx",
        "C": "Amazon Elastic Block Store(Amazon EBS)와 통합된 Amazon S3 Glacier",
        "D": "Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2) 볼륨과 통합된 VPC 엔드포인트가 있는 Amazon S3 버킷"
      },
      "eng": {
        "A": "Amazon FSx for Lustre integrated with Amazon S3",
        "B": "Amazon FSx for Windows File Server integrated with Amazon S3",
        "C": "Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)",
        "D": "Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume"
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87634-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 354,
    "question": {
      "kor": "연구소는 약 8TB의 데이터를 처리해야 합니다. 실험실에는 스토리지 하위 시스템에 대해 1밀리초 미만의 대기 시간과 최소 6GBps의 처리량이 필요합니다. Amazon Linux를 실행하는 수백 개의 Amazon EC2 인스턴스가 데이터를 배포하고 처리합니다.\n성능 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A research laboratory needs to process approximately 8 TB of data. The laboratory requires sub-millisecond latencies and a minimum throughput of 6 GBps for the storage subsystem. Hundreds of Amazon EC2 instances that run Amazon Linux will distribute and process the data.\nWhich solution will meet the performance requirements?"
    },
    "choices": {
      "kor": {
        "A": "NetApp ONTAP 파일 시스템용 Amazon FSx를 생성합니다. 각 볼륨의 계층화 정책을 ALL로 설정했습니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 fila 시스템을 탑재합니다.",
        "B": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 SSD 스토리지를 사용하는 Amazon FSx for Lustre 파일 시스템을 생성합니다. Amazon S3에서 데이터를 가져오고 내보내는 옵션을 선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다.",
        "C": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 HDD 스토리지를 사용하는 Amazon FSx for Lustre 파일 시스템을 생성합니다. Amazon S3에서 데이터를 가져오고 내보내는 옵션을 선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다.",
        "D": "NetApp ONTAP 파일 시스템용 Amazon FSx를 생성합니다. 각 볼륨의 계층화 정책을 NONE으로 설정합니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 파일 시스템을 탑재합니다."
      },
      "eng": {
        "A": "Create an Amazon FSx for NetApp ONTAP file system. Sat each volume’ tiering policy to ALL. Import the raw data into the file system. Mount the fila system on the EC2 instances.",
        "B": "Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.",
        "C": "Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent HDD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.",
        "D": "Create an Amazon FSx for NetApp ONTAP file system. Set each volume’s tiering policy to NONE. Import the raw data into the file system. Mount the file system on the EC2 instances."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99676-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 579,
    "question": {
      "kor": "한 회사는 AWS 클라우드에서 긴밀하게 결합된 고성능 컴퓨팅(HPC) 환경을 설계하고 있습니다. 회사는 네트워킹 및 스토리지를 위해 HPC 환경을 최적화하는 기능을 포함해야 합니다.\n이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company is designing a tightly coupled high performance computing (HPC) environment in the AWS Cloud. The company needs to include features that will optimize the HPC environment for networking and storage.\nWhich combination of solutions will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "AWS Global Accelerator에서 액셀러레이터를 생성합니다. 가속기에 대한 사용자 지정 라우팅을 구성합니다.",
        "B": "Lustre 파일 시스템용 Amazon FSx를 생성합니다. 스크래치 스토리지로 파일 시스템을 구성합니다.",
        "C": "Amazon CloudFront 배포판을 생성합니다. 뷰어 프로토콜 정책을 HTTP 및 HTTPS로 구성합니다.",
        "D": "Amazon EC2 인스턴스를 시작합니다. EFA(Elastic Fabric Adapter)를 인스턴스에 연결합니다.",
        "E": "환경을 관리하기 위해 AWS Elastic Beanstalk 배포를 생성합니다."
      },
      "eng": {
        "A": "Create an accelerator in AWS Global Accelerator. Configure custom routing for the accelerator.",
        "B": "Create an Amazon FSx for Lustre file system. Configure the file system with scratch storage.",
        "C": "Create an Amazon CloudFront distribution. Configure the viewer protocol policy to be HTTP and HTTPS.",
        "D": "Launch Amazon EC2 instances. Attach an Elastic Fabric Adapter (EFA) to the instances.",
        "E": "Create an AWS Elastic Beanstalk deployment to manage the environment."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre",
      "EFA"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133034-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 639,
    "question": {
      "kor": "한 회사는 최근 해양 조사에서 얻은 200TB의 데이터를 AWS Snowball Edge Storage Optimized 디바이스에 복사합니다. 이 회사는 석유 및 가스 매장지를 찾기 위해 AWS에 호스팅되는 고성능 컴퓨팅(HPC) 클러스터를 보유하고 있습니다. 솔루션 아키텍트는 Snowball Edge Storage Optimized 디바이스의 데이터에 대한 일관된 밀리초 미만의 지연 시간과 높은 처리량 액세스를 클러스터에 제공해야 합니다. 회사는 디바이스를 AWS로 다시 보내고 있습니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage Optimized devices. The company has a high performance computing (HPC) cluster that is hosted on AWS to look for oil and gas deposits. A solutions architect must provide the cluster with consistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge Storage Optimized devices. The company is sending the devices back to AWS.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 버킷을 생성합니다. 데이터를 S3 버킷으로 가져옵니다. S3 버킷을 사용하도록 AWS Storage Gateway 파일 게이트웨이를 구성합니다. HPC 클러스터 인스턴스에서 파일 게이트웨이에 액세스합니다.",
        "B": "Amazon S3 버킷을 생성합니다. 데이터를 S3 버킷으로 가져옵니다. Lustre 파일 시스템용 Amazon FSx를 구성하고 이를 S3 버킷과 통합합니다. HPC 클러스터 인스턴스에서 FSx for Lustre 파일 시스템에 액세스합니다.",
        "C": "Amazon S3 버킷과 Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 데이터를 S3 버킷으로 가져옵니다. S3 버킷의 데이터를 EFS 파일 시스템에 복사 합니다. HPC 클러스터 인스턴스에서 EFS 파일 시스템에 액세스합니다.",
        "D": "Lustre 파일 시스템용 Amazon FSx를 생성합니다. 데이터를 FSx for Lustre 파일 시스템으로 직접 가져옵니다. HPC 클러스터 인스턴스에서 FSx for Lustre 파일 시스템에 액세스합니다."
      },
      "eng": {
        "A": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage Gateway file gateway to use the S3 bucket. Access the file gateway from the HPC cluster instances.",
        "B": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances.",
        "C": "Create an Amazon S3 bucket and an Amazon Elastic File System (Amazon EFS) file system. Import the data into the S3 bucket. Copy the data from the S3 bucket to the EFS file system. Access the EFS file system from the HPC cluster instances.",
        "D": "Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file system. Access the FSx for Lustre file system from the HPC cluster instances."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132866-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 781,
    "question": {
      "kor": "회사는 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션용 공유 스토리지 솔루션을 구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is implementing a shared storage solution for a gaming application that is hosted in an on-premises data center. The company needs the ability to use Lustre clients to access data. The solution must be fully managed.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "B": "Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 만들고 Lustre를 지원하도록 구성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다.",
        "D": "Amazon FSx for Lustre 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다."
      },
      "eng": {
        "A": "Create an AWS Storage Gateway file gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
        "B": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
        "C": "Create an Amazon Elastic File System (Amazon EFS) file system, and configure it to support Lustre. Attach the file system to the origin server. Connect the application server to the file system.",
        "D": "Create an Amazon FSx for Lustre file system. Attach the file system to the origin server. Connect the application server to the file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85811-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 794,
    "question": {
      "kor": "회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션용 공유 스토리지 솔루션을 구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is implementing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use Lustre clients to access data. The solution must be fully managed.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. 파일 시스템을 애플리케이션 서버에 마운트합니다.",
        "B": "AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "C": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 만들고 Lustre를 지원하도록 구성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다.",
        "D": "Amazon FSx for Lustre 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다."
      },
      "eng": {
        "A": "Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.",
        "B": "Create an AWS Storage Gateway file gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
        "C": "Create an Amazon Elastic File System (Amazon EFS) file system, and configure it to support Lustre. Attach the file system to the origin server. Connect the application server to the file system.",
        "D": "Create an Amazon FSx for Lustre file system. Attach the file system to the origin server. Connect the application server to the file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102184-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 869,
    "question": {
      "kor": "솔루션 아키텍트는 AWS 클라우드에서 고성능 컴퓨팅 워크로드(HPC)를 호스팅해야 합니다. 워크로드는 수백 개의 인스턴스에서 Amazon EC2 실행되며 대규모 데이터 세트의 분산 처리를 활성화하려면 공유 파일 시스템에 대한 병렬 액세스가 필요합니다. 데이터 세트는 여러 인스턴스에서 동시에 액세스됩니다. 워크로드에는 1ms 이내의 액세스 지연 시간이 필요합니다. 처리가 완료된 후 엔지니어는 수동 후처리를 위해 데이터세트에 액세스해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud. The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously. The workload requires access latency within 1 ms. After processing has completed, engineers will need access to the dataset for manual postprocessing.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic File System(Amazon EFS)을 공유 파일 시스템으로 사용합니다. Amazon EFS에서 데이터세트에 액세스합니다.",
        "B": "공유 파일 시스템으로 사용할 Amazon S3 버킷을 탑재합니다. S3 버킷에서 직접 사후 처리를 수행합니다.",
        "C": "Amazon FSx for Lustre를 공유 파일 시스템으로 사용합니다. 사후 처리를 위해 파일 시스템을 Amazon S3 버킷에 연결합니다.",
        "D": "Amazon S3 버킷을 공유하여 처리 및 사후 처리를 위해 모든 인스턴스에 탑재할 수 있도록 AWS Resource Access Manager를 구성합니다."
      },
      "eng": {
        "A": "Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.",
        "B": "Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.",
        "C": "Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.",
        "D": "Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Lustre"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125584-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 726,
    "question": {
      "kor": "한 회사는 CIFS 및 NFS 파일 공유를 위해 기본 AWS 지역에서 NetApp ONTAP용 Amazon FSx를 사용합니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션은 파일 공유에 액세스합니다. 회사는 보조 지역에 스토리지 재해 복구(DR) 솔루션이 필요합니다. 보조 리전에 복제된 데이터는 기본 리전과 동일한 프로토콜을 사용하여 액세스해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses Amazon FSx for NetApp ONTAP in its primary AWS Region for CIFS and NFS file shares. Applications that run on Amazon EC2 instances access the file shares. The company needs a storage disaster recovery (DR) solution in a secondary Region. The data that is replicated in the secondary\nRegion needs to be accessed by using the same protocols as the primary Region.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Lambda 함수를 생성하여 Amazon S3 버킷에 데이터를 복사합니다. S3 버킷을 보조 리전에 복제합니다.",
        "B": "AWS Backup을 사용하여 FSx for ONTAP 볼륨의 백업을 생성합니다. 볼륨을 보조 리전에 복사합니다. 백업에서 ONTAP 인스턴스용 새 FSx를 생성합니다.",
        "C": "보조 지역에 FSx for ONTAP 인스턴스를 생성합니다. NetApp SnapMirror를 사용하여 기본 지역에서 보조 지역으로 데이터를 복제합니다.",
        "D": "Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. 현재 데이터를 볼륨으로 마이그레이션합니다. 볼륨을 보조 리전에 복제합니다."
      },
      "eng": {
        "A": "Create an AWS Lambda function to copy the data to an Amazon S3 bucket. Replicate the S3 bucket to the secondary Region.",
        "B": "Create a backup of the FSx for ONTAP volumes by using AWS Backup. Copy the volumes to the secondary Region. Create a new FSx for ONTAP instance from the backup.",
        "C": "Create an FSx for ONTAP instance in the secondary Region. Use NetApp SnapMirror to replicate data from the primary Region to the secondary Region.",
        "D": "Create an Amazon Elastic File System (Amazon EFS) volume. Migrate the current data to the volume. Replicate the volume to the secondary Region."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for NetApp ONTAP"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125545-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 901,
    "question": {
      "kor": "한 회사가 온프레미스 스토리지에서 AWS로 대량의 데이터를 마이그레이션하고 있습니다. 동일한 AWS 리전에 있는 Windows, Mac 및 Linux 기반 Amazon EC2 인스턴스는 SMB 및 NFS 스토리지 프로토콜을 사용하여 데이터에 액세스합니다. 회사는 정기적으로 데이터의 일부에 액세스합니다. 회사는 나머지 데이터에 드물게 액세스합니다.\n회사는 데이터를 호스팅하기 위한 솔루션을 설계해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is migrating a large amount of data from on-premises storage to AWS. Windows, Mac, and Linux based Amazon EC2 instances in the same AWS Region will access the data by using SMB and NFS storage protocols. The company will access a portion of the data routinely. The company will access the remaining data infrequently.\nThe company needs to design a solution to host the data.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "EFS Intelligent-Tiering을 사용하는 Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. AWS DataSync를 사용하여 데이터를 EFS 볼륨으로 마이그레이션합니다.",
        "B": "ONTAP 인스턴스용 Amazon FSx를 생성합니다. 자동 계층화 정책을 사용하는 루트 볼륨이 있는 FSx for ONTAP 파일 시스템을 생성합니다. 데이터를 FSx for ONTAP 볼륨으로 마이그레이션합니다.",
        "C": "S3 Intelligent-Tiering을 사용하는 Amazon S3 버킷을 생성합니다. AWS Storage Gateway Amazon S3 파일 게이트웨이를 사용하여 데이터를 S3 버킷으로 마이그레이션합니다.",
        "D": "OpenZFS 파일 시스템용 Amazon FSx를 생성합니다. 데이터를 새 볼륨으로 마이그레이션합니다."
      },
      "eng": {
        "A": "Create an Amazon Elastic File System (Amazon EFS) volume that uses EFS Intelligent-Tiering. Use AWS DataSync to migrate the data to the EFS volume.",
        "B": "Create an Amazon FSx for ONTAP instance. Create an FSx for ONTAP file system with a root volume that uses the auto tiering policy. Migrate the data to the FSx for ONTAP volume.",
        "C": "Create an Amazon S3 bucket that uses S3 Intelligent-Tiering. Migrate the data to the S3 bucket by using an AWS Storage Gateway Amazon S3 File Gateway.",
        "D": "Create an Amazon FSx for OpenZFS file system. Migrate the data to the new volume."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for NetApp ONTAP"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132892-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 441,
    "question": {
      "kor": "회사는 온프레미스 NAS(Network Attached Storage) 시스템을 사용하여 HPC(고성능 컴퓨팅) 워크로드에 파일 공유를 제공합니다. 회사는 지연 시간에 민감한 HPC 워크로드와 스토리지를 AWS 클라우드로 마이그레이션하려고 합니다. 회사는 파일 시스템에서 NFS 및 SMB 다중 프로토콜 액세스를 제공할 수 있어야 합니다.\n가장 짧은 대기 시간으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company uses an on-premises network-attached storage (NAS) system to provide file shares to its high performance computing (HPC) workloads. The company wants to migrate its latency-sensitive HPC workloads and its storage to the AWS Cloud. The company must be able to provide NFS and SMB multiprotocol access from the file system.\nWhich solution will meet these requirements with the LEAST latency? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "컴퓨팅 최적화 EC2 인스턴스를 클러스터 배치 그룹에 배포합니다.",
        "B": "컴퓨팅 최적화 EC2 인스턴스를 파티션 배치 그룹에 배포합니다.",
        "C": "EC2 인스턴스를 Amazon FSx for Lustre 파일 시스템에 연결합니다.",
        "D": "EC2 인스턴스를 Amazon FSx for OpenZFS 파일 시스템에 연결합니다.",
        "E": "EC2 인스턴스를 NetApp ONTAP 파일 시스템용 Amazon FSx에 연결합니다."
      },
      "eng": {
        "A": "Deploy compute optimized EC2 instances into a cluster placement group.",
        "B": "Deploy compute optimized EC2 instances into a partition placement group.",
        "C": "Attach the EC2 instances to an Amazon FSx for Lustre file system.",
        "D": "Attach the EC2 instances to an Amazon FSx for OpenZFS file system.",
        "E": "Attach the EC2 instances to an Amazon FSx for NetApp ONTAP file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for NetApp ONTAP",
      "placement group"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/126797-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 606,
    "question": {
      "kor": "연구 회사는 시뮬레이션 응용 프로그램과 시각화 응용 프로그램으로 구동되는 실험을 실행합니다. 시뮬레이션 애플리케이션은 Linux에서 실행되며 5분마다 NFS 공유에 중간 데이터를 출력 합니다. 시각화 응용 프로그램은 시뮬레이션 출력을 표시하고 SMB 파일 시스템이 필요한 Windows 데스크톱 응용 프로그램입니다.\n회사는 두 개의 동기화된 파일 시스템을 유지 관리합니다. 이 전략은 데이터 중복 및 비효율적인 리소스 사용을 유발합니다. 회사는 애플리케이션에 코드를 변경하지 않고 애플리케이션을 AWS로 마이그레이션해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A research company runs experiments that are powered by a simulation application and a visualization application. The simulation application runs on Linux and outputs intermediate data to an NFS share every 5 minutes. The visualization application is a Windows desktop application that displays the simulation output and requires an SMB file system.\nThe company maintains two synchronized file systems. This strategy is causing data duplication and inefficient resource usage. The company needs to migrate the applications to AWS without making code changes to either application.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "두 애플리케이션을 모두 AWS Lambda로 마이그레이션합니다. 애플리케이션 간에 데이터를 교환할 Amazon S3 버킷을 생성합니다.",
        "B": "두 애플리케이션을 모두 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션합니다. 스토리지용 Amazon FSx 파일 게이트웨이를 구성합니다.",
        "C": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션합니다. 애플리케이션 간에 데이터를 교환하도록 Amazon Simple Queue Service(Amazon SQS)를 구성합니다.",
        "D": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션합니다. 스토리지용 NetApp ONTAP용 Amazon FSx를 구성합니다."
      },
      "eng": {
        "A": "Migrate both applications to AWS Lambda. Create an Amazon S3 bucket to exchange data between the applications.",
        "B": "Migrate both applications to Amazon Elastic Container Service (Amazon ECS). Configure Amazon FSx File Gateway for storage.",
        "C": "Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon Simple Queue Service (Amazon SQS) to exchange data between the applications.",
        "D": "Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon FSx for NetApp ONTAP for storage."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for NetApp ONTAP"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99512-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 7,
    "question": {
      "kor": "한 회사가 AWS에서 여러 Windows 워크로드를 실행합니다. 회사 직원은 두 개의 Amazon EC2 인스턴스에서 호스팅되는 Windows 파일 공유를 사용합니다. 파일 공유는 서로 간에 데이터를 동기화하고 복제본을 유지합니다. 회사는 사용자가 현재 파일에 액세스하는 방식을 보존하는 가용성이 높고 내구성이 뛰어난 스토리지 솔루션을 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company runs multiple Windows workloads on AWS. The company's employees use Windows file shares that are hosted on two Amazon EC2 instances.\nThe file shares synchronize data between themselves and maintain duplicate copies. The company wants a highly available and durable storage solution that preserves how users currently access the files.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "모든 데이터를 Amazon S3로 마이그레이션합니다. 사용자가 파일에 액세스할 수 있도록 IAM 인증을 설정합니다.",
        "B": "Amazon S3 파일 게이트웨이를 설정합니다. 기존 EC2 인스턴스에 S3 File Gateway를 탑재합니다.",
        "C": "다중 AZ 구성을 사용하여 파일 공유 환경을 Windows 파일 서버용 Amazon FSx로 확장합니다. 모든 데이터를 FSx for Windows File Server로 마이그레이션합니다.",
        "D": "다중 AZ 구성을 사용하여 파일 공유 환경을 Amazon Elastic File System(Amazon EFS)으로 확장합니다. 모든 데이터를 Amazon EFS로 마이그레이션합니다."
      },
      "eng": {
        "A": "Migrate all the data to Amazon S3. Set up IAM authentication for users to access files.",
        "B": "Set up an Amazon S3 File Gateway. Mount the S3 File Gateway on the existing EC2 instances.",
        "C": "Extend the file share environment to Amazon FSx for Windows File Server with a Multi-AZ configuration. Migrate all the data to FSx for Windows File Server.",
        "D": "Extend the file share environment to Amazon Elastic File System (Amazon EFS) with a Multi-AZ configuration. Migrate all the data to Amazon EFS."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server",
      "Windows file sharing"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85574-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 28,
    "question": {
      "kor": "한 회사가 AWS에서 호스팅하는 미디어 애플리케이션을 위한 공유 스토리지 솔루션을 구현하고 있습니다. 회사는 SMB 클라이언트를 사용하여 저장된 데이터에 액세스할 수 있는 기능이 필요합니다.\n최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is implementing a shared storage solution for a media application that the company hosts on AWS. The company needs the ability to use SMB clients to access stored data.\nWhich solution will meet these requirements with the LEAST administrative overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Storage Gateway 볼륨 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "B": "AWS Storage Gateway 테이프 게이트웨이를 생성합니다. Amazon S3를 사용하도록 테이프를 구성합니다. 애플리케이션 서버를 테이프 게이트웨이에 연결합니다.",
        "C": "Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "D": "Windows 파일 서버 파일 시스템용 Amazon FSx를 생성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다."
      },
      "eng": {
        "A": "Create an AWS Storage Gateway volume gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
        "B": "Create an AWS Storage Gateway tape gateway. Configure tapes to use Amazon S3. Connect the application server to the tape gateway.",
        "C": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
        "D": "Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95006-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 114,
    "question": {
      "kor": "회사에는 Microsoft Windows 공유 파일 저장소가 필요한 온-프레미스에서 실행되는 대규모 Microsoft SharePoint 배포가 있습니다. 이 회사는 이 워크로드를 AWS 클라우드로 마이그레이션하려고 하며 다양한 스토리지 옵션을 고려하고 있습니다. 저장소 솔루션은 액세스 제어를 위해 가용성이 높고 Active Directory와 통합되어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control.\nWhich solution will satisfy these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EFS 스토리지를 구성하고 인증을 위한 Active Directory 도메인을 설정합니다.",
        "B": "두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다.",
        "C": "Amazon S3 버킷을 생성하고 이를 볼륨으로 탑재하도록 Microsoft Windows Server를 구성합니다.",
        "D": "AWS에서 Windows File Server 파일 시스템용 Amazon FSx를 생성하고 인증을 위한 Active Directory 도메인을 설정합니다."
      },
      "eng": {
        "A": "Configure Amazon EFS storage and set the Active Directory domain for authentication.",
        "B": "Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones.",
        "C": "Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume.",
        "D": "Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86626-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 158,
    "question": {
      "kor": "회사에 AWS로 마이그레이션해야 하는 Windows 기반 애플리케이션이 있습니다. 이 애플리케이션은 여러 가용 영역에 배포된 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 Windows 파일 시스템을 사용해야 합니다.\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company has a Windows-based application that must be migrated to AWS. The application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances that are deployed across multiple Availability Zone:\nWhat should a solutions architect do to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "볼륨 게이트웨이 모드에서 AWS Storage Gateway를 구성합니다. 각 Windows 인스턴스에 볼륨을 마운트합니다.",
        "B": "Windows 파일 서버용 Amazon FSx를 구성합니다. Amazon FSx 파일 시스템을 각 Windows 인스턴스에 탑재합니다.",
        "C": "Amazon Elastic File System(Amazon EFS)을 사용하여 파일 시스템을 구성합니다. EFS 파일 시스템을 각 Windows 인스턴스에 마운트합니다.",
        "D": "필요한 크기로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 각 EC2 인스턴스를 볼륨에 연결합니다. 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트합니다."
      },
      "eng": {
        "A": "Configure AWS Storage Gateway in volume gateway mode. Mount the volume to each Windows instance.",
        "B": "Configure Amazon FSx for Windows File Server. Mount the Amazon FSx file system to each Windows instance.",
        "C": "Configure a file system by using Amazon Elastic File System (Amazon EFS). Mount the EFS file system to each Windows instance.",
        "D": "Configure an Amazon Elastic Block Store (Amazon EBS) volume with the required size. Attach each EC2 instance to the volume. Mount the file system within the volume to each Windows instance."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87650-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 214,
    "question": {
      "kor": "회사에서 Windows 기반 애플리케이션을 온프레미스에서 AWS 클라우드로 마이그레이션하려고 합니다. 애플리케이션에는 애플리케이션 계층, 비즈니스 계층 및 Microsoft SQL Server\n가 포함된 데이터베이스 계층의 세 가지 계층이 있습니다. 회사는 기본 백업 및 데이터 품질 서비스와 같은 SQL Server의 특정 기능을 사용하려고 합니다. 또한 회사는 계층 간에 처리를 위해\n파일을 공유해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까?",
      "eng": "A company wants to migrate a Windows-based application from on premises to the AWS Cloud. The application has three tiers: an application tier, a business tier, and a database tier with Microsoft SQL Server. The company wants to use specific features of SQL Server such as native backups and Data Quality Services. The company also needs to share files for processing between the tiers.\nHow should a solutions architect design the architecture to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 Amazon FSx File Gateway를 사용합니다.",
        "B": "Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 Amazon FSx for Windows File Server를 사용합니다.",
        "C": "Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. Amazon RDS에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 Amazon",
        "D": "Elastic File System(Amazon EFS)을 사용합니다.",
        "E": "Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. Amazon RDS에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 프로비저닝된",
        "F": "IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다."
      },
      "eng": {
        "A": "Host all three tiers on Amazon EC2 instances. Use Amazon FSx File Gateway for file sharing between the tiers.",
        "B": "Host all three tiers on Amazon EC2 instances. Use Amazon FSx for Windows File Server for file sharing between the tiers.",
        "C": "Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use Amazon Elastic File System (Amazon EFS) for file sharing between the tiers.",
        "D": "Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume for file sharing between the tiers."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99670-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 243,
    "question": {
      "kor": "솔루션 설계자는 Windows 인터넷 정보 서비스(IIS) 웹 애플리케이션을 AWS로 마이그레이션해야 합니다. 애플리케이션은 현재 사용자의 온프레미스 NAS(Network-Attached Storage)에서 호스팅되는 파일 공유에 의존합니다. 솔루션 설계자는 IIS 웹 서버를 스토리지 솔루션에 연결된 여러 가용 영역의 Amazon EC2 인스턴스로 마이그레이션하고 인스턴스에 연결된 Elastic Load Balancer를 구성할 것을 제안했습니다.\n온프레미스 파일 공유에 대한 어떤 대체가 가장 탄력적이고 내구성이 있습니까?",
      "eng": "A solutions architect must migrate a Windows Internet Information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user's on-premises network-attached storage (NAS). The solutions architect has proposed migrating the IIS web servers to Amazon EC2 instances in multiple Availability Zones that are connected to the storage solution, and configuring an Elastic Load Balancer attached to the instances.\nWhich replacement to the on-premises file share is MOST resilient and durable?"
    },
    "choices": {
      "kor": {
        "A": "파일 공유를 Amazon RDS로 마이그레이션합니다.",
        "B": "파일 공유를 AWS Storage Gateway로 마이그레이션합니다.",
        "C": "파일 공유를 Amazon FSx for Windows File Server로 마이그레이션합니다.",
        "D": "파일 공유를 Amazon Elastic File System(Amazon EFS)으로 마이그레이션합니다."
      },
      "eng": {
        "A": "Migrate the file share to Amazon RDS.",
        "B": "Migrate the file share to AWS Storage Gateway.",
        "C": "Migrate the file share to Amazon FSx for Windows File Server.",
        "D": "Migrate the file share to Amazon Elastic File System (Amazon EFS)."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102186-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 283,
    "question": {
      "kor": "회사는 직원들에게 기밀 및 민감한 파일에 대한 안전한 액세스를 제공해야 합니다. 회사는 권한이 있는 사용자만 파일에 액세스할 수 있기를 원합니다. 파일은 직원의 장치에 안전하게 다운로드되어야 합니다.\n파일은 온프레미스 Windows 파일 서버에 저장됩니다. 그러나 원격 사용량의 증가로 인해 파일 서버의 용량이 부족합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees’ devices.\nThe files are stored in an on-premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity. .\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "파일 서버를 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 인바운드 트래픽을 직원의 IP 주소로 제한하도록 보안 그룹을 구성합니다.",
        "B": "파일을 Amazon FSx for Windows File Server 파일 시스템으로 마이그레이션합니다. Amazon FSx 파일 시스템을 온프레미스 Active Directory와 통합합니다. AWS 클라이언트 VPN을 구성합니다.",
        "C": "파일을 Amazon S3로 마이그레이션하고 프라이빗 VPC 엔드포인트를 생성합니다. 다운로드를 허용하려면 서명된 URL을 만듭니다.",
        "D": "파일을 Amazon S3로 마이그레이션하고 퍼블릭 VPC 엔드포인트를 생성합니다. 직원이 AWS IAM Identity Center(AWS Single Sign-On)로 로그인하도록 허용합니다."
      },
      "eng": {
        "A": "Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees’ IP addresses.",
        "B": "Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.",
        "C": "Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.",
        "D": "Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS IAM Identity Center (AWS Single Sign-On)."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99792-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 353,
    "question": {
      "kor": "게임 회사는 공개 점수판을 데이터 센터에서 AWS 클라우드로 옮기고 있습니다. 이 회사는 Application Load Balancer 뒤에 Amazon EC2 Windows Server 인스턴스를 사용하여 동적 애플리케이션을 호스팅합니다. 회사는 애플리케이션을 위한 고가용성 스토리지 솔루션이 필요합니다. 애플리케이션은 정적 파일과 동적 서버 측 코드로 구성됩니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code.\nWhich combination of steps should a solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3에 정적 파일을 저장합니다. Amazon CloudFront를 사용하여 엣지에서 객체를 캐싱합니다.",
        "B": "정적 파일을 Amazon S3에 저장합니다. Amazon ElastiCache를 사용하여 엣지에서 객체를 캐싱합니다.",
        "C": "Amazon Elastic File System(Amazon EFS)에 서버 측 코드를 저장합니다. 파일을 공유할 각 EC2 인스턴스에 EFS 볼륨을 탑재합니다.",
        "D": "Windows File Server용 Amazon FSx에 서버 측 코드를 저장합니다. 파일을 공유할 각 EC2 인스턴스에 FSx for Windows File Server 볼륨을 탑재합니다.",
        "E": "범용 SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 서버 측 코드를 저장합니다. 각 EC2 인스턴스에 EBS 볼륨을 탑재하여 파일을 공유합니다."
      },
      "eng": {
        "A": "Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.",
        "B": "Store the static files on Amazon S3. Use Amazon ElastiCache to cache objects at the edge.",
        "C": "Store the server-side code on Amazon Elastic File System (Amazon EFS). Mount the EFS volume on each EC2 instance to share the files.",
        "D": "Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files.",
        "E": "Store the server-side code on a General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on each EC2 instance to share the files."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/100230-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 357,
    "question": {
      "kor": "회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 설계하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다.\n어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed.\nWhich AWS solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. 파일 시스템을 애플리케이션 서버에 마운트합니다.",
        "B": "Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다.",
        "C": "Windows 파일 서버 파일 시스템용 Amazon FSx를 생성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다.",
        "D": "Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM 역할을 할당하여 S3 버킷에 대한 액세스 권한을 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다."
      },
      "eng": {
        "A": "Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.",
        "B": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
        "C": "Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.",
        "D": "Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99809-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 39,
    "question": {
      "kor": "회사는 온프레미스에서 실행되는 Windows 파일 서버에 5TB 이상의 파일 데이터를 보유하고 있습니다. 사용자와 애플리케이션은 매일 데이터와 상호 작용합니다.\n이 회사는 Windows 워크로드를 AWS로 이전하고 있습니다. 회사가 이 프로세스를 계속 진행함에 따라 회사는 최소한의 대기 시간으로 AWS 및 온프레미스 파일 스토리지에 액세스해야 합니다. 회사는 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 변경할 필요가 없는 솔루션이 필요합니다. 이 회사는 AWS에 연결하기 위해 AWS Site-to-Site VPN 연결을 사용 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company has more than 5 TB of file data on Windows file servers that run on premises. Users and applications interact with the data each day.\nThe company is moving its Windows workloads to AWS. As the company continues this process, the company requires access to AWS and on-premises file storage with minimum latency. The company needs a solution that minimizes operational overhead and requires no significant changes to the existing file access patterns. The company uses an AWS Site-to-Site VPN connection for connectivity to AWS.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS에서 Windows File Server용 Amazon FSx를 배포하고 구성합니다. 온프레미스 파일 데이터를 FSx for Windows File Server로 이동합니다. AWS에서 Windows File Server용 FSx를 사용하도록 워크로드를 재구성합니다.",
        "B": "온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 S3 파일 게이트웨이로 이동합니다. S3 파일 게이트웨이를 사용하도록 온프레미스 워크로드 및 클라우드 워크로드를 재구성합니다.",
        "C": "온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 Amazon S3로 이동합니다. Amazon S3를 직접 사용하거나 S3 파일 게이트웨이를 사용하도록 워크로드를 재구성합니다. 각 워크로드의 위치에 따라 다릅니다.",
        "D": "AWS에서 Windows 파일 서버용 Amazon FSx를 배포하고 구성합니다. 온프레미스에 Amazon FSx 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 FSx 파일 게이트웨이로 이동합니다. AWS에서 Windows File Server용 FSx를 사용하도록 클라우드 워크로드를 구성합니다. FSx 파일 게이트웨이를 사용하도록 온프레미스 워크로드를 구성 합니다."
      },
      "eng": {
        "A": "Deploy and configure Amazon FSx for Windows File Server on AWS. Move the on-premises file data to FSx for Windows File Server. Reconfigure the workloads to use FSx for Windows File Server on AWS.",
        "B": "Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to the S3 File Gateway. Reconfigure the on-premises workloads and the cloud workloads to use the S3 File Gateway.",
        "C": "Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to Amazon S3. Reconfigure the workloads to use either Amazon S3 directly or the S3 File Gateway. depending on each workload's location.",
        "D": "Deploy and configure Amazon FSx for Windows File Server on AWS. Deploy and configure an Amazon FSx File Gateway on premises. Move the onpremises file data to the FSx File Gateway. Configure the cloud workloads to use FSx for Windows File Server on AWS. Configure the on-premises workloads to use the FSx File Gateway."
      }
    },
    "category": [
      "Storage"
    ],
    "subcategory": [
      "FSx for Windows File Server",
      "hybrid storage",
      "FSx File Gateway"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85173-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 906,
    "question": {
      "kor": "한 금융 서비스 회사는 두 개의 데이터 센터를 폐쇄하고 100TB가 넘는 데이터를 AWS로 마이그레이션하려고 합니다. 데이터는 하위 폴더의 깊은 계층에 저장된 수백만 개의 작은 파일로 구성된 복잡한 디렉터리 구조를 가지고 있습니다. 대부분의 데이터는 비정형이며 회사의 파일 스토리지는 여러 공급업체의 SMB 기반 스토리지 유형으로 구성됩니다. 회사는 마이그레이션 후 데이터에 액세스하기 위해 애플리케이션을 변경하고 싶지 않습니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A financial services company wants to shut down two data centers and migrate more than 100 TB of data to AWS. The data has an intricate directory structure with millions of small files stored in deep hierarchies of subfolders. Most of the data is unstructured, and the company’s file storage consists of SMB-based storage types from multiple vendors. The company does not want to change its applications to access the data after migration.\nWhat should a solutions architect do to meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Direct Connect를 사용하여 데이터를 Amazon S3로 마이그레이션합니다.",
        "B": "AWS DataSync를 사용하여 데이터를 Amazon FSx for Lustre로 마이그레이션합니다.",
        "C": "AWS DataSync를 사용하여 데이터를 Amazon FSx for Windows File Server로 마이그레이션합니다.",
        "D": "AWS Direct Connect를 사용하여 온프레미스 데이터 스토리지를 AWS Storage Gateway 볼륨 게이트웨이로 마이그레이션합니다."
      },
      "eng": {
        "A": "Use AWS Direct Connect to migrate the data to Amazon S3.",
        "B": "Use AWS DataSync to migrate the data to Amazon FSx for Lustre.",
        "C": "Use AWS DataSync to migrate the data to Amazon FSx for Windows File Server.",
        "D": "Use AWS Direct Connect to migrate the data on-premises file storage to an AWS Storage Gateway volume gateway."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132938-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 32,
    "question": {
      "kor": "회사에서 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 데이터 센터는 NFS 기반 파일 시스템에 데이터를 저장하는 SFTP 서버를 호스팅합니다. 서버에는 전송해야 하는 200GB의 데이터가 있습니다. 서버는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용하는 Amazon EC2 인스턴스에서 호스팅되어야 합니다.\n이 작업을 자동화하기 위해 솔루션 설계자가 수행해야 하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company wants to migrate an on-premises data center to AWS. The data center hosts an SFTP server that stores its data on an NFS-based file system.\nThe server holds 200 GB of data that needs to be transferred. The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system.\nWhich combination of steps should a solutions architect take to automate this task? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "EFS 파일 시스템과 동일한 가용 영역에서 EC2 인스턴스를 시작합니다.",
        "B": "온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다.",
        "C": "데이터를 위해 EC2 인스턴스에 보조 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다.",
        "D": "운영 체제 복사 명령을 수동으로 사용하여 데이터를 EC2 인스턴스로 푸시합니다.",
        "E": "AWS DataSync를 사용하여 온프레미스 SFTP 서버에 적합한 위치 구성을 생성합니다."
      },
      "eng": {
        "A": "Launch the EC2 instance into the same Availability Zone as the EFS file system.",
        "B": "Install an AWS DataSync agent in the on-premises data center.",
        "C": "Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data.",
        "D": "Manually use an operating system copy command to push the data to the EC2 instance.",
        "E": "Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85814-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 91,
    "question": {
      "kor": "회사는 단일 공장에 있는 여러 기계에서 매일 10TB의 계측 데이터를 받습니다. 데이터는 공장 내에 위치한 온프레미스 데이터 센터의 SAN(Storage Area Network)에 저장된 JSON 파일로 구성됩니다. 이 회사는 이 데이터를 거의 실시간에 가까운 중요한 분석을 제공하는 여러 추가 시스템에서 액세스할 수 있는 Amazon S3로 보내려고 합니다. 데이터가 민감한 것으로 간주되기 때문에 안전한 전송이 중요합니다.\n가장 안정적인 데이터 전송을 제공하는 솔루션은 무엇입니까?",
      "eng": "A company receives 10 TB of instrumentation data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on-premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near-real-time analytics. A secure transfer is important because the data is considered sensitive.\nWhich solution offers the MOST reliable data transfer?"
    },
    "choices": {
      "kor": {
        "A": "퍼블릭 인터넷을 통한 AWS DataSync",
        "B": "AWS Direct Connect를 통한 AWS DataSync",
        "C": "퍼블릭 인터넷을 통한 AWS DMS(AWS Database Migration Service)",
        "D": "AWS Direct Connect를 통한 AWS DMS(AWS Database Migration Service)"
      },
      "eng": {
        "A": "AWS DataSync over public internet",
        "B": "AWS DataSync over AWS Direct Connect",
        "C": "AWS Database Migration Service (AWS DMS) over public internet",
        "D": "AWS Database Migration Service (AWS DMS) over AWS Direct Connect"
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync",
      "Direct Connect"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 339,
    "question": {
      "kor": "한 회사가 최근 다른 AWS 리전에 재해 복구 사이트를 만들었습니다. 회사는 정기적으로 두 리전의 NFS 파일 시스템 간에 대량의 데이터를 주고 받아야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company recently created a disaster recovery site in a different AWS Region. The company needs to transfer large amounts of data back and forth between NFS file systems in the two Regions on a periodic basis.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용합니다.",
        "B": "AWS Snowball 디바이스를 사용합니다.",
        "C": "Amazon EC2에서 SFTP 서버를 설정합니다.",
        "D": "AWS 데이터베이스 마이그레이션 서비스(AWS DMS)를 사용합니다."
      },
      "eng": {
        "A": "Use AWS DataSync.",
        "B": "Use AWS Snowball devices.",
        "C": "Set up an SFTP server on Amazon EC2.",
        "D": "Use AWS Database Migration Service (AWS DMS)."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99949-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 481,
    "question": {
      "kor": "회사는 회사 데이터 센터의 대규모 NAS(Network-Attached Storage) 시스템에 700테라바이트의 데이터를 저장하고 있습니다. 이 회사는 10Gbps AWS Direct Connect 연결을 사용하는 하이브리드 환경을 보유하고 있습니다.\n규제 기관의 감사 후 회사는 90일 이내에 데이터를 클라우드로 옮길 수 있습니다. 회사는 데이터를 중단 없이 효율적으로 이동해야 합니다. 회사는 여전히 이전 기간 동안 데이터에 액세스하고 데이터를 업데이트할 수 있어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is storing 700 terabytes of data on a large network-attached storage (NAS) system in its corporate data center. The company has a hybrid environment with a 10 Gbps AWS Direct Connect connection.\nAfter an audit from a regulator, the company has 90 days to move the data to the cloud. The company needs to move the data efficiently and without disruption. The company still needs to be able to access and update the data during the transfer window.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사 데이터 센터에서 AWS DataSync 에이전트를 생성합니다. 데이터 전송 작업 생성 Amazon S3 버킷으로의 전송을 시작합니다.",
        "B": "데이터를 AWS Snowball Edge Storage Optimized 디바이스에 백업합니다. 디바이스를 AWS 데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 탑재합니다.",
        "C": "rsync를 사용하여 Direct Connect 연결을 통해 로컬 스토리지에서 지정된 Amazon S3 버킷으로 데이터를 직접 복사합니다.",
        "D": "테이프에 데이터를 백업합니다. 테이프를 AWS 데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 탑재합니다."
      },
      "eng": {
        "A": "Create an AWS DataSync agent in the corporate data center. Create a data transfer task Start the transfer to an Amazon S3 bucket.",
        "B": "Back up the data to AWS Snowball Edge Storage Optimized devices. Ship the devices to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.",
        "C": "Use rsync to copy the data directly from local storage to a designated Amazon S3 bucket over the Direct Connect connection.",
        "D": "Back up the data on tapes. Ship the tapes to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109403-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 489,
    "question": {
      "kor": "회사는 온프레미스 위치에서 Amazon S3 버킷으로 100GB의 기록 데이터를 마이그레이션하려고 합니다. 이 회사는 온프레미스에 100Mbps 인터넷 연결을 갖추고 있습니다. 회사는 S3 버킷으로 전송되는 데이터를 암호화해야 합니다. 회사는 새로운 데이터를 Amazon S3에 직접 저장합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to migrate 100 GB of historical data from an on-premises location to an Amazon S3 bucket. The company has a 100 megabits per second (Mbps) internet connection on premises. The company needs to encrypt the data in transit to the S3 bucket. The company will store new data directly in Amazon S3.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS CLI에서 s3 sync 명령을 사용하여 데이터를 S3 버킷으로 직접 이동합니다.",
        "B": "AWS DataSync를 사용하여 온프레미스 위치에서 S3 버킷으로 데이터 마이그레이션",
        "C": "AWS Snowball을 사용하여 데이터를 S3 버킷으로 이동",
        "D": "온프레미스 위치에서 AWS로 IPsec VPN을 설정합니다. AWS CLI에서 s3 cp 명령을 사용하여 데이터를 S3 버킷으로 직접 이동"
      },
      "eng": {
        "A": "Use the s3 sync command in the AWS CLI to move the data directly to an S3 bucket",
        "B": "Use AWS DataSync to migrate the data from the on-premises location to an S3 bucket",
        "C": "Use AWS Snowball to move the data to an S3 bucket",
        "D": "Set up an IPsec VPN from the on-premises location to AWS. Use the s3 cp command in the AWS CLI to move the data directly to an S3 bucket"
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109490-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 517,
    "question": {
      "kor": "솔루션 아키텍트는 Amazon S3 버킷의 파일을 Amazon Elastic File System(Amazon EFS) 파일 시스템과 다른 S3 버킷으로 복사해야 합니다. 파일은 계속해서 복사되어야 합니다.\n새 파일은 원본 S3 버킷에 지속적으로 추가됩니다. 복사된 파일은 원본 파일이 변경된 경우에만 덮어써야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A solutions architect needs to copy files from an Amazon S3 bucket to an Amazon Elastic File System (Amazon EFS) file system and another S3 bucket. The files must be copied continuously. New files are added to the original S3 bucket consistently. The copied files should be overwritten only if the source file changes.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. 대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 변경된 데이터만 전송하도록 전송 모드를 설정하세요.",
        "B": "AWS Lambda 함수를 생성합니다. 파일 시스템을 함수에 마운트합니다. Amazon S3에서 파일이 생성되고 변경될 때 함수를 호출하도록 S3 이벤트 알림을 설정합니다. 파일 시스템과 대상 S3 버킷에 파일을 복사하는 기능을 구성합니다.",
        "C": "대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. 대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 모든 데이터를 전송하려면 전송 모드를 설정하세요.",
        "D": "파일 시스템과 동일한 VPC에서 Amazon EC2 인스턴스를 시작합니다. 파일 시스템을 마운트합니다. 원본 S3 버킷에서 변경된 모든 객체를 대상 S3 버킷 및 탑재된 파일 시스템에 정기적으로 동기화하는 스크립트를 만듭니다."
      },
      "eng": {
        "A": "Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.",
        "B": "Create an AWS Lambda function. Mount the file system to the function. Set up an S3 event notification to invoke the function when files are created and changed in Amazon S3. Configure the function to copy files to the file system and the destination S3 bucket.",
        "C": "Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer all data.",
        "D": "Launch an Amazon EC2 instance in the same VPC as the file system. Mount the file system. Create a script to routinely synchronize all objects that changed in the origin S3 bucket to the destination S3 bucket and the mounted file system."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/129722-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 551,
    "question": {
      "kor": "회사에는 온프레미스에 여러 Windows 파일 서버가 있습니다. 이 회사는 파일을 Windows File Server 파일 시스템용 Amazon FSx로 마이그레이션하고 통합하려고 합니다. 액세스 권한이 변경되지 않도록 하려면 파일 권한을 보존해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company has multiple Windows file servers on premises. The company wants to migrate and consolidate its files into an Amazon FSx for Windows File Server file system. File permissions must be preserved to ensure that access rights do not change.\nWhich solutions will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "온프레미스에 AWS DataSync 에이전트를 배포합니다. 데이터를 FSx for Windows 파일 서버 파일 시스템으로 전송하도록 DataSync 작업을 예약합니다.",
        "B": "AWS CLI를 사용하여 각 파일 서버의 공유를 Amazon S3 버킷에 복사합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 작업을 예약합니다.",
        "C": "각 파일 서버에서 드라이브를 제거합니다. Amazon S3로 가져오기 위해 드라이브를 AWS로 배송합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 작업을 예약합니다.",
        "D": "AWS Snowcone 디바이스를 주문합니다. 장치를 온프레미스 네트워크에 연결합니다. 디바이스에서 AWS DataSync 에이전트를 시작합니다. 데이터를 FSx for Windows 파일 서버 파일 시스템으로 전송하도록 DataSync 작업을 예약합니다.",
        "E": "AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 장치를 온프레미스 네트워크에 연결합니다. AWS CLI를 사용하여 디바이스에 데이터를 복사합니다. Amazon S3로 가져오기 위해 디바이스를 AWS로 반송합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 작업을 예약합니다."
      },
      "eng": {
        "A": "Deploy AWS DataSync agents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
        "B": "Copy the shares on each file server into Amazon S3 buckets by using the AWS CLI. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
        "C": "Remove the drives from each file server. Ship the drives to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
        "D": "Order an AWS Snowcone device. Connect the device to the on-premises network. Launch AWS DataSync agents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
        "E": "Order an AWS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the AWS CLI. Ship the device back to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync",
      "Snowcone"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109689-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 557,
    "question": {
      "kor": "회사는 데이터를 온프레미스에 저장합니다. 데이터의 양은 회사가 사용할 수 있는 용량을 초과하여 증가하고 있습니다.\n회사는 온프레미스 위치에서 Amazon S3 버킷으로 데이터를 마이그레이션하려고 합니다. 회사에는 전송 후 데이터의 무결성을 자동으로 검증하는 솔루션이 필요합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company stores its data on premises. The amount of data is growing beyond the company's available capacity.\nThe company wants to migrate its data from the on-premises location to an Amazon S3 bucket. The company needs a solution that will automatically validate the integrity of the data after the transfer.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Snowball Edge 디바이스를 주문합니다. S3 버킷으로 온라인 데이터 전송을 수행하도록 Snowball Edge 디바이스를 구성합니다.",
        "B": "AWS DataSync 에이전트를 온프레미스에 배포합니다. S3 버킷으로의 온라인 데이터 전송을 수행하도록 DataSync 에이전트를 구성합니다.",
        "C": "온프레미스에서 Amazon S3 파일 게이트웨이를 생성합니다. S3 파일 게이트웨이를 구성하여 S3 버킷으로 온라인 데이터 전송을 수행합니다.",
        "D": "온프레미스에서 Amazon S3 Transfer Acceleration에 액셀러레이터를 구성합니다. S3 버킷으로의 온라인 데이터 전송을 수행하도록 액셀러레이터를 구성합니다."
      },
      "eng": {
        "A": "Order an AWS Snowball Edge device. Configure the Snowball Edge device to perform the online data transfer to an S3 bucket",
        "B": "Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.",
        "C": "Create an Amazon S3 File Gateway on premises Configure the S3 File Gateway to perform the online data transfer to an S3 bucket",
        "D": "Configure an accelerator in Amazon S3 Transfer Acceleration on premises. Configure the accelerator to perform the online data transfer to an S3 bucket."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125338-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 647,
    "question": {
      "kor": "한 금융 서비스 회사는 두 개의 데이터 센터를 폐쇄하고 100TB가 넘는 데이터를 AWS로 마이그레이션하려고 합니다. 데이터는 하위 폴더의 깊은 계층 구조로 구성된 수백만 개의 작은 파일을 포함하는 복잡한 디렉터리 구조를 가지고 있습니다. 대부분의 데이터는 구조화되지 않았으며 회사의 파일 스토리지에는 다양한 공급업체의 SMB 기반 스토리지 유형이 포함되어 있습니다.\n회사는 마이그레이션 후 데이터에 액세스하기 위해 애플리케이션을 변경하지 않기를 원합니다.\n솔루션 설계자는 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하기 위해 어떤 접근 방식을 취해야 합니까?",
      "eng": "A financial services company intends to shut down two data centers and migrate over 100 TB of data to AWS. The data has a complex directory structure, containing millions of small files organized in deep hierarchies of subfolders. Most of the data is unstructured, and the company's file storage includes SMBbased storage types from various vendors. The company wishes to avoid altering its applications to access the data post-migration.\nWhat approach should a solutions architect take to meet these requirements while minimizing operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS Direct Connect를 활용하여 데이터를 Amazon S3로 마이그레이션합니다.",
        "B": "AWS DataSync를 사용하여 데이터를 Amazon FSx for Lustre로 마이그레이션합니다.",
        "C": "AWS DataSync를 사용하여 Windows 파일 서버용 Amazon FSx로 데이터를 전송합니다.",
        "D": "AWS Direct Connect를 사용하여 온프레미스 파일 스토리지를 AWS Storage Gateway 볼륨 게이트웨이로 마이그레이션합니다."
      },
      "eng": {
        "A": "Utilize AWS Direct Connect to migrate the data to Amazon S3.",
        "B": "Employ AWS DataSync to migrate the data to Amazon FSx for Lustre.",
        "C": "Use AWS DataSync to transfer the data to Amazon FSx for Windows File Server.",
        "D": "Use AWS Direct Connect to migrate the on-premises file storage to an AWS Storage Gateway volume gateway."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 663,
    "question": {
      "kor": "한 회사의 온프레미스 데이터 센터에 소량의 데이터를 Amazon S3에 정기적으로 백업해야 하는 NFS 서버가 있습니다.\n이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?",
      "eng": "A company has NFS servers in an on-premises data center that need to periodically back up small amounts of data to Amazon S3.\nWhich solution meets these requirements and is MOST cost-effective?"
    },
    "choices": {
      "kor": {
        "A": "온프레미스 서버의 데이터를 Amazon S3에 복사하도록 AWS Glue를 설정합니다.",
        "B": "온프레미스 서버에 AWS DataSync 에이전트를 설정하고 데이터를 Amazon S3에 동기화합니다.",
        "C": "AWS Transfer for SFTP를 사용하여 SFTP 동기화를 설정하여 온프레미스에서 Amazon S3로 데이터를 동기화합니다.",
        "D": "온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 데이터를 Amazon S3에 복사합니다."
      },
      "eng": {
        "A": "Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.",
        "B": "Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.",
        "C": "Set up an SFTP sync using AWS Transfer for SFTP to sync data from on premises to Amazon S3.",
        "D": "Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132867-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 787,
    "question": {
      "kor": "대학 연구소는 온프레미스 Windows 파일 서버에서 Amazon FSx for Windows File Server로 30TB의 데이터를 마이그레이션해야 합니다. 실험실에는 대학의 다른 많은 부서에서 공유하는 1Gbps 네트워크 링크가 있습니다.\n실험실은 데이터 전송 성능을 최대화할 데이터 마이그레이션 서비스를 구현하려고 합니다. 그러나 실험실은 서비스가 다른 부서에 미치는 영향을 최소화하기 위해 사용하는 대역폭의 양을 제어할 수 있어야 합니다. 데이터 마이그레이션은 향후 5일 이내에 이루어져야 합니다.\n이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까?",
      "eng": "A university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share.\nThe laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days.\nWhich AWS solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS 스노우콘",
        "B": "Amazon FSx 파일 게이트웨이",
        "C": "AWS 데이터싱크",
        "D": "AWS Transfer Family"
      },
      "eng": {
        "A": "AWS Snowcone",
        "B": "Amazon FSx File Gateway",
        "C": "AWS DataSync",
        "D": "AWS Transfer Family"
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99659-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 847,
    "question": {
      "kor": "회사에서 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 데이터 센터는 NFS 기반 파일 시스템에 데이터를 저장하는 스토리지 서버를 호스팅합니다. 스토리지 서버는 200GB의 데이터를 보유합니다. 회사는 기존 서비스를 중단하지 않고 데이터를 마이그레이션해야 합니다. AWS의 여러 리소스는 NFS 프로토콜을 사용하여 데이터에 액세스할 수 있어야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company wants to migrate an on-premises data center to AWS. The data center hosts a storage server that stores data in an NFS-based file system. The storage server holds 200 GB of data. The company needs to migrate the data without interruption to existing services. Multiple resources in AWS must be able to access the data by using the NFS protocol.\nWhich combination of steps will meet these requirements MOST cost-effectively? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "Lustre 파일 시스템용 Amazon FSx를 생성합니다.",
        "B": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다.",
        "C": "데이터를 수신할 Amazon S3 버킷을 생성합니다.",
        "D": "운영 체제 복사 명령을 수동으로 사용하여 데이터를 AWS 대상으로 푸시합니다.",
        "E": "온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다. 온프레미스 위치와 AWS 간에 DataSync 작업을 사용합니다."
      },
      "eng": {
        "A": "Create an Amazon FSx for Lustre file system.",
        "B": "Create an Amazon Elastic File System (Amazon EFS) file system.",
        "C": "Create an Amazon S3 bucket to receive the data.",
        "D": "Manually use an operating system copy command to push the data into the AWS destination.",
        "E": "Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121176-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 167,
    "question": {
      "kor": "회사에서 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 온프레미스 데이터베이스는 마이그레이션 중에 온라인 상태를 유지하고 액세스할 수 있어야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화된 상태를 유지해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company is migrating its on-premises PostgreSQL database to Amazon Aurora PostgreSQL. The on-premises database must remain online and accessible during the migration. The Aurora database must remain synchronized with the on-premises database.\nWhich combination of actions must a solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "지속적인 복제 작업을 만듭니다.",
        "B": "온프레미스 데이터베이스의 데이터베이스 백업을 생성합니다.",
        "C": "AWS Database Migration Service(AWS DMS) 복제 서버를 생성합니다.",
        "D": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 데이터베이스 스키마를 변환합니다.",
        "E": "Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 데이터베이스 동기화를 모니터링합니다."
      },
      "eng": {
        "A": "Create an ongoing replication task.",
        "B": "Create a database backup of the on-premises database.",
        "C": "Create an AWS Database Migration Service (AWS DMS) replication server.",
        "D": "Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT).",
        "E": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Migration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85438-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 377,
    "question": {
      "kor": "회사에서 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL로 이전하고 있습니다. 데이터베이스에는 동일한 테이블에 쓰는 여러 응용 프로그램이 있습니다. 응용 프로그램은 각 마이그레이션 사이에 한 달씩 하나씩 마이그레이션해야 합니다. 경영진은 데이터베이스에 많은 수의 읽기 및 쓰기가 있다는 우려를 표명했습니다. 데이터는 마이그레이션하는 동안 두 데이터베이스에서 동기화 상태를 유지해야 합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is moving its on-premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables.\nThe applications need to be migrated one by one with a month in between each migration. Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "초기 마이그레이션에는 AWS DataSync를 사용합니다. AWS Database Migration Service(AWS DMS)를 사용하여 변경 데이터 캡처(CDC) 복제 작업 및 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "B": "초기 마이그레이션에 AWS DataSync를 사용합니다. AWS Database Migration Service(AWS DMS)를 사용하여 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "C": "메모리 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 모든 테이블을 선택합니다.",
        "D": "컴퓨팅 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다."
      },
      "eng": {
        "A": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables.",
        "B": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "C": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "D": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Migration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95326-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 422,
    "question": {
      "kor": "회사에는 트랜잭션 데이터를 처리하는 온프레미스 MySQL 데이터베이스가 있습니다. 회사는 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 마이그레이션된 데이터베이스는 데이터베이스를 사용하는 회사의 애플리케이션과 호환성을 유지해야 합니다. 마이그레이션된 데이터베이스는 또한 수요가 증가하는 기간 동안 자동으로 확장되어야 합니다.\n이러한 요구 사항을 충족하는 마이그레이션 솔루션은 무엇입니까?",
      "eng": "A company has an on-premises MySQL database that handles transactional data. The company is migrating the database to the AWS Cloud. The migrated database must maintain compatibility with the company's applications that use the database. The migrated database also must scale automatically during periods of increased demand.\nWhich migration solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "기본 MySQL 도구를 사용하여 데이터베이스를 MySQL용 Amazon RDS로 마이그레이션합니다. 탄력적 스토리지 확장을 구성합니다.",
        "B": "mysqldump 유틸리티를 사용하여 데이터베이스를 Amazon Redshift로 마이그레이션합니다. Amazon Redshift 클러스터에 대해 Auto Scaling을 켭니다.",
        "C": "AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다. Aurora Auto Scaling을 켭니다.",
        "D": "AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. Auto Scaling 정책을 구성합니다."
      },
      "eng": {
        "A": "Use native MySQL tools to migrate the database to Amazon RDS for MySQL. Configure elastic storage scaling.",
        "B": "Migrate the database to Amazon Redshift by using the mysqldump utility. Turn on Auto Scaling for the Amazon Redshift cluster.",
        "C": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon Aurora. Turn on Aurora Auto Scaling.",
        "D": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon DynamoDB. Configure an Auto Scaling policy."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Migration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117025-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 911,
    "question": {
      "kor": "회사는 온프레미스 Oracle 관계형 데이터베이스에 데이터를 저장합니다. 회사는 분석을 위해 Amazon Aurora PostgreSQL에서 데이터를 사용할 수 있도록 해야 합니다. 회사는 AWS Site-to-Site VPN 연결을 사용하여 온프레미스 네트워크를 AWS에 연결합니다.\n회사는 Aurora PostgreSQL로 마이그레이션하는 동안 소스 데이터베이스에 발생하는 변경 사항을 캡처해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company stores data in an on-premises Oracle relational database. The company needs to make the data available in Amazon Aurora PostgreSQL for analysis. The company uses an AWS Site-to-Site VPN connection to connect its on-premises network to AWS.\nThe company must capture the changes that occur to the source database during the migration to Aurora PostgreSQL.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS SCT(AWS Schema Conversion Tool)를 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS) 전체 로드 마이그레이션 작업을 사용하여 데이터를 마이그레이션합니다.",
        "B": "AWS DataSync를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL로 가져옵니다.",
        "C": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service(AWS DMS)를 사용하여 기존 데이터를 마이그레이션하고 지속적인 변경 사항을 복제합니다.",
        "D": "AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora PostgreSQL aws_s3 확장을 사용하여 S3 데이터를 Aurora PostgreSQL로 가져옵니다."
      },
      "eng": {
        "A": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use the AWS Database Migration Service (AWS DMS) full-load migration task to migrate the data.",
        "B": "Use AWS DataSync to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension.",
        "C": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use AWS Database Migration Service (AWS DMS) to migrate the existing data and replicate the ongoing changes.",
        "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Migration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132999-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 718,
    "question": {
      "kor": "회사에서는 Microsoft SQL Server 데이터베이스를 사용합니다. 회사의 애플리케이션은 데이터베이스에 연결됩니다. 회사는 애플리케이션 코드를 최소한으로 변경하면서 Amazon Aurora PostgreSQL 데이터베이스로 마이그레이션하려고 합니다.\n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2개를 선택하세요.)",
      "eng": "A company uses a Microsoft SQL Server database. The company's applications are connected to the database. The company wants to migrate to an Amazon Aurora PostgreSQL database with minimal changes to the application code.\nWhich combination of steps will meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "AWS SCT(AWS Schema Conversion Tool)를 사용하여 애플리케이션에서 SQL 쿼리를 다시 작성합니다.",
        "B": "Aurora PostgreSQL에서 Babelfish를 활성화하여 애플리케이션에서 SQL 쿼리를 실행합니다.",
        "C": "AWS Schema Conversion Tool(AWS SCT) 및 AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스 스키마와 데이터를 마이그레이션합니다.",
        "D": "Amazon RDS Proxy를 사용하여 애플리케이션을 Aurora PostgreSQL에 연결합니다.",
        "E": "AWS Database Migration Service(AWS DMS)를 사용하여 애플리케이션에서 SQL 쿼리를 다시 작성합니다."
      },
      "eng": {
        "A": "Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications.",
        "B": "Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications.",
        "C": "Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS).",
        "D": "Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL.",
        "E": "Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Migration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/139802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 459,
    "question": {
      "kor": "회사는 2주 이내에 온프레미스 데이터 센터에서 AWS로 MySQL 데이터베이스를 마이그레이션해야 합니다. 데이터베이스 크기는 20TB입니다. 회사는 다운타임을 최소화하면서 마이그레이션을 완료하기를 원합니다.\n데이터베이스를 가장 비용 효율적으로 마이그레이션하는 솔루션은 무엇입니까?",
      "eng": "A company needs to migrate a MySQL database from its on-premises data center to AWS within 2 weeks. The database is 20 TB in size. The company wants to complete the migration with minimal downtime.\nWhich solution will migrate the database MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 진행 중인 변경 사항을 복제하여 데이터베이스를 마이그레이션합니다. Snowball Edge 디바이스를 AWS로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다.",
        "B": "AWS Snowmobile 차량을 주문합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 사항이 있는 데이터베이스를 마이그레이션합니다. Snowmobile 차량을 다시 AWS로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다.",
        "C": "GPU 장치로 AWS Snowball Edge Compute Optimized를 주문합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 사항이 있는 데이터베이스를 마이그레이션합니다. Snowball 디바이스를 AWS로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다.",
        "D": "1GB 전용 AWS Direct Connect 연결을 주문하여 데이터 센터와의 연결을 설정합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 AWS Database MigrationService(AWS DMS)를 사용하여 진행 중인 변경 사항을 복제하여 데이터베이스를 마이그레이션합니다."
      },
      "eng": {
        "A": "Order an AWS Snowball Edge Storage Optimized device. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with replication of ongoing changes. Send the Snowball Edge device to AWS to finish the migration and continue the ongoing replication.",
        "B": "Order an AWS Snowmobile vehicle. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with ongoing changes. Send the Snowmobile vehicle back to AWS to finish the migration and continue the ongoing replication.",
        "C": "Order an AWS Snowball Edge Compute Optimized with GPU device. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with ongoing changes. Send the Snowball device to AWS to finish the migration and continue the ongoing replication",
        "D": "Order a 1 GB dedicated AWS Direct Connect connection to establish a connection with the data center. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with replication of ongoing changes."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109377-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 832,
    "question": {
      "kor": "회사는 물리적 테이프에 5PB의 아카이빙된 데이터를 가지고 있습니다. 회사는 규정 준수를 위해 테이프의 데이터를 10년 더 보존해야 합니다. 회사는 향후 6개월 내에 AWS로 마이그레이션하기를 원합니다. 테이프를 저장하는 데이터 센터에는 1Gbps 업링크 인터넷 연결이 있습니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has 5 PB of archived data on physical tapes. The company needs to preserve the data on the tapes for another 10 years for compliance purposes. The company wants to migrate to AWS in the next 6 months. The data center that stores the tapes has a 1 Gbps uplink internet connectivity.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "온프레미스에서 테이프의 데이터를 읽습니다. 로컬 NFS 스토리지에 데이터를 준비합니다. AWS DataSync를 사용하여 데이터를 Amazon S3 Glacier Flexible Retrieval로 마이그레이션합니다.",
        "B": "온프레미스 백업 애플리케이션을 사용하여 테이프에서 데이터를 읽고 Amazon S3 Glacier Deep Archive에 직접 씁니다.",
        "C": "테이프 게이트웨이가 있는 여러 AWS Snowball 디바이스를 주문합니다. Snowball의 가상 테이프에 물리적 테이프를 복사합니다. Snowball 디바이스를 AWS로 배송합니다. 수명 주기 정책을 생성하여 테이프를 Amazon S3 Glacier Deep Archive로 이동합니다.",
        "D": "온프레미스 테이프 게이트웨이를 구성합니다. AWS 클라우드에서 가상 테이프를 생성합니다. 백업 소프트웨어를 사용하여 물리적 테이프를 가상 테이프에 복사합니다."
      },
      "eng": {
        "A": "Read the data from the tapes on premises. Stage the data in a local NFS storage. Use AWS DataSync to migrate the data to Amazon S3 Glacier Flexible Retrieval.",
        "B": "Use an on-premises backup application to read the data from the tapes and to write directly to Amazon S3 Glacier Deep Archive.",
        "C": "Order multiple AWS Snowball devices that have Tape Gateway. Copy the physical tapes to virtual tapes in Snowball. Ship the Snowball devices to AWS. Create a lifecycle policy to move the tapes to Amazon S3 Glacier Deep Archive.",
        "D": "Configure an on-premises Tape Gateway. Create virtual tapes in the AWS Cloud. Use backup software to copy the physical tape to the virtual tape."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball",
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/117215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 875,
    "question": {
      "kor": "한 회사에서 데이터 센터를 이전하고 2주 이내에 50TB의 데이터를 AWS로 안전하게 전송하려고 합니다. 기존 데이터 센터에는 90% 활용되는 AWS에 대한 Site-to-Site VPN 연결이 있습니다.\n솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
      "eng": "A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks. The existing data center has a Site-to-Site VPN connection to AWS that is 90% utilized.\nWhich AWS service should a solutions architect use to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "VPC 엔드포인트가 있는 AWS DataSync",
        "B": "AWS 다이렉트 커넥트",
        "C": "AWS Snowball Edge 스토리지 최적화",
        "D": "AWS 스토리지 게이트웨이"
      },
      "eng": {
        "A": "AWS DataSync with a VPC endpoint",
        "B": "AWS Direct Connect",
        "C": "AWS Snowball Edge Storage Optimized",
        "D": "AWS Storage Gateway"
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/128067-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 6,
    "question": {
      "kor": "회사는 NFS를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장합니다. 각 비디오 파일의 크기는 1MB에서 500GB까지입니다. 총 스토리지는 70TB이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 Amazon S3로 마이그레이션하기로 결정합니다. 회사는 최소한의 네트워크 대역폭을 사용하면서 가능한 한 빨리 비디오 파일을 마이그레이션해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses NFS to store large video files in on-premises network attached storage. Each video file ranges in size from 1 MB to 500 GB. The total storage is 70 TB and is no longer growing. The company decides to migrate the video files to Amazon S3. The company must migrate the video files as soon as possible while using the least possible network bandwidth.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "S3 버킷을 생성합니다. S3 버킷에 쓸 수 있는 권한이 있는 IAM 역할을 생성합니다. AWS CLI를 사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다.",
        "B": "AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 디바이스를 받습니다. Snowball Edge 클라이언트를 사용하여 데이터를 디바이스로 전송합니다. AWS가 데이터를 Amazon S3로 가져올 수 있도록 장치를 반환합니다.",
        "C": "온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 File Gateway에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.",
        "D": "온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 가상 인터페이스(VIF)를 생성합니다. S3 버킷을 생성합니다. S3 File Gateway에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다."
      },
      "eng": {
        "A": "Create an S3 bucket. Create an IAM role that has permissions to write to the S3 bucket. Use the AWS CLI to copy all files locally to the S3 bucket.",
        "B": "Create an AWS Snowball Edge job. Receive a Snowball Edge device on premises. Use the Snowball Edge client to transfer data to the device. Return the device so that AWS can import the data into Amazon S3.",
        "C": "Deploy an S3 File Gateway on premises. Create a public service endpoint to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway.",
        "D": "Set up an AWS Direct Connect connection between the on-premises network and AWS. Deploy an S3 File Gateway on premises. Create a public virtual interface (VIF) to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84875-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 183,
    "question": {
      "kor": "회사는 데이터 센터의 NAS(Network Attached Storage)에 700TB의 백업 데이터를 저장하고 있습니다. 이 백업 데이터는 드문 규제 요청을 위해 액세스할 수 있어야 하며 7년 동안 보관해야 합니다. 회사는 이 백업 데이터를 데이터 센터에서 AWS로 마이그레이션하기로 결정했습니다. 마이그레이션은 1개월 이내에 완료되어야 합니다. 회사는 데이터 전송에 사용할 수 있는 공용 인터넷 연결에 500Mbps의 전용 대역폭을 가지고 있습니다.\n최저 비용으로 데이터를 마이그레이션하고 저장하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A company has 700 TB of backup data stored in network attached storage (NAS) in its data center. This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer.\nWhat should a solutions architect do to migrate and store the data at the LOWEST cost?"
    },
    "choices": {
      "kor": {
        "A": "데이터를 전송할 AWS Snowball 디바이스를 주문합니다. 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive로 전환합니다.",
        "B": "데이터 센터와 Amazon VPC 간에 VPN 연결을 배포합니다. AWS CLI를 사용하여 온프레미스에서 Amazon S3 Glacier로 데이터를 복사합니다.",
        "C": "500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3로 전송합니다. 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive로 전환합니다.",
        "D": "AWS DataSync를 사용하여 데이터를 전송하고 온프레미스에 DataSync 에이전트를 배포합니다. DataSync 작업을 사용하여 온프레미스 NAS 스토리지에서 Amazon S3 Glacier로 파일을 복사합니다."
      },
      "eng": {
        "A": "Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.",
        "B": "Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on premises to Amazon S3 Glacier.",
        "C": "Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.",
        "D": "Use AWS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on-premises NAS storage to Amazon S3 Glacier."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball",
      "S3",
      "lifecycle policies",
      "S3 Glacier Deep Archive"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/94983-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 255,
    "question": {
      "kor": "회사는 30일 이내에 데이터 센터에서 AWS 클라우드로 20TB의 데이터를 마이그레이션해야 합니다. 회사의 네트워크 대역폭은 15Mbps로 제한되며 사용률이 70%를 초과할 수 없습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company’s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Snowball을 사용합니다.",
        "B": "AWS DataSync를 사용합니다.",
        "C": "안전한 VPN 연결을 사용합니다.",
        "D": "Amazon S3 Transfer Acceleration을 사용합니다."
      },
      "eng": {
        "A": "Use AWS Snowball.",
        "B": "Use AWS DataSync.",
        "C": "Use a secure VPN connection.",
        "D": "Use Amazon S3 Transfer Acceleration."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99603-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 268,
    "question": {
      "kor": "회사는 온프레미스 NAS(Network-Attached Storage) 시스템에서 AWS 클라우드로 600TB의 데이터를 전송해야 합니다. 데이터 전송은 2주 이내에 완료되어야 합니다. 데이터는 민감하며 전송 중에 암호화되어야 합니다. 회사의 인터넷 연결은 100Mbps의 업로드 속도를 지원할 수 있습니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company’s internet connection can support an upload speed of 100\nMbps.\nWhich solution meets these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3 멀티파트 업로드 기능을 사용하여 HTTPS를 통해 파일을 전송합니다.",
        "B": "온프레미스 NAS 시스템과 가장 가까운 AWS 리전 간에 VPN 연결을 생성합니다. VPN 연결을 통해 데이터를 전송합니다.",
        "C": "AWS Snow Family 콘솔을 사용하여 여러 AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 디바이스를 사용하여 데이터를 Amazon S3로 전송합니다.",
        "D": "회사 위치와 가장 가까운 AWS 리전 간에 10Gbps AWS Direct Connect 연결을 설정합니다. VPN 연결을 통해 데이터를 리전으로 전송하여 Amazon S3에 데이터를 저장합니다."
      },
      "eng": {
        "A": "Use Amazon S3 multi-part upload functionality to transfer the files over HTTPS.",
        "B": "Create a VPN connection between the on-premises NAS system and the nearest AWS Region. Transfer the data over the VPN connection.",
        "C": "Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.",
        "D": "Set up a 10 Gbps AWS Direct Connect connection between the company location and the nearest AWS Region. Transfer the data over a VPN connection into the Region to store the data in Amazon S3."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102166-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 632,
    "question": {
      "kor": "한 회사에는 다음 달 내에 AWS 클라우드로 이동해야 하는 150TB의 보관된 이미지 데이터가 온프레미스에 저장되어 있습니다. 회사의 현재 네트워크 연결은 야간에만 이 목적으로 최대 100Mbps의 업로드를 허용합니다.\n이 데이터를 이동하고 마이그레이션 기한을 맞추는 가장 비용 효율적인 메커니즘은 무엇입니까?",
      "eng": "A company has 150 TB of archived image data stored on-premises that needs to be moved to the AWS Cloud within the next month. The company’s current network connection allows up to 100 Mbps uploads for this purpose during the night only.\nWhat is the MOST cost-effective mechanism to move this data and meet the migration deadline?"
    },
    "choices": {
      "kor": {
        "A": "AWS Snowmobile을 사용하여 AWS로 데이터를 전송합니다.",
        "B": "여러 AWS Snowball 장치를 주문하여 AWS로 데이터를 전송합니다.",
        "C": "Amazon S3 Transfer Acceleration을 활성화하고 데이터를 안전하게 업로드합니다.",
        "D": "Amazon S3 VPC 엔드포인트를 생성하고 VPN을 설정하여 데이터를 업로드합니다."
      },
      "eng": {
        "A": "Use AWS Snowmobile to ship the data to AWS.",
        "B": "Order multiple AWS Snowball devices to ship the data to AWS.",
        "C": "Enable Amazon S3 Transfer Acceleration and securely upload the data.",
        "D": "Create an Amazon S3 VPC endpoint and establish a VPN to upload the data."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132952-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 773,
    "question": {
      "kor": "회사에서 보고용으로 50TB의 데이터를 사용합니다. 회사는 이 데이터를 온프레미스에서 AWS로 이동하려고 합니다. 회사 데이터 센터의 맞춤형 애플리케이션은 매주 데이터 변환 작업을 실행합니다. 회사는 데이터 전송이 완료될 때까지 애플리케이션을 일시 중지할 계획이며 가능한 한 빨리 전송 프로세스를 시작해야 합니다.\n데이터 센터에는 추가 워크로드에 사용할 수 있는 네트워크 대역폭이 없습니다. 솔루션 설계자는 데이터를 전송하고 변환 작업이 AWS 클라우드에서 계속 실행되도록 구성해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses 50 TB of data for reporting. The company wants to move this data from on premises to AWS. A custom application in the company’s data center runs a weekly data transformation job. The company plans to pause the application until the data transfer is complete and needs to begin the transfer process as soon as possible.\nThe data center does not have any available network bandwidth for additional workloads. A solutions architect must transfer the data and must configure the transformation job to continue to run in the AWS Cloud.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 데이터를 이동합니다. AWS Glue를 사용하여 사용자 지정 변환 작업을 생성합니다.",
        "B": "데이터를 이동할 AWS Snowcone 디바이스를 주문합니다. 장치에 변환 응용 프로그램을 배포합니다.",
        "C": "AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 복사합니다. AWS Glue를 사용하여 사용자 지정 변환 작업을 생성합니다.",
        "D": "Amazon EC2 컴퓨팅을 포함하는 AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 복사합니다. AWS에서 새 EC2 인스턴스를 생성하여 변환",
        "E": "애플리케이션을 실행합니다."
      },
      "eng": {
        "A": "Use AWS DataSync to move the data. Create a custom transformation job by using AWS Glue.",
        "B": "Order an AWS Snowcone device to move the data. Deploy the transformation application to the device.",
        "C": "Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue.",
        "D": "Order an AWS Snowball Edge Storage Optimized device that includes Amazon EC2 compute. Copy the data to the device. Create a new EC2 instance on AWS to run the transformation application."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85912-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 842,
    "question": {
      "kor": "회사는 6주 안에 10PB의 데이터를 Amazon S3로 마이그레이션할 예정입니다. 현재 데이터 센터에는 인터넷에 대한 500Mbps 업링크가 있습니다. 다른 온프레미스 애플리케이션은 업링크를 공유합니다. 회사는 이 일회성 마이그레이션 작업에 인터넷 대역폭의 80%를 사용할 수 있습니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company will migrate 10 PB of data to Amazon S3 in 6 weeks. The current data center has a 500 Mbps uplink to the internet. Other on-premises applications share the uplink. The company can use 80% of the internet bandwidth for this one-time migration task.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "데이터를 Amazon S3로 마이그레이션하고 자동으로 데이터를 확인하도록 AWS DataSync를 구성합니다.",
        "B": "rsync를 사용하여 데이터를 Amazon S3로 직접 전송합니다.",
        "C": "AWS CLI와 여러 복사 프로세스를 사용하여 데이터를 Amazon S3에 직접 보냅니다.",
        "D": "여러 AWS Snowball 디바이스를 주문합니다. 데이터를 장치에 복사합니다. 디바이스를 AWS로 보내 데이터를 Amazon S3에 복사합니다."
      },
      "eng": {
        "A": "Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.",
        "B": "Use rsync to transfer the data directly to Amazon S3.",
        "C": "Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3.",
        "D": "Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/121186-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 914,
    "question": {
      "kor": "한 데이터 분석 회사에는 전 세계적으로 분산된 80개의 사무실이 있습니다. 각 사무실은 1PB의 데이터를 호스팅하고 1~2Gbps의 인터넷 대역폭을 보유합니다.\n회사는 사무실에서 Amazon S3로 대량의 데이터를 일회성 마이그레이션해야 합니다. 회사는 4주 이내에 마이그레이션을 완료해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A data analytics company has 80 offices that are distributed globally. Each office hosts 1 PB of data and has between 1 and 2 Gbps of internet bandwidth.\nThe company needs to perform a one-time migration of a large amount of data from its offices to Amazon S3. The company must complete the migration within 4 weeks.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "각 사무실에 새로운 10Gbps AWS Direct Connect 연결을 설정합니다. 데이터를 Amazon S3로 전송합니다.",
        "B": "여러 AWS Snowball Edge 스토리지 최적화 장치를 사용하여 데이터를 Amazon S3에 저장하고 전송합니다.",
        "C": "AWS Snowmobile을 사용하여 데이터를 Amazon S3에 저장하고 전송합니다.",
        "D": "데이터를 Amazon S3로 전송하도록 AWS Storage Gateway 볼륨 게이트웨이를 설정합니다."
      },
      "eng": {
        "A": "Establish a new 10 Gbps AWS Direct Connect connection to each office. Transfer the data to Amazon S3.",
        "B": "Use multiple AWS Snowball Edge storage-optimized devices to store and transfer the data to Amazon S3.",
        "C": "Use an AWS Snowmobile to store and transfer the data to Amazon S3.",
        "D": "Set up an AWS Storage Gateway Volume Gateway to transfer the data to Amazon S3."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Snowball"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/133010-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 358,
    "question": {
      "kor": "데이터 분석 회사에서 일괄 처리 시스템을 AWS로 마이그레이션하려고 합니다. 회사는 FTP를 통해 낮 동안 주기적으로 수천 개의 작은 데이터 파일을 받습니다. 온프레미스 일괄 작업은 밤새 데이터 파일을 처리합니다. 그러나 일괄 작업 실행을 완료하는 데 몇 시간이 걸립니다.\n회사는 파일을 전송하는 FTP 클라이언트에 대한 최소한의 변경으로 수신 데이터 파일을 처리할 수 있는 AWS 솔루션을 원합니다. 솔루션은 파일이 성공적으로 처리된 수신 데이터 파일을 삭제해야 합니다. 각 파일을 처리하는 데 3~8분이 소요됩니다.\n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A data analytics company wants to migrate its batch processing system to AWS. The company receives thousands of small data files periodically during the day through FTP. A onpremises batch job processes the data files overnight. However, the batch job takes hours to finish running.\nThe company wants the AWS solution to process incoming data files are possible with minimal changes to the FTP clients that send the files. The solution must delete the incoming data files the files have been processed successfully. Processing for each file needs to take 3-8 minutes.\nWhich solution will meet these requirements in the MOST operationally efficient way?"
    },
    "choices": {
      "kor": {
        "A": "FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon S3 Glacier Flexible Retrieval의 객체로 저장합니다. AWS Batch에서 작업 대기열을 구성합니다. Amazon EventBridge 규칙을 사용하여 S3 Glacier Flexible Retrieval에서 야간에 객체를 처리하는 작업을 호출합니다. 작업이 개체를 처리한 후 개체를 삭제합니다.",
        "B": "FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. AWS Batch에서 작업 대기열을 구성 합니다. Amazon EventBridge 규칙을 사용하여 야간에 EBS 볼륨에서 파일 프로세스를 호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다.",
        "C": "AWS Transfer Family를 사용하여 들어오는 파일을 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장할 FTP 서버를 생성합니다. AWS Batch에서 작업 대기열을 구성합니다. 각 파일이 도착하면 Amazon S3 이벤트 알림을 사용하여 AWS Batch에서 작업을 호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다.",
        "D": "AWS Transfer Family를 사용하여 Amazon S3 Standard에 수신 파일을 저장할 FTP 서버를 생성합니다. 파일을 처리하고 파일이 처리된 후 파일을 삭제하는 AWS Lambda 함수를 생성합니다. 파일이 도착하면 S3 이벤트 알림을 사용하여 람다 함수를 호출합니다."
      },
      "eng": {
        "A": "Use an Amazon EC2 instance that runs an FTP server to store incoming files as objects in Amazon S3 Glacier Flexible Retrieval. Configure a job queue in AWS Batch. Use Amazon EventBridge rules to invoke the job to process the objects nightly from S3 Glacier Flexible Retrieval. Delete the objects after the job has processed the objects.",
        "B": "Use an Amazon EC2 instance that runs an FTP server to store incoming files on an Amazon Elastic Block Store (Amazon EBS) volume. Configure a job queue in AWS Batch. Use Amazon EventBridge rules to invoke the process the files nightly from the EBS volume. Delete the files after the job has processed the files.",
        "C": "Use AWS Transfer Family to create an FTP server to store incoming files on an Amazon Elastic Block Store (Amazon EBS) volume. Configure a job queue in AWS Batch. Use an Amazon S3 event notification when each files arrives to invoke the job in AWS Batch. Delete the files after the job has processed the files.",
        "D": "Use AWS Transfer Family to create an FTP server to store incoming files in Amazon S3 Standard. Create an AWS Lambda function to process the files and to delete the files after they are proessed. Use an S3 event notification to invoke the lambda function when the files arrive."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/111317-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 504,
    "question": {
      "kor": "회사에서 고가용성 SFTP 서비스를 실행합니다. SFTP 서비스는 탄력적 IP 주소로 실행되는 두 개의 Amazon EC2 Linux 인스턴스를 사용하여 인터넷에서 신뢰할 수 있는 IP 소스의 트래픽을 허용합니다. SFTP 서비스는 인스턴스에 연결된 공유 스토리지에서 지원합니다. 사용자 계정은 SFTP 서버에서 Linux 사용자로 생성되고 관리됩니다.\n회사는 높은 IOPS 성능과 고도로 구성 가능한 보안을 제공하는 서버리스 옵션을 원합니다. 회사는 또한 사용자 권한에 대한 제어를 유지하기를 원합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs a highly available SFTP service. The SFTP service uses two Amazon EC2 Linux instances that run with elastic IP addresses to accept traffic from trusted IP sources on the internet. The SFTP service is backed by shared storage that is attached to the instances. User accounts are created and managed as Linux users in the SFTP servers.\nThe company wants a serverless option that provides high IOPS performance and highly configurable security. The company also wants to maintain control over user permissions.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. EBS 볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다.",
        "B": "암호화된 Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. 탄력적 IP 주소와 인터넷 연결 액세스가 있는 VPC 엔드포인트를 사용하여 AWS Transfer Family SFTP 서비스를 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 엔드포인트에 보안 그룹을 연결합니다. EFS 볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다.",
        "C": "기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. S3 버킷을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다.",
        "D": "기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 프라이빗 서브넷에서 내부 액세스 권한이 있는 VPC 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 보안 그룹을 연결합니다. S3 버킷을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다."
      },
      "eng": {
        "A": "Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the EBS volume to the SFTP service endpoint. Grant users access to the SFTP service.",
        "B": "Create an encrypted Amazon Elastic File System (Amazon EFS) volume. Create an AWS Transfer Family SFTP service with elastic IP addresses and a VPC endpoint that has internet-facing access. Attach a security group to the endpoint that allows only trusted IP addresses. Attach the EFS volume to the SFTP service endpoint. Grant users access to the SFTP service.",
        "C": "Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service.",
        "D": "Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a VPC endpoint that has internal access in a private subnet. Attach a security group that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109270-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 575,
    "question": {
      "kor": "회사에서 온프레미스 레거시 애플리케이션을 AWS로 마이그레이션하려고 합니다. 애플리케이션은 온프레미스 ERP(전사적 자원 관리) 시스템에서 고객 주문 파일을 수집합니다. 그런 다음 애플리케이션은 파일을 SFTP 서버에 업로드합니다. 애플리케이션은 매시간 주문 파일을 확인하는 예약된 작업을 사용합니다.\n회사에는 이미 온프레미스 네트워크에 연결된 AWS 계정이 있습니다. AWS의 새로운 애플리케이션은 기존 ERP 시스템과의 통합을 지원해야 합니다. 새로운 애플리케이션은 안전하고 탄력적이어야 하며 SFTP 프로토콜을 사용하여 ERP 시스템의 주문을 즉시 처리해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company wants to migrate an on-premises legacy application to AWS. The application ingests customer order files from an on-premises enterprise resource planning (ERP) system. The application then uploads the files to an SFTP server. The application uses a scheduled job that checks for order files every hour.\nThe company already has an AWS account that has connectivity to the on-premises network. The new application on AWS must support integration with the existing ERP system. The new application must be secure and resilient and must use the SFTP protocol to process orders from the ERP system immediately.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "두 개의 가용 영역에 AWS Transfer Family SFTP 인터넷 연결 서버를 생성합니다. Amazon S3 스토리지를 사용하세요. 주문 파일을 처리하는 AWS Lambda 함수를 생성합니다. S3 이벤트 알림을 사용하여 s3:ObjectCreated:* 이벤트를 Lambda 함수로 보냅니다.",
        "B": "하나의 가용 영역에 AWS Transfer Family SFTP 인터넷 연결 서버를 생성합니다. Amazon Elastic File System(Amazon EFS) 스토리지를 사용합니다. 주문 파일을 처리하는 AWS Lambda 함수를 생성합니다. Transfer Family 관리형 워크플로를 사용하여 Lambda 함수를 호출합니다.",
        "C": "두 개의 가용 영역에 AWS Transfer Family SFTP 내부 서버를 생성합니다. Amazon Elastic File System(Amazon EFS) 스토리지를 사용합니다. 주문 파일을 처리하기 위해 AWS Step Functions 상태 머신을 생성합니다. Amazon EventBridge Scheduler를 사용하면 상태 시스템을 호출하여 Amazon EFS에서 주문 파일을 주기적으로 확인할 수 있습니다.",
        "D": "두 개의 가용 영역에 AWS Transfer Family SFTP 내부 서버를 생성합니다. Amazon S3 스토리지를 사용하세요. 주문 파일을 처리하는 AWS Lambda 함수를 생성합니다. Transfer Family 관리형 워크플로를 사용하여 Lambda 함수를 호출합니다."
      },
      "eng": {
        "A": "Create an AWS Transfer Family SFTP internet-facing server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use S3 Event Notifications to send s3:ObjectCreated:* events to the Lambda function.",
        "B": "Create an AWS Transfer Family SFTP internet-facing server in one Availability Zone. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.",
        "C": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Step Functions state machine to process order files. Use Amazon EventBridge Scheduler to invoke the state machine to periodically check Amazon EFS for order files.",
        "D": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/132890-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 670,
    "question": {
      "kor": "회사는 Amazon S3를 데이터 레이크로 사용합니다. 회사에는 SFTP를 사용하여 데이터 파일을 업로드해야 하는 새로운 파트너가 있습니다. 솔루션 설계자는 운영 오버헤드를 최소화하는 고가용성 SFTP 솔루션을 구현해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses Amazon S3 as its data lake. The company has a new partner that must use SFTP to upload data files. A solutions architect needs to implement a highly available SFTP solution that minimizes operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Transfer Family를 사용하여 공개적으로 액세스할 수 있는 SFTP 엔드포인트가 있는 지원 서버를 구성합니다. S3 데이터 레이크를 대상으로 선택합니다.",
        "B": "Amazon S3 파일 게이트웨이를 SFTP 서버로 사용합니다. S3 파일 게이트웨이 엔드포인트 URL을 새 파트너에게 노출합니다. S3 파일 게이트웨이 엔드포인트를 새 파트너와 공유합니다.",
        "C": "VPC의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. VPN을 사용하여 EC2 인스턴스에 파일을 업로드하도록 새 파트너에게 지시합니다. EC2 인스턴스에서 cron 작업 스크립트를 실행하여 S3 데이터 레이크에 파일을 업로드합니다.",
        "D": "VPC의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스 앞에 NLB(Network Load Balancer)를 배치합니다. NLB에 대한 SFTP 수신기 포트를 만듭니다. NLB 호스트 이름을 새 파트너와 공유합니다. EC2 인스턴스에서 cron 작업 스크립트를 실행하여 S3 데이터 레이크에 파일을 업로드합니다."
      },
      "eng": {
        "A": "Use AWS Transfer Family to configure an SFTP-enabled server with a publicly accessible endpoint. Choose the S3 data lake as the destination.",
        "B": "Use Amazon S3 File Gateway as an SFTP server. Expose the S3 File Gateway endpoint URL to the new partner. Share the S3 File Gateway endpoint with the new partner.",
        "C": "Launch an Amazon EC2 instance in a private subnet in a VPC. Instruct the new partner to upload files to the EC2 instance by using a VPN. Run a cron job script, on the EC2 instance to upload files to the S3 data lake.",
        "D": "Launch Amazon EC2 instances in a private subnet in a VPC. Place a Network Load Balancer (NLB) in front of the EC2 instances. Create an SFTP listener port for the NLB. Share the NLB hostname with the new partner. Run a cron job script on the EC2 instances to upload files to the S3 data lake."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87566-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 789,
    "question": {
      "kor": "회사는 고객이 온프레미스 Microsoft Active Directory를 사용하여 Amazon S3에 저장된 파일을 다운로드할 수 있는 기능을 제공하려고 합니다. 고객의 애플리케이션은 SFTP 클라이언트를 사용하여 파일을 다운로드합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하고 고객의 애플리케이션을 변경하지 않는 솔루션은 무엇입니까?",
      "eng": "A company wants to give a customer the ability to use on-premises Microsoft Active Directory to download files that are stored in Amazon S3. The customer’s application uses an SFTP client to download the files.\nWhich solution will meet these requirements with the LEAST operational overhead and no changes to the customer’s application?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3용 SFTP로 AWS Transfer Family를 설정합니다. 통합된 Active Directory 인증을 구성합니다.",
        "B": "온프레미스 클라이언트를 Amazon S3와 동기화하도록 AWS DMS(AWS Database Migration Service)를 설정합니다. 통합된 Active Directory 인증을 구성합니다.",
        "C": "AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 온프레미스 위치와 S3 위치 간에 동기화하도록 AWS DataSync를 설정합니다.",
        "D": "SFTP로 Windows Amazon EC2 인스턴스를 설정하여 온프레미스 클라이언트를 Amazon S3와 연결합니다. AWS Identity and Access Management(IAM)를 통합합니다."
      },
      "eng": {
        "A": "Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.",
        "B": "Set up AWS Database Migration Service (AWS DMS) to synchronize the on-premises client with Amazon S3. Configure integrated Active Directory authentication.",
        "C": "Set up AWS DataSync to synchronize between the on-premises location and the S3 location by using AWS IAM Identity Center (AWS Single Sign-On).",
        "D": "Set up a Windows Amazon EC2 instance with SFTP to connect the on-premises client with Amazon S3. Integrate AWS Identity and Access Management (IAM)."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/99703-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 807,
    "question": {
      "kor": "AWS를 사용하는 회사는 제품 제조업체에 데이터를 전송하는 애플리케이션을 구축하고 있습니다. 회사에는 자체 ID 공급자(IdP)가 있습니다. 회사는 사용자가 애플리케이션을 사용하여 데이터를 전송하는 동안 IdP가 애플리케이션 사용자를 인증하기를 원합니다. 회사는 AS2(Applicability Statement 2) 프로토콜을 사용해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company that uses AWS is building an application to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to authenticate application users while the users use the application to transfer data. The company must use Applicability Statement 2 (AS2) protocol.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 데이터를 전송합니다. IdP 인증을 위한 AWS Lambda 함수를 생성합니다.",
        "B": "Amazon AppFlow 흐름을 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon Elastic Container Service(Amazon ECS) 작업을 생성합니다.",
        "C": "AWS Transfer Family를 사용하여 데이터를 전송합니다. IdP 인증을 위한 AWS Lambda 함수를 생성합니다.",
        "D": "AWS Storage Gateway를 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon Cognito 자격 증명 풀을 생성합니다."
      },
      "eng": {
        "A": "Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication.",
        "B": "Use Amazon AppFlow flows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.",
        "C": "Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.",
        "D": "Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/109524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  },
  {
    "idx": 931,
    "question": {
      "kor": "회사에는 SFTP를 사용하여 여러 공급업체로부터 재무 데이터를 수집하는 온프레미스 애플리케이션이 있습니다. 회사는 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 Amazon S3 API를 사용하여 공급업체로부터 파일을 업로드하는 애플리케이션을 만들었습니다.\n일부 공급업체는 S3 API를 지원하지 않는 레거시 애플리케이션에서 시스템을 실행합니다. 공급업체는 SFTP 기반 애플리케이션을 계속 사용하여 데이터를 업로드하기를 원합니다. 회사는 레거시 애플리케이션을 사용하는 공급업체의 요구에 맞게 관리형 서비스를 사용하려고 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an on-premises application that uses SFTP to collect financial data from multiple vendors. The company is migrating to the AWS Cloud. The company has created an application that uses Amazon S3 APIs to upload files from vendors.\nSome vendors run their systems on legacy applications that do not support S3 APIs. The vendors want to continue to use SFTP-based applications to upload data. The company wants to use managed services for the needs of the vendors that use legacy applications.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS DMS(AWS Database Migration Service) 인스턴스를 생성하여 레거시 애플리케이션을 사용하는 공급업체의 스토리지에서 Amazon S3로 데이터를 복제합니다. AWS DMS 인스턴스에 액세스하기 위한 자격 증명을 공급업체에 제공합니다.",
        "B": "레거시 애플리케이션을 사용하는 공급업체를 위한 AWS Transfer Family 엔드포인트를 생성합니다.",
        "C": "SFTP 서버를 실행하도록 Amazon EC2 인스턴스를 구성합니다. 레거시 애플리케이션을 사용하는 공급업체에 SFTP 서버를 사용하여 데이터를 업로드하도록 지시합니다.",
        "D": "레거시 애플리케이션을 사용하여 SMB 파일 공유에 파일을 업로드하는 공급업체를 위해 Amazon S3 파일 게이트웨이를 구성합니다."
      },
      "eng": {
        "A": "Create an AWS Database Migration Service (AWS DMS) instance to replicate data from the storage of the vendors that use legacy applications to Amazon S3. Provide the vendors with the credentials to access the AWS DMS instance.",
        "B": "Create an AWS Transfer Family endpoint for vendors that use legacy applications.",
        "C": "Configure an Amazon EC2 instance to run an SFTP server. Instruct the vendors that use legacy applications to use the SFTP server to upload data.",
        "D": "Configure an Amazon S3 File Gateway for vendors that use legacy applications to upload files to an SMB file share."
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "Transfer Family"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/135268-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ],
    "correct": 0,
    "incorrect": 0,
    "correct_students": []
  }
]