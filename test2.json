[
  {
    "idx": 51,
    "question": {
      "kor": "회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 관심이 있습니다. 테이블은 대부분의 아침에 사용되지 않습니다. 저녁에는 읽기 및 쓰기 트래픽을 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur, they will happen very quickly.\nWhat should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.",
        "B": "글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.",
        "C": "프로비저닝된 용량과 Auto Scaling으로 DynamoDB 테이블을 생성합니다.",
        "D": "프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 글로벌 테이블로 구성합니다."
      },
      "eng": {
        "A": "Create a DynamoDB table in on-demand capacity mode.",
        "B": "Create a DynamoDB table with a global secondary index.",
        "C": "Create a DynamoDB table with provisioned capacity and auto scaling.",
        "D": "Create a DynamoDB table in provisioned capacity mode, and configure it as a global table."
      }
    },
    "category": [
      "DynamoDB"
    ],
    "subcategory": [
      "mode",
      "scaling"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 52,
    "question": {
      "kor": "회사에는 매일 동시에 실행되는 AWS Glue 추출 변환 및 로드(ETL) 작업이 있습니다. 작업은 Amazon S3 버킷에 있는 XML 데이터를 처리합니다. S3 버킷에는 매일 새 데이터가 추가됩니다. 솔루션 설계자는 각 실행 중에 AWS Glue가 모든 데이터를 처리하고 있음을 확인합니다.\n솔루션 설계자는 AWS Glue가 오래된 데이터를 재처리하지 못하도록 어떻게 해야 합니까?",
      "eng": "A company has an AWS Glue extract, transform, and load (ETL) job that runs every day at the same time. The job processes XML data that is in an Amazon S3 bucket. New data is added to the S3 bucket every day. A solutions architect notices that AWS Glue is processing all the data during each run.\nWhat should the solutions architect do to prevent AWS Glue from reprocessing old data?"
    },
    "choices": {
      "kor": {
        "A": "작업 북마크를 사용하도록 작업을 편집합니다.",
        "B": "작업을 편집하여 데이터 처리 후 데이터를 삭제합니다.",
        "C": "NumberOfWorkers 필드를 1로 설정하여 작업을 편집합니다.",
        "D": "FindMatches 기계 학습(ML) 변환을 사용합니다."
      },
      "eng": {
        "A": "Edit the job to use job bookmarks.",
        "B": "Edit the job to delete data after the data is processed.",
        "C": "Edit the job by setting the NumberOfWorkers field to 1.",
        "D": "Use a FindMatches machine learning (ML) transform."
      }
    },
    "category": [
      "Glue"
    ],
    "subcategory": [
      "bookmakr"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85781-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 53,
    "question": {
      "kor": "소셜 미디어 회사는 사용자가 웹 사이트에 이미지를 업로드할 수 있도록 합니다. 웹 사이트는 Amazon EC2 인스턴스에서 실행됩니다. 업로드 요청 중에 웹 사이트는 이미지 크기를 표준 크기로 조정하고 크기 조정된 이미지를 Amazon S3에 저장합니다. 사용자가 웹 사이트에 대한 느린 업로드 요청을 경험하고 있습니다.\n회사는 애플리케이션 내 결합을 줄이고 웹 사이트 성능을 개선해야 합니다. 솔루션 설계자는 이미지 업로드를 위해 운영상 가장 효율적인 프로세스를 설계해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A social media company allows users to upload images to its website. The website runs on Amazon EC2 instances. During upload requests, the website resizes the images to a standard size and stores the resized images in Amazon S3. Users are experiencing slow upload requests to the website.\nThe company needs to reduce coupling within the application and improve website performance. A solutions architect must design the most operationally efficient process for image uploads.\nWhich combination of actions should the solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "S3 Glacier에 이미지를 업로드하도록 애플리케이션을 구성합니다.",
        "B": "원본 이미지를 Amazon S3에 업로드하도록 웹 서버를 구성합니다.",
        "C": "미리 서명된 URL을 사용하여 각 사용자의 브라우저에서 Amazon S3로 직접 이미지를 업로드하도록 애플리케이션을 구성합니다.",
        "D": "이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 이벤트 알림을 구성합니다. 기능을 사용하여 이미지 크기를 조정하십시오.",
        "E": "업로드된 이미지의 크기를 조정하기 위해 일정에 따라 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다."
      },
      "eng": {
        "A": "Configure the application to upload images to S3 Glacier.",
        "B": "Configure the web server to upload the original images to Amazon S3.",
        "C": "Configure the application to upload images directly from each user's browser to Amazon S3 through the use of a presigned URL",
        "D": "Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image.",
        "E": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function on a schedule to resize uploaded images."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86471-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "D"
    ]
  },
  {
    "idx": 54,
    "question": {
      "kor": "회사에는 공통 Amazon RDS MySQL 다중 AZ DB 인스턴스에 자주 액세스해야 하는 여러 웹 서버가 있습니다. 회사는 사용자 자격 증명을 자주 교체해야 하는 보안 요구 사항을 충족하면서 웹 서버가 데이터베이스에 연결할 수 있는 안전한 방법을 원합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has several web servers that need to frequently access a common Amazon RDS MySQL Multi-AZ DB instance. The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Secrets Manager에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 AWS Secrets Manager에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.",
        "B": "AWS Systems Manager OpsCenter에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 OpsCenter에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.",
        "C": "안전한 Amazon S3 버킷에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 자격 증명을 검색하고 데이터베이스에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.",
        "D": "웹 서버 파일 시스템에서 AWS KMS(AWS Key Management Service)로 암호화된 파일에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 액세스할 수 있어야 합니다."
      },
      "eng": {
        "A": "Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager.",
        "B": "Store the database user credentials in AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter.",
        "C": "Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database.",
        "D": "Store the database user credentials in files encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85753-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 55,
    "question": {
      "kor": "회사에서 AWS에 새로운 퍼블릭 웹 애플리케이션을 배포하고 있습니다. 애플리케이션은 ALB(Application Load Balancer) 뒤에서 실행됩니다. 외부 인증 기관(CA)에서 발급한 SSL/TLS 인증서를 사용하여 에지에서 애플리케이션을 암호화해야 합니다. 인증서는 만료되기 전에 매년 교체해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is deploying a new public web application to AWS. The application will run behind an Application Load Balancer (ALB). The application needs to be encrypted at the edge with an SSL/TLS certificate that is issued by an external certificate authority (CA). The certificate must be rotated each year before the certificate expires.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. ALB에 인증서를 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체하십시오.",
        "B": "AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서에서 키 자료를 가져옵니다. 인증서를 AL에 적용관리형 갱신 기능을 사용하여 인증서를 자동으로 교체하십시오.",
        "C": "AWS Certificate Manager(ACM) 사설 인증 기관을 사용하여 루트 CA에서 SSL/TLS 인증서를 발급합니다. ALB에 인증서를 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체하십시오.",
        "D": "AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 가져옵니다. ALB에 인증서를 적용합니다. 인증서 만료가 가까워지면 Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 알림을 보냅니다. 인증서를 수동으로 교체하십시오."
      },
      "eng": {
        "A": "Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate.",
        "B": "Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Import the key material from the certificate. Apply the certificate to the ALUse the managed renewal feature to automatically rotate the certificate.",
        "C": "Use AWS Certificate Manager (ACM) Private Certificate Authority to issue an SSL/TLS certificate from the root CA. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate.",
        "D": "Use AWS Certificate Manager (ACM) to import an SSL/TLS certificate. Apply the certificate to the ALB. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification when the certificate is nearing expiration. Rotate the certificate manually."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 56,
    "question": {
      "kor": "회사의 HTTP 애플리케이션은 NLB(Network Load Balancer) 뒤에 있습니다. NLB의 대상 그룹은 웹 서비스를 실행하는 여러 EC2 인스턴스와 함께 Amazon EC2 Auto Scaling 그룹을 사용하도록 구성됩니다.\n회사는 NLB가 애플리케이션에 대한 HTTP 오류를 감지하지 못한다는 것을 알게 됩니다. 이러한 오류는 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 다시 시작해야 합니다. 회사는 사용자 지정 스크립트나 코드를 작성하지 않고 애플리케이션의 가용성을 개선해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company's HTTP application is behind a Network Load Balancer (NLB). The NLB's target group is configured to use an Amazon EC2 Auto Scaling group with multiple EC2 instances that run the web service.\nThe company notices that the NLB is not detecting HTTP errors for the application. These errors require a manual restart of the EC2 instances that run the web service. The company needs to improve the application's availability without writing custom scripts or code.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사 애플리케이션의 URL을 제공하여 NLB에서 HTTP 상태 확인을 활성화합니다.",
        "B": "EC2 인스턴스에 cron 작업을 추가하여 1분에 한 번씩 로컬 애플리케이션의 로그를 확인합니다. HTTP 오류가 감지된 경우. 응용 프로그램이 다시 시작됩니다.",
        "C": "NLB를 Application Load Balancer로 교체합니다. 회사 애플리케이션의 URL을 제공하여 HTTP 상태 확인을 활성화합니다. 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다.",
        "D": "NLB에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon Cloud Watch 경보를 생성합니다. 경보가 ALARM 상태일 때 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다."
      },
      "eng": {
        "A": "Enable HTTP health checks on the NLB, supplying the URL of the company's application.",
        "B": "Add a cron job to the EC2 instances to check the local application's logs once each minute. If HTTP errors are detected. the application will restart.",
        "C": "Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company's application. Configure an Auto Scaling action to replace unhealthy instances.",
        "D": "Create an Amazon Cloud Watch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85734-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 57,
    "question": {
      "kor": "회사는 회계 기록을 Amazon S3에 저장해야 합니다. 기록은 1년 동안 즉시 액세스할 수 있어야 하며 추가 9년 동안 보관해야 합니다. 관리 사용자 및 루트 사용자를 포함하여 회사의 그 누구도 전체 10년 기간 동안 레코드를 삭제할 수 없습니다. 기록은 최대한 탄력적으로 저장해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company needs to store its accounting records in Amazon S3. The records must be immediately accessible for 1 year and then must be archived for an additional 9 years. No one at the company, including administrative users and root users, can be able to delete the records during the entire 10-year period.\nThe records must be stored with maximum resiliency.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "전체 10년 동안 S3 Glacier에 레코드를 저장합니다. 액세스 제어 정책을 사용하여 10년 동안 레코드 삭제를 거부합니다.",
        "B": "S3 Intelligent-Tiering을 사용하여 레코드를 저장합니다. IAM 정책을 사용하여 레코드 삭제를 거부합니다. 10년 후 삭제를 허용하도록 IAM 정책을 변경합니다.",
        "C": "S3 수명 주기 정책을 사용하여 1년 후 레코드를 S3 Standard에서 S3 Glacier Deep Archive로 전환합니다. 10년 동안 규정 준수 모드에서 S3 객체 잠금을 사용합니다.",
        "D": "S3 수명 주기 정책을 사용하여 1년 후 레코드를 S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 10년 동안 거버넌스 모드에서 S3 객체 잠금을 사용합니다."
      },
      "eng": {
        "A": "Store the records in S3 Glacier for the entire 10-year period. Use an access control policy to deny deletion of the records for a period of 10 years.",
        "B": "Store the records by using S3 Intelligent-Tiering. Use an IAM policy to deny deletion of the records. After 10 years, change the IAM policy to allow deletion.",
        "C": "Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 Glacier Deep Archive after 1 year. Use S3 Object Lock in compliance mode for a period of 10 years.",
        "D": "Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 year. Use S3 Object Lock in governance mode for a period of 10 years."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85532-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 58,
    "question": {
      "kor": "한 회사가 AWS에서 2계층 웹 애플리케이션을 개발하고 있습니다. 이 회사의 개발자는 백엔드 Amazon RDS 데이터베이스에 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩해서는 안 됩니다. 또한 회사는 정기적으로 데이터베이스 자격 증명을 자동으로 교체하는 솔루션을 구현해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is developing a two-tier web application on AWS. The company's developers have deployed the application on an Amazon EC2 instance that connects directly to a backend Amazon RDS database. The company must not hardcode database credentials in the application. The company must also implement a solution to automatically rotate the database credentials on a regular basis.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "인스턴스 메타데이터에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 인스턴스 메타데이터를 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다.",
        "B": "암호화된 Amazon S3 버킷의 구성 파일에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 구성 파일의 자격 증명을 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다. S3 버전 관리를 사용하여 이전 값으로 폴백할 수 있습니다.",
        "C": "데이터베이스 자격 증명을 AWS Secrets Manager에 비밀로 저장합니다. 보안 비밀에 대해 자동 회전을 켭니다. 암호에 대한 액세스 권한을 부여하려면 EC2 역할에 필요한 권한을 연결합니다.",
        "D": "데이터베이스 자격 증명을 AWS Systems Manager Parameter Store에 암호화된 파라미터로 저장합니다. 암호화된 매개변수에 대해 자동 회전을 켭니다. 암호화된 매개변수에 대한 액세스 권한을 부여하려면 필요한 권한을 EC2 역할에 연결하십시오."
      },
      "eng": {
        "A": "Store the database credentials in the instance metadata. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and instance metadata at the same time.",
        "B": "Store the database credentials in a configuration file in an encrypted Amazon S3 bucket. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and the credentials in the configuration file at the same time. Use S3 Versioning to ensure the ability to fall back to previous values.",
        "C": "Store the database credentials as a secret in AWS Secrets Manager. Turn on automatic rotation for the secret. Attach the required permission to the EC2 role to grant access to the secret.",
        "D": "Store the database credentials as encrypted parameters in AWS Systems Manager Parameter Store. Turn on automatic rotation for the encrypted parameters. Attach the required permission to the EC2 role to grant access to the encrypted parameters."
      }
    },
    "category": [
      "Secrets Manager"
    ],
    "subcategory": [
      "credentials",
      "operational overhead"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85580-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 59,
    "question": {
      "kor": "회사가 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 AWS 리전의 Amazon S3 버킷에 데이터를 저장합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하여 S3 버킷에 저장된 모든 데이터를 암호화해야 합니다. 두 S3 버킷의 데이터는 동일한 KMS 키로 암호화 및 암호 해독되어야 합니다. 데이터와 키는 두 지역 각각에 저장되어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is building an application in the AWS Cloud. The application will store data in Amazon S3 buckets in two AWS Regions. The company must use an AWS Key Management Service (AWS KMS) customer managed key to encrypt all data that is stored in the S3 buckets. The data in both S3 buckets must be encrypted and decrypted with the same KMS key. The data and the key must be stored in each of the two Regions.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "각 리전에서 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.",
        "B": "고객 관리 다중 리전 KMS 키를 생성합니다. 각 리전에서 S3 버킷을 생성합니다. S3 버킷 간의 복제를 구성합니다. 클라이언트 측 암호화와 함께 KMS 키를 사용하도록 애플리케이션을 구성합니다.",
        "C": "각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.",
        "D": "각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다."
      },
      "eng": {
        "A": "Create an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
        "B": "Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption.",
        "C": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
        "D": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84747-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 60,
    "question": {
      "kor": "한 전자상거래 회사가 AWS에서 하루에 하나의 거래 웹사이트를 시작하려고 합니다. 매일 24시간 동안 정확히 하나의 제품이 판매됩니다. 이 회사는 사용량이 많은 시간에 밀리초 대기 시간으로 시간당 수백만 건의 요청을 처리할 수 있기를 원합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "An ecommerce company wants to launch a one-deal-a-day website on AWS. Each day will feature exactly one product on sale for a period of 24 hours. The company wants to be able to handle millions of requests each hour with millisecond latency during peak hours.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3를 사용하여 다른 S3 버킷에서 전체 웹 사이트를 호스팅합니다. Amazon CloudFront 배포를 추가합니다. S3 버킷을 배포의 원본으로 설정합니다. 주문 데이터를 Amazon S3에 저장합니다.",
        "B": "여러 가용 영역의 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스에 전체 웹 사이트를 배포합니다. ALB(Application Load Balancer)를 추가하여 웹 사이트 트래픽을 분산합니다. 백엔드 API에 대해 다른 ALB를 추가하십시오. MySQL용 Amazon RDS에 데이터를 저장합니다.",
        "C": "전체 애플리케이션을 마이그레이션하여 컨테이너에서 실행합니다. Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너를 호스팅합니다. Kubernetes ClusterAutoscaler를 사용하여 팟(Pod) 수를 늘리거나 줄여 트래픽의 버스트를 처리합니다. MySQL용 Amazon RDS에 데이터를 저장합니다.",
        "D": "Amazon S3 버킷을 사용하여 웹 사이트의 정적 콘텐츠를 호스팅합니다. Amazon CloudFront 배포를 배포합니다. S3 버킷을 오리진으로 설정합니다. 백엔드 API에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. Amazon DynamoDB에 데이터를 저장합니다."
      },
      "eng": {
        "A": "Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3.",
        "B": "Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website traffic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL.",
        "C": "Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in traffic. Store the data in Amazon RDS for MySQL.",
        "D": "Use an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85195-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 61,
    "question": {
      "kor": "회사의 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 카탈로그의 가용성이 높고 카탈로그가 안정적인 위치에 저장되기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company's website uses an Amazon EC2 instance store for its catalog of items. The company wants to make sure that the catalog is highly available and that the catalog is stored in a durable location.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Redis용 Amazon ElastiCache로 카탈로그를 이동합니다.",
        "B": "더 큰 인스턴스 저장소가 있는 더 큰 EC2 인스턴스를 배포합니다.",
        "C": "인스턴스 스토어에서 Amazon S3 Glacier Deep Archive로 카탈로그를 이동합니다.",
        "D": "카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다."
      },
      "eng": {
        "A": "Move the catalog to Amazon ElastiCache for Redis.",
        "B": "Deploy a larger EC2 instance with a larger instance store.",
        "C": "Move the catalog from the instance store to Amazon S3 Glacier Deep Archive.",
        "D": "Move the catalog to an Amazon Elastic File System (Amazon EFS) file system."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 62,
    "question": {
      "kor": "회사에는 Amazon S3에 백업되는 대량의 시간에 민감한 데이터를 생성하는 온프레미스 애플리케이션이 있습니다. 애플리케이션이 성장했고 인터넷 대역폭 제한에 대한 사용자 불만이 있습니다. 솔루션 설계자는 Amazon S3에 적시에 백업하고 내부 사용자의 인터넷 연결에 미치는 영향을 최소화할 수 있는 장기 솔루션을 설계해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company has an on-premises application that generates a large amount of time-sensitive data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long-term solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity for internal users.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS VPN 연결을 설정하고 VPC 게이트웨이 엔드포인트를 통해 모든 트래픽을 프록시합니다.",
        "B": "새로운 AWS Direct Connect 연결을 설정하고 이 새로운 연결을 통해 백업 트래픽을 전달합니다.",
        "C": "매일 AWS Snowball 디바이스를 주문합니다. Snowball 디바이스에 데이터를 로드하고 디바이스를 매일 AWS에 반환합니다.",
        "D": "AWS Management Console을 통해 지원 티켓을 제출합니다. 계정에서 S3 서비스 제한 제거를 요청합니다."
      },
      "eng": {
        "A": "Establish AWS VPN connections and proxy all traffic through a VPC gateway endpoint.",
        "B": "Establish a new AWS Direct Connect connection and direct backup traffic through this new connection.",
        "C": "Order daily AWS Snowball devices. Load the data onto the Snowball devices and return the devices to AWS each day.",
        "D": "Submit a support ticket through the AWS Management Console. Request the removal of S3 service limits from the account."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85206-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 63,
    "question": {
      "kor": "회사에서 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 1개월 동안 파일에 자주 액세스합니다. 그러나 1개월이 지나면 파일에 액세스하지 않습니다. 회사는 파일을 무기한으로 보관해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?",
      "eng": "A company is storing backup files by using Amazon S3 Standard storage. The files are accessed frequently for 1 month. However, the files are not accessed after 1 month. The company must keep the files indefinitely.\nWhich storage solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "개체를 자동으로 마이그레이션하도록 S3 Intelligent-Tiering을 구성합니다.",
        "B": "1개월 후에 객체를 S3 Standard에서 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 구성을 생성합니다.",
        "C": "1개월 후 객체를 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하는 S3 수명 주기 구성을 생성합니다.",
        "D": "1개월 후에 객체를 S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 S3 수명 주기 구성을 생성합니다."
      },
      "eng": {
        "A": "Configure S3 Intelligent-Tiering to automatically migrate objects.",
        "B": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Glacier Deep Archive after 1 month.",
        "C": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) after 1 month.",
        "D": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 month."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Storage Class"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85092-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 64,
    "question": {
      "kor": "애플리케이션은 VPC의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 액세스해야 합니다.\nAmazon S3에 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까?",
      "eng": "An application runs on an Amazon EC2 instance in a VPC. The application processes logs that are stored in an Amazon S3 bucket. The EC2 instance needs to access the S3 bucket without connectivity to the internet.\nWhich solution will provide private network connectivity to Amazon S3?"
    },
    "choices": {
      "kor": {
        "A": "S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.",
        "B": "로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.",
        "C": "Amazon EC2에서 인스턴스 프로필을 생성하여 S3 액세스를 허용합니다.",
        "D": "S3 엔드포인트에 액세스하기 위한 프라이빗 링크가 있는 Amazon API Gateway API를 생성합니다."
      },
      "eng": {
        "A": "Create a gateway VPC endpoint to the S3 bucket.",
        "B": "Stream the logs to Amazon CloudWatch Logs. Export the logs to the S3 bucket.",
        "C": "Create an instance profile on Amazon EC2 to allow S3 access.",
        "D": "Create an Amazon API Gateway API with a private link to access the S3 endpoint."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84980-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 65,
    "question": {
      "kor": "회사에는 다음으로 구성된 데이터 수집 워크플로가 있습니다.\n* 새로운 데이터 전달에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 주제\n* 데이터를 처리하고 메타데이터를 기록하는 AWS Lambda 함수\n수집 워크플로가 실패하는 것을 회사에서 관찰합니다. 때때로 네트워크 연결 문제로 인해. 이러한 실패가 발생하면 회사에서 수동으로 작업을 다시 실행하지 않는 한 Lambda 함수는 해당 데이터를 수집하지 않습니다.\nLambda 함수가 미래에 모든 데이터를 수집하도록 하기 위해 솔루션 설계자는 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company has a data ingestion workflow that consists of the following: * An Amazon Simple Notification Service (Amazon SNS) topic for notifications about new data deliveries * An AWS Lambda function to process the data and record metadata\nThe company observes that the ingestion workflow fails occasionally because of network connectivity issues. When such a failure occurs, the Lambda function does not ingest the corresponding data unless the company manually reruns the job.\nWhich combination of actions should a solutions architect take to ensure that the Lambda function ingests all data in the future? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "여러 가용 영역에 Lambda 함수를 배포합니다.",
        "B": "Amazon Simple Queue Service(Amazon SQS) 대기열을 생성하고 SNS 주제를 구독합니다.",
        "C": "Lambda 함수에 할당된 CPU와 메모리를 늘립니다.",
        "D": "Lambda 함수에 대해 프로비저닝된 처리량을 늘립니다.",
        "E": "Amazon Simple Queue Service(Amazon SQS) 대기열에서 읽도록 Lambda 함수를 수정합니다."
      },
      "eng": {
        "A": "Deploy the Lambda function in multiple Availability Zones.",
        "B": "Create an Amazon Simple Queue Service (Amazon SQS) queue, and subscribe it to the SNS topic.",
        "C": "Increase the CPU and memory that are allocated to the Lambda function.",
        "D": "Increase provisioned throughput for the Lambda function.",
        "E": "Modify the Lambda function to read from an Amazon Simple Queue Service (Amazon SQS) queue."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85408-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ]
  },
  {
    "idx": 66,
    "question": {
      "kor": "회사는 AWS 클라우드에서 웹 애플리케이션을 호스팅합니다. 회사는 AWS Certificate Manager(ACM)로 가져온 인증서를 사용하도록 Elastic Load Balancer를 구성합니다. 각 인증서가 만료되기 30일 전에 회사의 보안 팀에 알려야 합니다.\n이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company hosts its web applications in the AWS Cloud. The company configures Elastic Load Balancers to use certificates that are imported into AWS Certificate Manager (ACM). The company's security team must be notified 30 days before the expiration of each certificate.\nWhat should a solutions architect recommend to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "인증서가 만료되기 30일 전부터 매일 Amazon Simple Notification Service(Amazon SNS) 주제에 사용자 지정 메시지를 게시하는 규칙을 ACM에 추가합니다.",
        "B": "30일 이내에 만료되는 인증서를 확인하는 AWS Config 규칙을 생성합니다. AWS Config가 비준수 리소스를 보고할 때 Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 호출하도록 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다.",
        "C": "AWS Trusted Advisor를 사용하여 30일 이내에 만료되는 인증서를 확인합니다. 확인 상태 변경에 대한 Trusted Advisor 지표를 기반으로 하는 Amazon CloudWatch 경보를 생성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 경보를 구성합니다.",
        "D": "30일 이내에 만료되는 모든 인증서를 감지하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. AWS Lambda 함수를 호출하도록 규칙을 구성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 Lambda 함수를 구성합니다."
      },
      "eng": {
        "A": "Add a rule in ACM to publish a custom message to an Amazon Simple Notification Service (Amazon SNS) topic every day, beginning 30 days before any certificate will expire.",
        "B": "Create an AWS Config rule that checks for certificates that will expire within 30 days. Configure Amazon EventBridge (Amazon CloudWatch Events) to invoke a custom alert by way of Amazon Simple Notification Service (Amazon SNS) when AWS Config reports a noncompliant resource.",
        "C": "Use AWS Trusted Advisor to check for certificates that will expire within 30 days. Create an Amazon CloudWatch alarm that is based on Trusted Advisor metrics for check status changes. Configure the alarm to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS).",
        "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect any certificates that will expire within 30 days. Configure the rule to invoke an AWS Lambda function. Configure the Lambda function to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85615-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 67,
    "question": {
      "kor": "한 회사에 AWS에 배포된 3계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC의 퍼블릭 서브넷에 배포됩니다. 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC의 프라이빗 서브넷에 배포됩니다. 이 회사는 검사 VPC의 AWS Marketplace에서 타사 가상 방화벽 어플라이언스를 배포했습니다. 기기는 IP 패킷을 수락할 수 있는 IP 인터페이스로 구성됩니다.\n솔루션 설계자는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 검사하기 위해 웹 애플리케이션을 어플라이언스와 통합해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a three-tier web application that is deployed on AWS. The web servers are deployed in a public subnet in a VPC. The application servers and database servers are deployed in private subnets in the same VPC. The company has deployed a third-party virtual firewall appliance from AWS Marketplace in an inspection VPC. The appliance is configured with an IP interface that can accept IP packets.\nA solutions architect needs to integrate the web application with the appliance to inspect all traffic to the application before the traffic reaches the web server.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "애플리케이션 VPC의 퍼블릭 서브넷에 Network Load Balancer를 생성하여 패킷 검사를 위해 어플라이언스로 트래픽을 라우팅합니다.",
        "B": "애플리케이션 VPC의 퍼블릭 서브넷에 Application Load Balancer를 생성하여 패킷 검사를 위해 트래픽을 어플라이언스로 라우팅합니다.",
        "C": "Transit Gateway를 통해 들어오는 패킷을 라우팅하도록 라우팅 테이블을 구성하는 검사 VPC에 Transit Gateway를 배포합니다.",
        "D": "검사 VPC에 게이트웨이 로드 밸런서를 배포합니다. 수신 패킷을 수신하고 패킷을 어플라이언스로 전달하기 위한 게이트웨이 로드 밸런서 엔드포인트를 생성합니다."
      },
      "eng": {
        "A": "Create a Network Load Balancer in the public subnet of the application's VPC to route the traffic to the appliance for packet inspection.",
        "B": "Create an Application Load Balancer in the public subnet of the application's VPC to route the traffic to the appliance for packet inspection.",
        "C": "Deploy a transit gateway in the inspection VPConfigure route tables to route the incoming packets through the transit gateway.",
        "D": "Deploy a Gateway Load Balancer in the inspection VPC. Create a Gateway Load Balancer endpoint to receive the incoming packets and forward the packets to the appliance."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/94990-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 68,
    "question": {
      "kor": "회사는 민감한 사용자 정보를 Amazon S3 버킷에 저장하고 있습니다. 회사는 VPC 내부의 Amazon EC2 인스턴스에서 실행되는 애플리케이션 계층에서 이 버킷에 대한 보안 액세스를 제공하려고 합니다.\n이를 달성하기 위해 솔루션 설계자가 수행해야 하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A company is storing sensitive user information in an Amazon S3 bucket. The company wants to provide secure access to this bucket from the application tier running on Amazon EC2 instances inside a VPC.\nWhich combination of steps should a solutions architect take to accomplish this? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "VPC 내에서 Amazon S3에 대한 VPC 게이트웨이 엔드포인트를 구성합니다.",
        "B": "버킷 정책을 생성하여 S3 버킷의 객체를 공개합니다.",
        "C": "VPC에서 실행되는 애플리케이션 계층으로만 액세스를 제한하는 버킷 정책을 만듭니다.",
        "D": "S3 액세스 정책으로 IAM 사용자를 생성하고 IAM 자격 증명을 EC2 인스턴스에 복사합니다.",
        "E": "NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 사용하여 S3 버킷에 액세스하도록 합니다."
      },
      "eng": {
        "A": "Configure a VPC gateway endpoint for Amazon S3 within the VPC.",
        "B": "Create a bucket policy to make the objects in the S3 bucket public.",
        "C": "Create a bucket policy that limits access to only the application tier running in the VPC.",
        "D": "Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance.",
        "E": "Create a NAT instance and have the EC2 instances use the NAT instance to access the S3 bucket."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "VPC endpoint",
      "bucket policy"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85903-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "C"
    ]
  },
  {
    "idx": 69,
    "question": {
      "kor": "한 회사가 여러 대륙에 걸쳐 도시의 온도, 습도 및 기압에 대한 데이터를 수집합니다. 회사가 매일 각 사이트에서 수집하는 평균 데이터 양은 500GB입니다. 각 사이트에는 고속 인터넷 연결이 있습니다.\n회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 가능한 한 빨리 집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company collects data for temperature, humidity, and atmospheric pressure in cities across multiple continents. The average volume of data that the company collects from each site daily is 500 GB. Each site has a high-speed Internet connection.\nThe company wants to aggregate the data from all these global sites as quickly as possible in a single Amazon S3 bucket. The solution must minimize operational complexity.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "대상 S3 버킷에서 S3 Transfer Acceleration을 켭니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다.",
        "B": "각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전 복제를 사용하여 객체를 대상 S3 버킷에 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.",
        "C": "AWS Snowball Edge Storage Optimized 장치 작업을 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 객체를 대상 S3 버킷에 복사합니다.",
        "D": "각 사이트에서 가장 가까운 리전의 Amazon EC2 인스턴스로 데이터를 업로드합니다. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS 스냅샷을 생성하여 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다."
      },
      "eng": {
        "A": "Turn on S3 Transfer Acceleration on the destination S3 bucket. Use multipart uploads to directly upload site data to the destination S3 bucket.",
        "B": "Upload the data from each site to an S3 bucket in the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket. Then remove the data from the origin S3 bucket.",
        "C": "Schedule AWS Snowball Edge Storage Optimized device jobs daily to transfer data from each site to the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket.",
        "D": "Upload the data from each site to an Amazon EC2 instance in the closest Region. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. At regular intervals, take an EBS snapshot and copy it to the Region that contains the destination S3 bucket. Restore the EBS volume in that Region."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Transfer Acceleration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 70,
    "question": {
      "kor": "한 회사가 최근 AWS 계정의 Amazon EC2 인스턴스에서 다양한 새 워크로드를 시작했습니다. 회사는 인스턴스를 원격으로 안전하게 액세스하고 관리하기 위한 전략을 수립해야 합니다. 회사는 기본 AWS 서비스와 함께 작동하고 AWS Well-Architected 프레임워크를 따르는 반복 가능한 프로세스를 구현해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company recently launched a variety of new workloads on Amazon EC2 instances in its AWS account. The company needs to create a strategy to access and administer the instances remotely and securely. The company needs to implement a repeatable process that works with native AWS services and follows the AWS Well-Architected Framework.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "관리를 위해 각 인스턴스의 터미널 인터페이스에 직접 액세스하려면 EC2 직렬 콘솔을 사용하십시오.",
        "B": "각각의 기존 인스턴스와 새 인스턴스에 적절한 IAM 역할을 연결합니다. AWS Systems Manager Session Manager를 사용하여 원격 SSH 세션을 설정합니다.",
        "C": "관리 SSH 키 쌍을 만듭니다. 퍼블릭 키를 각 EC2 인스턴스에 로드합니다. 퍼블릭 서브넷에 배스천 호스트를 배포하여 각 인스턴스 관리를 위한 터널을 제공합니다.",
        "D": "AWS Site-to-Site VPN 연결을 설정합니다. 관리자에게 로컬 온프레미스 시스템을 사용하여 VPN 터널에서 SSH 키를 사용하여 인스턴스에 직접 연결하도록 지시합니다."
      },
      "eng": {
        "A": "Use the EC2 serial console to directly access the terminal interface of each instance for administration.",
        "B": "Attach the appropriate IAM role to each existing instance and new instance. Use AWS Systems Manager Session Manager to establish a remote SSH session.",
        "C": "Create an administrative SSH key pair. Load the public key into each EC2 instance. Deploy a bastion host in a public subnet to provide a tunnel for administration of each instance.",
        "D": "Establish an AWS Site-to-Site VPN connection. Instruct administrators to use their local on-premises machines to connect directly to the instances by using SSH keys across the VPN tunnel."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85037-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 71,
    "question": {
      "kor": "한 회사에서 사용자가 사진을 업로드하고 이미지에 사진 프레임을 추가할 수 있는 이미지 분석 애플리케이션을 만들었습니다. 사용자는 이미지에 추가할 사진 프레임을 나타내기 위해 이미지와 메타데이터를 업로드합니다. 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon DynamoDB를 사용하여 메타데이터를 저장합니다. 응용 프로그램이 점점 대중화되고 사용자 수가 증가하고 있습니다. 회사는 시간대와 요일에 따라 동시접속자 수가 크게 달라질 것으로 예상하고 있다. 회사는 애플리케이션이 증가하는 사용자 기반의 요구 사항을 충족하도록 확장할 수 있는지 확인해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has created an image analysis application in which users can upload photos and add photo frames to their images. The users upload images and metadata to indicate which photo frames they want to add to their images. The application uses a single Amazon EC2 instance and Amazon DynamoDB to store the metadata.\nThe application is becoming more popular, and the number of users is increasing. The company expects the number of concurrent users to vary significantly depending on the time of day and day of week. The company must ensure that the application can scale to meet the needs of the growing user base.\nWhich solution meats these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Lambda를 사용하여 사진을 처리하십시오. 사진과 메타데이터를 DynamoDB에 저장합니다.",
        "B": "Amazon Kinesis Data Firehose를 사용하여 사진을 처리하고 사진과 메타데이터를 저장합니다.",
        "C": "AWS Lambda를 사용하여 사진을 처리합니다. 사진을 Amazon S3에 저장합니다. 메타데이터를 저장하기 위해 DynamoDB를 보관합니다.",
        "D": "EC2 인스턴스 수를 3개로 늘립니다. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하여 사진과 메타데이터를 저장합니다."
      },
      "eng": {
        "A": "Use AWS Lambda to process the photos. Store the photos and metadata in DynamoDB.",
        "B": "Use Amazon Kinesis Data Firehose to process the photos and to store the photos and metadata.",
        "C": "Use AWS Lambda to process the photos. Store the photos in Amazon S3. Retain DynamoDB to store the metadata.",
        "D": "Increase the number of EC2 instances to three. Use Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volumes to store the photos and metadata."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85189-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 72,
    "question": {
      "kor": "회사에서 애플리케이션을 설계하고 있습니다. 애플리케이션은 AWS Lambda 함수를 사용하여 Amazon API Gateway를 통해 정보를 수신하고 Amazon Aurora PostgreSQL 데이터베이스에 정보를 저장합니다.\n개념 증명 단계에서 회사는 데이터베이스에 로드해야 하는 대량의 데이터를 처리하기 위해 Lambda 할당량을 크게 늘려야 합니다. 솔루션 설계자는 확장성을 개선하고 구성 노력을 최소화하기 위해 새로운 설계를 권장해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is designing an application. The application uses an AWS Lambda function to receive information through Amazon API Gateway and to store the information in an Amazon Aurora PostgreSQL database.\nDuring the proof-of-concept stage, the company has to increase the Lambda quotas significantly to handle the high volumes of data that the company needs to load into the database. A solutions architect must recommend a new design to improve scalability and minimize the configuration effort.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 리팩터링합니다. 원시 JDBC(Java Database Connectivity) 드라이버를 사용하여 데이터베이스를 연결하십시오.",
        "B": "Aurora에서 DynamoDB Accelerator(DAX) 클러스터를 Amazon DynamoDProvision으로 플랫폼을 변경합니다. DAX 클라이언트 SDK를 사용하여 DAX 클러스터에서 기존 DynamoDB API 호출을 가리킵니다.",
        "C": "두 개의 Lambda 함수를 설정합니다. 정보를 수신하도록 하나의 기능을 구성합니다. 데이터베이스에 정보를 로드하도록 다른 기능을 구성하십시오. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Lambda 함수를 통합합니다.",
        "D": "두 개의 Lambda 함수를 설정합니다. 정보를 수신하도록 하나의 기능을 구성합니다. 데이터베이스에 정보를 로드하도록 다른 기능을 구성하십시오. Amazon Simple Queue Service(Amazon SQS) 대기열을 사용하여 Lambda 함수를 통합합니다."
      },
      "eng": {
        "A": "Refactor the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances. Connect the database by using native Java Database Connectivity (JDBC) drivers.",
        "B": "Change the platform from Aurora to Amazon DynamoDProvision a DynamoDB Accelerator (DAX) cluster. Use the DAX client SDK to point the existing DynamoDB API calls at the DAX cluster.",
        "C": "Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using Amazon Simple Notification Service (Amazon SNS).",
        "D": "Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85197-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 73,
    "question": {
      "kor": "회사에서 애플리케이션을 AWS로 마이그레이션하고 있습니다. 응용 프로그램은 다른 계정에 배포됩니다. 회사는 AWS Organizations를 사용하여 중앙에서 계정을 관리합니다. 회사의 보안 팀은 회사의 모든 계정에 대한 SSO(Single Sign-On) 솔루션이 필요합니다. 회사는 온프레미스 자체 관리 Microsoft Active Directory에서 사용자와 그룹을 계속 관리해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is migrating applications to AWS. The applications are deployed in different accounts. The company manages the accounts centrally by using AWS Organizations. The company's security team needs a single sign-on (SSO) solution across all the company's accounts. The company must continue managing the users and groups in its on-premises self-managed Microsoft Active Directory.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. 단방향 포리스트 트러스트 또는 단방향 도메인 트러스트를 생성하여 Microsoft Active Directory용 AWS Directory Service를 사용하여 회사의 자체 관리형 Microsoft Active Directory를 AWS SSO와 연결합니다.",
        "B": "AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. Microsoft Active Directory용 AWS Directory Service를 사용하여 회사의 자체 관리형 Microsoft Active Directory를 AWS SSO와 연결하는 양방향 포리스트 트러스트를 생성합니다.",
        "C": "AWS 디렉터리 서비스를 사용합니다. 회사의 자체 관리 Microsoft Active Directory와 양방향 신뢰 관계를 만듭니다.",
        "D": "온프레미스에 ID 공급자(IdP)를 배포합니다. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다."
      },
      "eng": {
        "A": "Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a one-way forest trust or a one-way domain trust to connect the company's self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory.",
        "B": "Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a two-way forest trust to connect the company's self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory.",
        "C": "Use AWS Directory Service. Create a two-way trust relationship with the company's self-managed Microsoft Active Directory.",
        "D": "Deploy an identity provider (IdP) on premises. Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85231-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 74,
    "question": {
      "kor": "회사에서 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 수십 기가바이트에서 수백 테라바이트에 이르는 다양한 크기의 출력 파일을 생성합니다. 애플리\n케이션 데이터는 표준 파일 시스템 구조에 저장되어야 합니다. 회사는 자동으로 확장되는 솔루션을 원합니다. 가용성이 높고 최소한의 운영 오버헤드가 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to migrate its on-premises application to AWS. The application produces output files that vary in size from tens of gigabytes to hundreds of terabytes. The application data must be stored in a standard file system structure. The company wants a solution that scales automatically. is highly available, and requires minimum operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic Container Service(Amazon ECS)에서 컨테이너로 실행되도록 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon S3를 사용합니다.",
        "B": "Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너로 실행되도록 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon Elastic Block Store(Amazon EBS)를 사용합니다.",
        "C": "다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 스토리지에 Amazon Elastic File System(Amazon EFS)을 사용합니다.",
        "D": "다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 저장을 위해 Amazon Elastic Block Store(Amazon EBS)를 사용합니다."
      },
      "eng": {
        "A": "Migrate the application to run as containers on Amazon Elastic Container Service (Amazon ECS). Use Amazon S3 for storage.",
        "B": "Migrate the application to run as containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Block Store (Amazon EBS) for storage.",
        "C": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.",
        "D": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic Block Store (Amazon EBS) for storage."
      }
    },
    "category": [
      "EFS"
    ],
    "subcategory": [
      "auto scaling",
      "availability"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 75,
    "question": {
      "kor": "회사는 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 응용 프로그램은 피크 시간 동안 수십만 명의 사용자에게 서비스를 제공합니다. 이 회사는 수백만 건의 금융 거래 세부 정보를 다른 여러 내부 애플리케이션과 공유하기 위해 확장 가능한 실시간에 가까운 솔루션이 필요합니다. 짧은 대기 시간 검색을 위해 문서 데이터베이스에 저장되기 전에 민감한 데이터를 제거하기 위해 트랜잭션을 처리해야 합니다.\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?",
      "eng": "A company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval.\nWhat should a solutions architect recommend to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "트랜잭션 데이터를 Amazon DynamoDB에 저장합니다. 쓰기 시 모든 트랜잭션에서 중요한 데이터를 제거하도록 DynamoDB에서 규칙을 설정합니다. DynamoDB Streams를 사용하여 트랜잭션 데이터를 다른 애플리케이션과 공유합니다.",
        "B": "트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3에 데이터를 저장합니다. Kinesis Data Firehose와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거합니다. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 사용할 수 있습니다.",
        "C": "트랜잭션 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 트랜잭션 데이터를 Amazon DynamoDB에 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림 외부에서 트랜잭션 데이터를 사용할 수 있습니다.",
        "D": "배치 트랜잭션 데이터를 Amazon S3에 파일로 저장합니다. Amazon S3에서 파일을 업데이트하기 전에 AWS Lambda를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거하십시오. 그런 다음 Lambda 함수는 Amazon DynamoDB에 데이터를 저장합니다. 다른 애플리케이션은 Amazon S3에 저장된 트랜잭션 파일을 사용할 수 있습니다."
      },
      "eng": {
        "A": "Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications.",
        "B": "Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.",
        "C": "Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.",
        "D": "Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85201-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 76,
    "question": {
      "kor": "회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 실행합니다. 회사는 애플리케이션의 탄력성과 가용성을 높이기 위해 애플리케이션을 AWS로 마이그레이션하고 있습니다.\n현재 아키텍처는 정상 작동 시간 동안 데이터베이스에서 과도한 읽기 활동을 보여줍니다. 회사의 개발 팀은 4시간마다 프로덕션 데이터베이스의 전체 내보내기를 가져와 스테이징 환경에서 데이터베이스를 채웁니다. 이 기간 동안 사용자는 허용할 수 없는 애플리케이션 대기 시간을 경험합니다. 개발팀은 절차가 완료될 때까지 스테이징 환경을 사용할 수 없습니다.\n솔루션 설계자는 애플리케이션 대기 시간 문제를 완화하는 대체 아키텍처를 권장해야 합니다. 대체 아키텍처는 또한 개발 팀이 스테이징 환경을 지체 없이 계속 사용할 수 있는 기능을 제공해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company runs an on-premises application that is powered by a MySQL database. The company is migrating the application to AWS to increase the application's elasticity and availability.\nThe current architecture shows heavy read activity on the database during times of normal operation. Every 4 hours, the company's development team pulls a full export of the production database to populate a database in the staging environment. During this period, users experience unacceptable application latency. The development team is unable to use the staging environment until the procedure completes.\nA solutions architect must recommend replacement architecture that alleviates the application latency issue. The replacement architecture also must give the development team the ability to continue using the staging environment without delay.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션을 위해 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL을 사용하십시오. mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징 데이터베이스를 채웁니다.",
        "B": "프로덕션을 위해 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL을 사용합니다. 데이터베이스 복제를 사용하여 필요에 따라 스테이징 데이터베이스를 생성합니다.",
        "C": "다중 AZ 배포와 함께 Amazon RDS for MySQL을 사용하고 프로덕션용 읽기 전용 복제본을 사용합니다. 스테이징 데이터베이스에 대기 인스턴스를 사용하십시오.",
        "D": "다중 AZ 배포와 함께 Amazon RDS for MySQL을 사용하고 프로덕션용 읽기 전용 복제본을 사용합니다. mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테",
        "E": "이징 데이터베이스를 채웁니다."
      },
      "eng": {
        "A": "Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility.",
        "B": "Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.",
        "C": "Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Use the standby instance for the staging database.",
        "D": "Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85729-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 77,
    "question": {
      "kor": "회사에서 새로운 서버리스 워크로드 배포를 준비하고 있습니다. 솔루션 설계자는 최소 권한 원칙을 사용하여 AWS Lambda 함수를 실행하는 데 사용할 권한을 구성해야 합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙이 함수를 호출합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is preparing to deploy a new serverless workload. A solutions architect must use the principle of least privilege to configure permissions that will be used to run an AWS Lambda function. An Amazon EventBridge (Amazon CloudWatch Events) rule will invoke the function.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "lambda:InvokeFunction을 액션으로, *를 보안 주체로 사용하여 함수에 실행 역할을 추가합니다.",
        "B": "Lambda:InvokeFunction을 작업으로, Service: lambda.amazonaws.com을 보안 주체로 사용하여 함수에 실행 역할을 추가합니다.",
        "C": "Lambda:*를 작업으로, Service: events.amazonaws.com을 보안 주체로 사용하여 함수에 리소스 기반 정책을 추가합니다.",
        "D": "Lambda:InvokeFunction을 작업으로, Service: events.amazonaws.com을 보안 주체로 사용하여 함수에 리소스 기반 정책을 추가합니다."
      },
      "eng": {
        "A": "Add an execution role to the function with lambda:InvokeFunction as the action and * as the principal.",
        "B": "Add an execution role to the function with lambda:InvokeFunction as the action and Service: lambda.amazonaws.com as the principal.",
        "C": "Add a resource-based policy to the function with lambda:* as the action and Service: events.amazonaws.com as the principal.",
        "D": "Add a resource-based policy to the function with lambda:InvokeFunction as the action and Service: events.amazonaws.com as the principal."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85816-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 78,
    "question": {
      "kor": "한 회사가 AWS 클라우드에서 공개 웹 애플리케이션을 출시할 준비를 하고 있습니다. 아키텍처는 ELB(Elastic Load Balancer) 뒤에 있는 VPC 내의 Amazon EC2 인스턴스로 구성됩니다. 타사 서비스가 DNS에 사용됩니다. 회사의 솔루션 설계자는 대규모 DDoS 공격을 탐지하고 방어하는 솔루션을 추천해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A company is preparing to launch a public-facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third-party service is used for the DNS. The company's solutions architect must recommend a solution to detect and protect against large-scale DDoS attacks.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "계정에서 Amazon GuardDuty를 활성화합니다.",
        "B": "EC2 인스턴스에서 Amazon Inspector를 활성화합니다.",
        "C": "AWS Shield를 활성화하고 여기에 Amazon Route 53을 할당합니다.",
        "D": "AWS Shield Advanced를 활성화하고 여기에 ELB를 할당합니다."
      },
      "eng": {
        "A": "Enable Amazon GuardDuty on the account.",
        "B": "Enable Amazon Inspector on the EC2 instances.",
        "C": "Enable AWS Shield and assign Amazon Route 53 to it.",
        "D": "Enable AWS Shield Advanced and assign the ELB to it."
      }
    },
    "category": [
      "DDoS"
    ],
    "subcategory": [
      "Shield",
      "Shield Advanced"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85203-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 79,
    "question": {
      "kor": "한 회사에서 인기 있는 소셜 미디어 웹사이트를 운영하고 있습니다. 웹사이트는 사용자에게 이미지를 업로드하여 다른 사용자와 공유할 수 있는 기능을 제공합니다. 회사는 이미지에 부적절한 콘텐츠가 포함되어 있지 않은지 확인하려고 합니다. 회사는 개발 노력을 최소화하는 솔루션이 필요합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is running a popular social media website. The website gives users the ability to upload images to share with other users. The company wants to make sure that the images do not contain inappropriate content. The company needs a solution that minimizes development effort.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Comprehend를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에는 사람의 검토를 사용하세요.",
        "B": "Amazon Rekognition을 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에는 사람의 검토를 사용하세요.",
        "C": "Amazon SageMaker를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에 라벨을 지정하려면 Ground Truth를 사용하세요.",
        "D": "AWS Fargate를 사용하여 사용자 지정 기계 학습 모델을 배포하여 부적절한 콘텐츠를 탐지합니다. 신뢰도가 낮은 예측에 라벨을 지정하려면 Ground Truth를 사용하세요."
      },
      "eng": {
        "A": "Use Amazon Comprehend to detect inappropriate content. Use human review for low-confidence predictions.",
        "B": "Use Amazon Rekognition to detect inappropriate content. Use human review for low-confidence predictions.",
        "C": "Use Amazon SageMaker to detect inappropriate content. Use ground truth to label low-confidence predictions.",
        "D": "Use AWS Fargate to deploy a custom machine learning model to detect inappropriate content. Use ground truth to label low-confidence predictions."
      }
    },
    "category": [
      "AI"
    ],
    "subcategory": [
      "Rekognition",
      "detect inappropriate content"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85452-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 80,
    "question": {
      "kor": "회사는 여러 Amazon EC 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션은 Amazon SQS  대기열의 메시지를 처리하고 Amazon RDS 테이블에 쓰고 대기열에서 메시지를 삭제합니다. 때때로 중복 레코드가 RDS 테이블에서 발견됩니다. SQS 대기열에는 중복 메시지가 없습니다.\n솔루션 설계자는 메시지가 한 번만 처리되도록 하려면 어떻게 해야 합니까?",
      "eng": "A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue, writes to an Amazon RDS table, and deletes the message from the queue. Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages.\nWhat should a solutions architect do to ensure messages are being processed once only?"
    },
    "choices": {
      "kor": {
        "A": "CreateQueue API 호출을 사용하여 새 대기열을 만듭니다.",
        "B": "AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.",
        "C": "ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.",
        "D": "ChangeMessageVisibility API 호출을 사용하여 가시성 제한 시간을 늘립니다."
      },
      "eng": {
        "A": "Use the CreateQueue API call to create a new queue.",
        "B": "Use the AddPermission API call to add appropriate permissions.",
        "C": "Use the ReceiveMessage API call to set an appropriate wait time.",
        "D": "Use the ChangeMessageVisibility API call to increase the visibility timeout."
      }
    },
    "category": [
      "SQS"
    ],
    "subcategory": [
      "Visibility timeout"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85583-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 81,
    "question": {
      "kor": "이미지 처리 회사에는 사용자가 이미지를 업로드하는 데 사용하는 웹 애플리케이션이 있습니다. 애플리케이션은 이미지를 Amazon S3 버킷에 업로드합니다. 회사는 객체 생성 이벤트를 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 게시하도록 S3 이벤트 알림을 설정했습니다. SQS 대기열은 이미지를 처리하고 이메일을 통해 사용자에게 결과를 보내는 AWS Lambda 함수의 이벤트 소스 역할을 합니다.\n사용자는 업로드된 모든 이미지에 대해 여러 개의 이메일 메시지를 받고 있다고 보고합니다. 솔루션 아키텍트는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 메시지가 생성되었음을 확인합니다.\n최소한의 운영 오버헤드로 이 문제를 해결하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "An image-processing company has a web application that users use to upload images. The application uploads the images into an Amazon S3 bucket. The company has set up S3 event notifications to publish the object creation events to an Amazon Simple Queue Service (Amazon SQS) standard queue. The SQS queue serves as the event source for an AWS Lambda function that processes the images and sends the results to users through email.\nUsers report that they are receiving multiple email messages for every uploaded image. A solutions architect determines that SQS messages are invoking the Lambda function more than once, resulting in multiple email messages.\nWhat should the solutions architect do to resolve this issue with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "ReceiveMessage 대기 시간을 30초로 늘려 SQS 대기열에서 긴 폴링을 설정합니다.",
        "B": "SQS 표준 대기열을 SQS FIFO 대기열로 변경합니다. 중복 메시지를 삭제하려면 메시지 중복 제거 ID를 사용하십시오.",
        "C": "SQS 대기열의 가시성 제한 시간을 기능 제한 시간과 배치 창 제한 시간의 합계보다 큰 값으로 늘립니다.",
        "D": "처리하기 전에 메시지를 읽은 직후 SQS 대기열에서 각 메시지를 삭제하도록 Lambda 함수를 수정합니다."
      },
      "eng": {
        "A": "Set up long polling in the SQS queue by increasing the ReceiveMessage wait time to 30 seconds.",
        "B": "Change the SQS standard queue to an SQS FIFO queue. Use the message deduplication ID to discard duplicate messages.",
        "C": "Increase the visibility timeout in the SQS queue to a value that is greater than the total of the function timeout and the batch window timeout.",
        "D": "Modify the Lambda function to delete each message from the SQS queue immediately after the message is read before processing."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85185-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 82,
    "question": {
      "kor": "회사에서 대량의 생산 데이터를 동일한 AWS 리전의 테스트 환경으로 복제하는 기능을 개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon EC2 인스턴스에 저장됩니다. 복제된 데이터에 대한 수정은 생산 환경에 영향을 미치지 않아야 합니다. 이 데이터에 액세스하는 소프트웨어에는 지속적으로 높은 I/O 성능이 필요합니다.\n솔루션 설계자는 프로덕션 데이터를 테스트 환경으로 복제하는 데 필요한 시간을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to improve its ability to clone large amounts of production data into a test environment in the same AWS Region. The data is stored in Amazon EC2 instances on Amazon Elastic Block Store (Amazon EBS) volumes. Modifications to the cloned data must not affect the production environment.\nThe software that accesses this data requires consistently high I/O performance.\nA solutions architect needs to minimize the time that is required to clone the production data into the test environment.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 테스트 환경의 EC2 인스턴스 스토어 볼륨에 스냅샷을 복원합니다.",
        "B": "EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS 볼륨의 EBS 스냅샷을 생성합니다. 프로덕션 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "C": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 새 EBS 볼륨을 생성하고 초기화합니다. 프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 새 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
        "D": "프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 기능을 켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경에서 새 EBS 볼륨을 EC2 인스턴스에 연결합니다."
      },
      "eng": {
        "A": "Take EBS snapshots of the production EBS volumes. Restore the snapshots onto EC2 instance store volumes in the test environment.",
        "B": "Configure the production EBS volumes to use the EBS Multi-Attach feature. Take EBS snapshots of the production EBS volumes. Attach the production EBS volumes to the EC2 instances in the test environment.",
        "C": "Take EBS snapshots of the production EBS volumes. Create and initialize new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment before restoring the volumes from the production EBS snapshots.",
        "D": "Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 83,
    "question": {
      "kor": "회사에서 분산 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 다양한 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성됩니다. 회사는 복원력과 확장성을 최대화하는 솔루션으로 애플리케이션을 현대화하려고 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까?",
      "eng": "A company is migrating a distributed application to AWS. The application serves variable workloads. The legacy platform consists of a primary server that coordinates jobs across multiple compute nodes. The company wants to modernize the application with a solution that maximizes resiliency and scalability.\nHow should a solutions architect design the architecture to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 조정을 사용하도록 EC2 Auto Scaling을 구성합니다.",
        "B": "작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열 크기에 따라 EC2 Auto Scaling을 구성합니다.",
        "C": "Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버 및 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail을 구성합니다. 기본 서버의 로드를 기반으로 EC2 Auto Scaling을 구성합니다.",
        "D": "Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버 및 컴퓨팅 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 컴퓨팅 노드의 로드를 기반으로 EC2 Auto Scaling을 구성합니다."
      },
      "eng": {
        "A": "Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling to use scheduled scaling.",
        "B": "Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling based on the size of the queue.",
        "C": "Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure AWS CloudTrail as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the primary server.",
        "D": "Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure Amazon EventBridge (Amazon CloudWatch Events) as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the compute nodes."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84679-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 84,
    "question": {
      "kor": "AWS에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하려고 합니다. Amazon RDS DB 인스턴스. Amazon Redshift 클러스터는 태그로 구성됩니다.\n회사는 이 검사를 구성하고 운영하는 노력을 최소화하기를 원합니다.\n이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까?",
      "eng": "A company that hosts its web application on AWS wants to ensure all Amazon EC2 instances. Amazon RDS DB instances. and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check.\nWhat should a solutions architect do to accomplish this?"
    },
    "choices": {
      "kor": {
        "A": "AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 감지합니다.",
        "B": "Cost Explorer를 사용하여 태그가 제대로 지정되지 않은 리소스를 표시합니다. 해당 리소스에 수동으로 태그를 지정합니다.",
        "C": "적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다.",
        "D": "적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. 코드를 주기적으로 실행하도록 Amazon CloudWatch를 통해 AWS Lambda 함수를 예약합니다."
      },
      "eng": {
        "A": "Use AWS Config rules to define and detect resources that are not properly tagged.",
        "B": "Use Cost Explorer to display resources that are not properly tagged. Tag those resources manually.",
        "C": "Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.",
        "D": "Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85198-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 85,
    "question": {
      "kor": "회사에서 기존 3계층 웹 아키텍처의 비용을 줄이고자 합니다. 웹, 애플리케이션 및 데이터베이스 서버는 개발, 테스트 및 프로덕션 환경을 위해 Amazon EC2 인스턴스에서 실행됩니다.\nEC2 인스턴스는 사용량이 많은 시간에 평균 30%의 CPU 사용률을 보이고 사용량이 적은 시간에는 10%의 CPU 사용률을 보입니다.\n프로덕션 EC2 인스턴스는 하루 24시간 실행됩니다. 개발 및 테스트 EC2 인스턴스는 매일 최소 8시간 동안 실행됩니다. 이 회사는 개발을 중지하고 사용하지 않는 EC2 인스턴스를 테스트하기 위해 자동화를 구현할 계획입니다.\n어떤 EC2 인스턴스 구매 솔루션이 회사의 요구 사항을 가장 비용 효율적으로 충족합니까?",
      "eng": "A company wants to reduce the cost of its existing three-tier web architecture. The web, application, and database servers are running on Amazon EC2 instances for the development, test, and production environments. The EC2 instances average 30% CPU utilization during peak hours and 10% CPU utilization during non-peak hours.\nThe production EC2 instances run 24 hours a day. The development and test EC2 instances run for at least 8 hours each day. The company plans to implement automation to stop the development and test EC2 instances when they are not in use.\nWhich EC2 instance purchasing solution will meet the company's requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 EC2 인스턴스에는 스팟 인스턴스를 사용하십시오. 개발 및 테스트 EC2 인스턴스에 예약 인스턴스를 사용합니다.",
        "B": "프로덕션 EC2 인스턴스에 예약 인스턴스를 사용합니다. 개발 및 테스트 EC2 인스턴스에 온디맨드 인스턴스를 사용합니다.",
        "C": "프로덕션 EC2 인스턴스에 스팟 블록을 사용합니다. 개발 및 테스트 EC2 인스턴스에 예약 인스턴스를 사용합니다.",
        "D": "프로덕션 EC2 인스턴스에 온디맨드 인스턴스를 사용합니다. 개발 및 테스트 EC2 인스턴스에 스팟 블록을 사용합니다."
      },
      "eng": {
        "A": "Use Spot Instances for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances.",
        "B": "Use Reserved Instances for the production EC2 instances. Use On-Demand Instances for the development and test EC2 instances.",
        "C": "Use Spot blocks for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances.",
        "D": "Use On-Demand Instances for the production EC2 instances. Use Spot blocks for the development and test EC2 instances."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85665-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 86,
    "question": {
      "kor": "회사에는 Amazon RDS의 데이터베이스에 목록을 저장하는 자동차 판매 웹 사이트가 있습니다. 자동차가 판매되면 웹사이트에서 목록을 제거하고 데이터를 여러 대상 시스템으로 전송해야 합니다.\n솔루션 설계자는 어떤 디자인을 추천해야 합니까?",
      "eng": "A company has an automobile sales website that stores its listings in a database on Amazon RDS. When an automobile is sold, the listing needs to be removed from the website and the data must be sent to multiple target systems.\nWhich design should a solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "대상이 소비할 Amazon Simple Queue Service(Amazon SQS) 대기열로 정보를 전송하도록 Amazon RDS의 데이터베이스가 업데이트될 때 트리거되는 AWS Lambda 함수를 생성합니다.",
        "B": "대상이 사용할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 정보를 전송하도록 Amazon RDS의 데이터베이스가 업데이트될 때 트리거되는 AWS Lambda 함수를 생성합니다.",
        "C": "RDS 이벤트 알림을 구독하고 여러 Amazon Simple Notification Service(Amazon SNS) 주제로 팬 아웃된 Amazon Simple Queue Service(Amazon SQS) 대기열을 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다.",
        "D": "RDS 이벤트 알림을 구독하고 여러 Amazon Simple Queue Service(Amazon SQS) 대기열로 팬 아웃된 Amazon Simple Notification Service(Amazon SNS) 주제를 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다."
      },
      "eng": {
        "A": "Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.",
        "B": "Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.",
        "C": "Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.",
        "D": "Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85427-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 87,
    "question": {
      "kor": "회사에서 기밀 데이터를 Amazon S3에 저장할 준비를 하고 있습니다. 규정 준수를 위해 데이터는 유휴 상태에서 암호화되어야 합니다. 감사 목적으로 암호화 키 사용을 기록해야 합니다. 키는 매년 교체해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까?",
      "eng": "A company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest. Encryption key usage must be logged for auditing purposes. Keys must be rotated every year.\nWhich solution meets these requirements and is the MOST operationally efficient?"
    },
    "choices": {
      "kor": {
        "A": "고객 제공 키를 사용한 서버 측 암호화(SSE-C)",
        "B": "Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화",
        "C": "수동 교체가 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화",
        "D": "자동 교체가 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화"
      },
      "eng": {
        "A": "Server-side encryption with customer-provided keys (SSE-C)",
        "B": "Server-side encryption with Amazon S3 managed keys (SSE-S3)",
        "C": "Server-side encryption with AWS KMS keys (SSE-KMS) with manual rotation",
        "D": "Server-side encryption with AWS KMS keys (SSE-KMS) with automatic rotation"
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85817-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 88,
    "question": {
      "kor": "글로벌 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. 회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 회사는 정적 데이터 및 동적 데이터의 성능을 개선하고 대기 시간을 줄이려고 합니다. 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A global company hosts its web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The web application has static data and dynamic data. The company stores its static data in an Amazon S3 bucket. The company wants to improve performance and reduce latency for the static data and dynamic data. The company is using its own domain name registered with Amazon Route 53.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "S3 버킷과 ALB를 원본으로 하는 Amazon CloudFront 배포를 생성합니다. 트래픽을 CloudFront 배포로 라우팅하도록 Route 53을 구성합니다.",
        "B": "ALB를 오리진으로 하는 Amazon CloudFront 배포를 생성합니다. 엔드포인트로 S3 버킷이 있는 AWS Global Accelerator 표준 가속기를 생성합니다. 트래픽을 CloudFront 배포로 라우팅하도록 Route 53을 구성합니다.",
        "C": "S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 생성합니다. ALB 및 CloudFront 배포를 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 지정 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.",
        "D": "ALB를 오리진으로 하는 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 두 개의 도메인 이름을 만듭니다. 동적 콘텐츠에 대한 하나의 도메인 이름이 CloudFront DNS 이름을 가리킵니다. 다른 도메인 이름은 정적 콘텐츠에 대한 액셀러레이터 DNS 이름을 가리킵니다. 도메인 이름을 웹 애플리케이션의 끝점으로 사용합니다."
      },
      "eng": {
        "A": "Create an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins. Configure Route 53 to route traffic to the CloudFront distribution.",
        "B": "Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint Configure Route 53 to route traffic to the CloudFront distribution.",
        "C": "Create an Amazon CloudFront distribution that has the S3 bucket as an origin. Create an AWS Global Accelerator standard accelerator that has the ALB and the CloudFront distribution as endpoints. Create a custom domain name that points to the accelerator DNS name. Use the custom domain name as an endpoint for the web application.",
        "D": "Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint. Create two domain names. Point one domain name to the CloudFront DNS name for dynamic content. Point the other domain name to the accelerator DNS name for static content. Use the domain names as endpoints for the web application."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85010-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 89,
    "question": {
      "kor": "회사에는 각각 크기가 약 5MB인 많은 수의 파일을 생성하는 응용 프로그램이 있습니다. 파일은 Amazon S3에 저장됩니다. 회사 정책에 따라 파일은 삭제되기 전에 4년 동안 저장되어야 합니다. 파일에는 재현하기 어려운 중요한 비즈니스 데이터가 포함되어 있으므로 즉각적인 액세스 가능성이 항상 필요합니다. 파일은 개체 생성 후 처음 30일 동안 자주 액세스되지만 처음 30일 이후에는 거의 액세스되지 않습니다.\n가장 비용 효율적인 스토리지 솔루션은 무엇입니까?",
      "eng": "A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.\nWhich storage solution is MOST cost-effective?"
    },
    "choices": {
      "kor": {
        "A": "객체 생성 30일 후에 S3 Standard에서 S3 Glacier로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제하십시오.",
        "B": "S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 객체 생성 30일 후에 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제하십시오.",
        "C": "객체 생성 30일 후에 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제하십시오.",
        "D": "객체 생성 30일 후에 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 4년 후 파일을 S3 Glacier로 이동합니다."
      },
      "eng": {
        "A": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation.",
        "B": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation.",
        "C": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.",
        "D": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Storage Class",
      "lifecycle policies"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85310-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 90,
    "question": {
      "kor": "개발 팀은 다른 팀에서 액세스할 웹 사이트를 호스팅해야 합니다. 웹 사이트 콘텐츠는 HTML, CSS, 클라이언트 측 JavaScript 및 이미지로 구성됩니다.\n웹 사이트 호스팅에 가장 비용 효율적인 방법은 무엇입니까?",
      "eng": "A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images.\nWhich method is the MOST cost-effective for hosting the website?"
    },
    "choices": {
      "kor": {
        "A": "웹 사이트를 컨테이너화하고 AWS Fargate에서 호스팅합니다.",
        "B": "Amazon S3 버킷을 생성하고 그곳에서 웹사이트를 호스팅합니다.",
        "C": "Amazon EC2 인스턴스에 웹 서버를 배포하여 웹사이트를 호스팅합니다.",
        "D": "Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer를 구성합니다."
      },
      "eng": {
        "A": "Containerize the website and host it in AWS Fargate.",
        "B": "Create an Amazon S3 bucket and host the website there.",
        "C": "Deploy a web server on an Amazon EC2 instance to host the website.",
        "D": "Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85199-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 91,
    "question": {
      "kor": "회사는 단일 공장에 있는 여러 기계에서 매일 10TB의 계측 데이터를 받습니다. 데이터는 공장 내에 위치한 온프레미스 데이터 센터의 SAN(Storage Area Network)에 저장된 JSON 파일로 구성됩니다. 이 회사는 이 데이터를 거의 실시간에 가까운 중요한 분석을 제공하는 여러 추가 시스템에서 액세스할 수 있는 Amazon S3로 보내려고 합니다. 데이터가 민감한 것으로 간주되기 때문에 안전한 전송이 중요합니다.\n가장 안정적인 데이터 전송을 제공하는 솔루션은 무엇입니까?",
      "eng": "A company receives 10 TB of instrumentation data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on-premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near-real-time analytics. A secure transfer is important because the data is considered sensitive.\nWhich solution offers the MOST reliable data transfer?"
    },
    "choices": {
      "kor": {
        "A": "퍼블릭 인터넷을 통한 AWS DataSync",
        "B": "AWS Direct Connect를 통한 AWS DataSync",
        "C": "퍼블릭 인터넷을 통한 AWS DMS(AWS Database Migration Service)",
        "D": "AWS Direct Connect를 통한 AWS DMS(AWS Database Migration Service)"
      },
      "eng": {
        "A": "AWS DataSync over public internet",
        "B": "AWS DataSync over AWS Direct Connect",
        "C": "AWS Database Migration Service (AWS DMS) over public internet",
        "D": "AWS Database Migration Service (AWS DMS) over AWS Direct Connect"
      }
    },
    "category": [
      "Data Transfer"
    ],
    "subcategory": [
      "DataSync",
      "Direct Connect"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 92,
    "question": {
      "kor": "응용 프로그램을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. 제품 데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다. 운영 팀은 애플리케이션 성능 저하를 격리했으며 쓰기 트래픽에서 읽기 트래픽을 분리하려고 합니다. 솔루션 설계자는 애플리케이션의 성능을 신속하게 최적화해야 합니다.\n솔루션 설계자는 무엇을 추천해야 합니까?",
      "eng": "An application allows users at a company's headquarters to access product data. The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application's performance quickly.\nWhat should the solutions architect recommend?"
    },
    "choices": {
      "kor": {
        "A": "기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 가용 영역에서 읽기 요청을 처리합니다.",
        "B": "기존 데이터베이스를 다중 AZ 배포로 변경합니다. 보조 가용 영역에서 읽기 요청을 처리합니다.",
        "C": "데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 컴퓨팅 및 스토리지 리소스의 절반을 원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다.",
        "D": "데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 소스 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 읽기 전용 복제본을 구성합니다."
      },
      "eng": {
        "A": "Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone.",
        "B": "Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone.",
        "C": "Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.",
        "D": "Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85906-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 93,
    "question": {
      "kor": "회사는 AWS에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 PostgreSQL용 Amazon S3 및 Amazon RDS의 데이터로 구성됩니다. 회사는 데이터 시각화를 제공하고 데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 회사의 관리 팀만 모든 시각화에 대한 전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스만 허용해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a data lake on AWS. The data lake consists of data in Amazon S3 and Amazon RDS for PostgreSQL. The company needs a reporting solution that provides data visualization and includes all the data sources within the data lake. Only the company's management team should have full access to all the visualizations. The rest of the company should have only limited access.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 대시보드를 공유합니다.",
        "B": "Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 대시보드를 공유합니다.",
        "C": "Amazon S3 AWS Glue의 데이터에 대한 테이블 및 크롤러를 생성합니다. AWS Glue 추출 변환 및 로드(ETL) 작업을 생성하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.",
        "D": "Amazon S3의 데이터에 대한 AWS Glue 테이블 및 크롤러를 생성합니다. Amazon Athena Federated Query를 사용하여 PostgreSQL용 Amazon RDS 내의 데이터에 액세스합니다. Amazon Athena를 사용하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다."
      },
      "eng": {
        "A": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate IAM roles.",
        "B": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups.",
        "C": "Create an AWS Glue table and crawler for the data in Amazon S3. Create an AWS Glue extract, transform, and load (ETL) job to produce reports. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports.",
        "D": "Create an AWS Glue table and crawler for the data in Amazon S3. Use Amazon Athena Federated Query to access data within Amazon RDS for PostgreSQL. Generate reports by using Amazon Athena. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84732-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 94,
    "question": {
      "kor": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 비즈니스 크리티컬 웹 애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 애플리케이션은 단일 가용 영역에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 사용합니다. 회사는 가동 중지 시간을 최소화하고 데이터 손실을 최소화하면서 애플리케이션의 가용성을 높이길 원합니다.\n최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is running a business-critical web application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances are in an Auto Scaling group. The application uses an Amazon Aurora PostgreSQL database that is deployed in a single Availability Zone. The company wants the application to be highly available with minimum downtime and minimum loss of data.\nWhich solution will meet these requirements with the LEAST operational effort?"
    },
    "choices": {
      "kor": {
        "A": "다른 AWS 지역에 EC2 인스턴스를 배치하십시오. Amazon Route 53 상태 확인을 사용하여 트래픽을 리디렉션합니다. Aurora PostgreSQL 교차 리전 복제를 사용합니다.",
        "B": "여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스를 다중 AZ로 구성합니다. 데이터베이스에 대한 Amazon RDS Proxy 인스턴스를 구성합니다.",
        "C": "하나의 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스의 시간별 스냅샷을 생성합니다. 장애 발생 시 스냅샷에서 데이터베이스를 복구합니다.",
        "D": "여러 AWS 리전을 사용하도록 Auto Scaling 그룹을 구성합니다. 애플리케이션의 데이터를 Amazon S3에 씁니다. S3 이벤트 알림을 사용하여 데이터베이스에 데이터를 쓰는 AWS",
        "E": "Lambda 함수를 시작합니다."
      },
      "eng": {
        "A": "Place the EC2 instances in different AWS Regions. Use Amazon Route 53 health checks to redirect traffic. Use Aurora PostgreSQL Cross-Region Replication.",
        "B": "Configure the Auto Scaling group to use multiple Availability Zones. Configure the database as Multi-AZ. Configure an Amazon RDS Proxy instance for the database.",
        "C": "Configure the Auto Scaling group to use one Availability Zone. Generate hourly snapshots of the database. Recover the database from the snapshots in the event of a failure.",
        "D": "Configure the Auto Scaling group to use multiple AWS Regions. Write the data from the application to Amazon S3. Use S3 Event Notifications to launch an AWS Lambda function to write the data to the database."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85594-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 95,
    "question": {
      "kor": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 전자상거래 애플리케이션을 실행합니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 CPU 사용률 지표를 기반으로 확장됩니다. 전자 상거래 애플리케이션은 대규모 EC2 인스턴스에서 호스팅되는 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다.\n애플리케이션 로드가 증가하면 데이터베이스 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 트랜잭션보다 더 많은 읽기 요청을 처리합니다. 회사는 고가용성을 유지하면서 예측할 수 없는 읽기 워크로드의 수요를 충족하기 위해 데이터베이스를 자동으로 확장하는 솔루션을 원합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs an ecommerce application on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales based on CPU utilization metrics. The ecommerce application stores the transaction data in a MySQL 8.0 database that is hosted on a large EC2 instance.\nThe database's performance degrades quickly as application load increases. The application handles more read requests than write transactions. The company wants a solution that will automatically scale the database to meet the demand of unpredictable read workloads while maintaining high availability.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "리더 및 컴퓨팅 기능을 위해 단일 노드와 함께 Amazon Redshift를 사용하십시오.",
        "B": "단일 AZ 배포와 함께 Amazon RDS 사용 Amazon RDS를 구성하여 다른 가용 영역에 리더 인스턴스를 추가합니다.",
        "C": "다중 AZ 배포와 함께 Amazon Aurora를 사용합니다. Aurora 복제본으로 Aurora Auto Scaling을 구성합니다.",
        "D": "EC2 스팟 인스턴스와 함께 Memcached용 Amazon ElastiCache를 사용합니다."
      },
      "eng": {
        "A": "Use Amazon Redshift with a single node for leader and compute functionality.",
        "B": "Use Amazon RDS with a Single-AZ deployment Configure Amazon RDS to add reader instances in a different Availability Zone.",
        "C": "Use Amazon Aurora with a Multi-AZ deployment. Configure Aurora Auto Scaling with Aurora Replicas.",
        "D": "Use Amazon ElastiCache for Memcached with EC2 Spot Instances."
      }
    },
    "category": [
      "Aurora"
    ],
    "subcategory": [
      "auto scaling",
      "replicas"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85019-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 96,
    "question": {
      "kor": "회사는 확장성 및 가용성에 대한 요구 사항을 충족하기 위해 컨테이너에서 중요한 애플리케이션을 실행하려고 합니다. 회사는 중요한 응용 프로그램의 유지 관리에 집중하는 것을 선호합니다.\n회사는 컨테이너화된 워크로드를 실행하는 기본 인프라를 프로비저닝하고 관리하는 책임을 원하지 않습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company wants to run its critical applications in containers to meet requirements for scalability and availability. The company prefers to focus on maintenance of the critical applications. The company does not want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workload.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EC2 인스턴스를 사용하고 인스턴스에 Docker를 설치하십시오.",
        "B": "Amazon EC2 작업자 노드에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.",
        "C": "AWS Fargate에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.",
        "D": "Amazon Elastic Container Service(Amazon ECS)에 최적화된 Amazon Machine Image(AMI)에서 Amazon EC2 인스턴스를 사용합니다."
      },
      "eng": {
        "A": "Use Amazon EC2 instances, and install Docker on the instances.",
        "B": "Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes.",
        "C": "Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.",
        "D": "Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)-optimized Amazon Machine Image (AMI)."
      }
    },
    "category": [
      "ECS"
    ],
    "subcategory": [
      "Fargate"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85453-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 97,
    "question": {
      "kor": "최근에 AWS로 마이그레이션한 회사에서 프로덕션 VPC로 들어오고 나가는 트래픽을 보호하기 위한 솔루션을 구현하려고 합니다. 이 회사는 온프레미스 데이터 센터에 검사 서버를 가지고 있었습니다. 검사 서버는 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 수행했습니다. 회사는 AWS 클라우드에서 동일한 기능을 갖기를 원합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company recently migrated to AWS and wants to implement a solution to protect the traffic that flows in and out of the production VPC. The company had an inspection server in its on-premises data center. The inspection server performed specific operations such as traffic flow inspection and traffic filtering.\nThe company wants to have the same functionalities in the AWS Cloud.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "프로덕션 VPC에서 트래픽 검사 및 트래픽 필터링에 Amazon GuardDuty를 사용하십시오.",
        "B": "트래픽 미러링을 사용하여 트래픽 검사 및 필터링을 위해 프로덕션 VPC의 트래픽을 미러링합니다.",
        "C": "AWS Network Firewall을 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 생성합니다.",
        "D": "AWS Firewall Manager를 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 생성합니다."
      },
      "eng": {
        "A": "Use Amazon GuardDuty for traffic inspection and traffic filtering in the production VPC.",
        "B": "Use Traffic Mirroring to mirror traffic from the production VPC for traffic inspection and filtering.",
        "C": "Use AWS Network Firewall to create the required rules for traffic inspection and traffic filtering for the production VPC.",
        "D": "Use AWS Firewall Manager to create the required rules for traffic inspection and traffic filtering for the production VPC."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84731-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 98,
    "question": {
      "kor": "솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC를 설계하고 있습니다. VPC와 서브넷은 IPv4 CIDR 블록을 사용합니다. 고가용성을 위해 3개의 가용 영역(AZ) 각각에 퍼블릭 서브넷 1개와 프라이빗 서브넷 1개가 있습니다. 인터넷 게이트웨이는 퍼블릭 서브넷에 대한 인터넷 액세스를 제공하는 데 사용됩니다. 프라이빗 서브넷은 Amazon EC2 인스턴스가 소프트웨어 업데이트를 다운로드할 수 있도록 인터넷에 액세스해야 합니다.\n사설 서브넷에 대한 인터넷 액세스를 활성화하려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates.\nWhat should the solutions architect do to enable Internet access for the private subnets?"
    },
    "choices": {
      "kor": {
        "A": "각 AZ의 퍼블릭 서브넷마다 하나씩 세 개의 NAT 게이트웨이를 생성합니다. 비 VPC 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ에 대한 프라이빗 라우팅 테이블을 생성합니다.",
        "B": "각 AZ의 각 프라이빗 서브넷에 대해 하나씩 세 개의 NAT 인스턴스를 만듭니다. 비 VPC 트래픽을 해당 AZ의 NAT 인스턴스로 전달하는 각 AZ에 대한 프라이빗 라우팅 테이블을 생성 합니다.",
        "C": "프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 만듭니다. VPC가 아닌 트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.",
        "D": "퍼블릭 서브넷 중 하나에 외부 전용 인터넷 게이트웨이를 만듭니다. 비 VPC 트래픽을 외부 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다."
      },
      "eng": {
        "A": "Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ.",
        "B": "Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ.",
        "C": "Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC traffic to the private internet gateway.",
        "D": "Create an egress-only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non-VPC traffic to the egress-only Internet gateway."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86019-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 99,
    "question": {
      "kor": "회사는 들어오는 요청을 처리하는 온프레미스 서버 플릿에서 컨테이너화된 웹 애플리케이션을 호스팅합니다. 요청 수가 빠르게 증가하고 있습니다. 온프레미스 서버는 증가된 요청 수를 처리할 수 없습니다. 이 회사는 최소한의 코드 변경과 최소한의 개발 노력으로 애플리케이션을 AWS로 옮기기를 원합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a containerized web application on a fleet of on-premises servers that process incoming requests. The number of requests is growing quickly. The on-premises servers cannot handle the increased number of requests. The company wants to move the application to AWS with minimum code changes and minimum development effort.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Elastic Container Service(Amazon ECS)에서 AWS Fargate를 사용하여 Service Auto Scaling으로 컨테이너화된 웹 애플리케이션을 실행합니다. Application Load Balancer를 사용하여 들어오는 요청을 분산합니다.",
        "B": "두 개의 Amazon EC2 인스턴스를 사용하여 컨테이너화된 웹 애플리케이션을 호스팅합니다. Application Load Balancer를 사용하여 들어오는 요청을 분산합니다.",
        "C": "지원되는 언어 중 하나를 사용하는 새 코드와 함께 AWS Lambda를 사용합니다. 로드를 지원하는 여러 Lambda 함수를 생성합니다. Amazon API Gateway를 Lambda 함수에 대한 진입점으로 사용합니다.",
        "D": "AWS ParallelCluster와 같은 고성능 컴퓨팅(HPC) 솔루션을 사용하여 적절한 규모로 들어오는 요청을 처리할 수 있는 HPC 클러스터를 설정합니다."
      },
      "eng": {
        "A": "Use AWS Fargate on Amazon Elastic Container Service (Amazon ECS) to run the containerized web application with Service Auto Scaling. Use an Application Load Balancer to distribute the incoming requests.",
        "B": "Use two Amazon EC2 instances to host the containerized web application. Use an Application Load Balancer to distribute the incoming requests.",
        "C": "Use AWS Lambda with a new code that uses one of the supported languages. Create multiple Lambda functions to support the load. Use Amazon API Gateway as an entry point to the Lambda functions.",
        "D": "Use a high performance computing (HPC) solution such as AWS ParallelCluster to establish an HPC cluster that can process the incoming requests at the appropriate scale."
      }
    },
    "category": [
      "ECS"
    ],
    "subcategory": [
      "Fargate"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85913-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 100,
    "question": {
      "kor": "조사 회사는 미국 지역에서 몇 년 동안 데이터를 수집했습니다. 회사는 크기가 3TB이고 계속 증가하는 Amazon S3 버킷에서 데이터를 호스팅합니다. 회사는 S3 버킷을 보유한 유럽 마케팅 회사와 데이터를 공유하기 시작했습니다. 회사는 데이터 전송 비용이 가능한 한 낮게 유지되기를 원합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A survey company has gathered data for several years from areas in the United States. The company hosts the data in an Amazon S3 bucket that is 3 TB in size and growing. The company has started to share the data with a European marketing firm that has S3 buckets. The company wants to ensure that its data transfer costs remain as low as possible.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사의 S3 버킷에서 요청자 지불 기능을 구성합니다.",
        "B": "회사의 S3 버킷에서 마케팅 회사의 S3 버킷 중 하나로 S3 교차 리전 복제를 구성합니다.",
        "C": "마케팅 회사가 회사의 S3 버킷에 액세스할 수 있도록 마케팅 회사에 대한 교차 계정 액세스를 구성합니다.",
        "D": "S3 Intelligent-Tiering을 사용하도록 회사의 S3 버킷을 구성합니다. 마케팅 회사의 S3 버킷 중 하나에 S3 버킷을 동기화합니다."
      },
      "eng": {
        "A": "Configure the Requester Pays feature on the company's S3 bucket.",
        "B": "Configure S3 Cross-Region Replication from the company's S3 bucket to one of the marketing firm's S3 buckets.",
        "C": "Configure cross-account access for the marketing firm so that the marketing firm has access to the company's S3 bucket.",
        "D": "Configure the company's S3 bucket to use S3 Intelligent-Tiering. Sync the S3 bucket to one of the marketing firm's S3 buckets."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85738-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 101,
    "question": {
      "kor": "회사의 애플리케이션은 데이터 수집을 위해 여러 SaaS(Software-as-a-Service) 소스와 통합됩니다. 회사는 Amazon EC2 인스턴스를 실행하여 데이터를 수신하고 분석을 위해 데이터를 Amazon S3 버킷에 업로드합니다. 데이터를 수신하고 업로드하는 동일한 EC2 인스턴스도 업로드가 완료되면 사용자에게 알림을 보냅니다. 회사는 느린 응용 프로그램 성능을 발견했으며 성능을 최대한 개선하고자 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company's application integrates with multiple software-as-a-service (SaaS) sources for data collection. The company runs Amazon EC2 instances to receive the data and to upload the data to an Amazon S3 bucket for analysis. The same EC2 instance that receives and uploads the data also sends a notification to the user when an upload is complete. The company has noticed slow application performance and wants to improve the performance as much as possible.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스가 확장될 수 있도록 Auto Scaling 그룹을 생성합니다. S3 버킷에 대한 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제로 이벤트를 보내도록 S3 이벤트 알림을 구성합니다.",
        "B": "각 SaaS 소스와 S3 버킷 간에 데이터를 전송하는 Amazon AppFlow 흐름을 생성합니다. S3 버킷에 대한 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제로 이벤트를 보내도록 S3 이벤트 알림을 구성합니다.",
        "C": "각 SaaS 소스에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 출력 데이터를 보냅니다. S3 버킷을 규칙의 대상으로 구성합니다. S3 버킷에 대한 업로드가 완료되면 이벤트를 전송하는 두 번째 EventBridge(Cloud Watch Events) 규칙을 생성합니다. Amazon Simple Notification Service(Amazon SNS) 주제를 두 번째 규칙의 대상으로 구성합니다.",
        "D": "EC2 인스턴스 대신 사용할 Docker 컨테이너를 생성합니다. Amazon Elastic Container Service(Amazon ECS)에서 컨테이너화된 애플리케이션을 호스팅합니다. S3 버킷에 대한 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제로 이벤트를 보내도록 Amazon CloudWatch Container Insights를 구성합니다."
      },
      "eng": {
        "A": "Create an Auto Scaling group so that EC2 instances can scale out. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.",
        "B": "Create an Amazon AppFlow flow to transfer data between each SaaS source and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.",
        "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for each SaaS source to send output data. Configure the S3 bucket as the rule's target. Create a second EventBridge (Cloud Watch Events) rule to send events when the upload to the S3 bucket is complete. Configure an Amazon Simple Notification Service (Amazon SNS) topic as the second rule's target.",
        "D": "Create a Docker container to use instead of an EC2 instance. Host the containerized application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon CloudWatch Container Insights to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85446-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 102,
    "question": {
      "kor": "한 회사에 AWS에서 호스팅되는 웹사이트가 있습니다. 웹사이트는 HTTP와 HTTPS를 별도로 처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 HTTPS를 사용하도록 모든 요청을 웹 사이트로 전달하려고 합니다.\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company has a website hosted on AWS. The website is behind an Application Load Balancer (ALB) that is configured to handle HTTP and HTTPS separately. The company wants to forward all requests to the website so that the requests will use HTTPS.\nWhat should a solutions architect do to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "HTTPS 트래픽만 허용하도록 ALB의 네트워크 ACL을 업데이트합니다.",
        "B": "URL의 HTTP를 HTTPS로 바꾸는 규칙을 만듭니다.",
        "C": "ALB에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS로 리디렉션합니다.",
        "D": "ALB를 SNI(Server Name Indication)를 사용하도록 구성된 Network Load Balancer로 교체합니다."
      },
      "eng": {
        "A": "Update the ALB's network ACL to accept only HTTPS traffic.",
        "B": "Create a rule that replaces the HTTP in the URL with HTTPS.",
        "C": "Create a listener rule on the ALB to redirect HTTP traffic to HTTPS.",
        "D": "Replace the ALB with a Network Load Balancer configured to use Server Name Indication (SNI)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85121-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 103,
    "question": {
      "kor": "회사는 클라우드 배포를 검토하여 AWS Amazon S3 버킷에 무단 구성 변경이 없는지 확인해야 합니다.\n이 목표를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까?",
      "eng": "A company needs to review its AWS Cloud deployment to ensure that its Amazon S3 buckets do not have unauthorized configuration changes.\nWhat should a solutions architect do to accomplish this goal?"
    },
    "choices": {
      "kor": {
        "A": "적절한 규칙으로 AWS Config를 켭니다.",
        "B": "적절한 확인을 통해 AWS Trusted Advisor를 켭니다.",
        "C": "적절한 평가 템플릿으로 Amazon Inspector를 켭니다.",
        "D": "Amazon S3 서버 액세스 로깅을 켭니다. Amazon EventBridge(Amazon Cloud Watch Events)를 구성합니다."
      },
      "eng": {
        "A": "Turn on AWS Config with the appropriate rules.",
        "B": "Turn on AWS Trusted Advisor with the appropriate checks.",
        "C": "Turn on Amazon Inspector with the appropriate assessment template.",
        "D": "Turn on Amazon S3 server access logging. Configure Amazon EventBridge (Amazon Cloud Watch Events)."
      }
    },
    "category": [
      "Config"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84940-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 104,
    "question": {
      "kor": "회사는 동일한 AWS 리전에 있는 Amazon S3 버킷에서 사진을 자주 업로드하고 다운로드해야 하는 사진 처리 애플리케이션을 실행합니다. 솔루션 아키텍트가 데이터 전송 비용의 증가를 발견하고 이러한 비용을 줄이기 위한 솔루션을 구현해야 합니다.\n솔루션 설계자는 이 요구 사항을 어떻게 충족할 수 있습니까?",
      "eng": "A company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region. A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs.\nHow can the solutions architect meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "Amazon API Gateway를 퍼블릭 서브넷에 배포하고 이를 통해 S3 호출을 라우팅하도록 라우팅 테이블을 조정합니다.",
        "B": "퍼블릭 서브넷에 NAT 게이트웨이를 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결합니다.",
        "C": "애플리케이션을 퍼블릭 서브넷에 배포하고 인터넷 게이트웨이를 통해 라우팅하여 S3 버킷에 액세스하도록 허용합니다.",
        "D": "S3 VPC 게이트웨이 엔드포인트를 VPC에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결합니다."
      },
      "eng": {
        "A": "Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it.",
        "B": "Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets.",
        "C": "Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets.",
        "D": "Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets."
      }
    },
    "category": [
      "VPC endpoint"
    ],
    "subcategory": [
      "S3"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85604-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 105,
    "question": {
      "kor": "회사는 사용자 트랜잭션 데이터를 Amazon DynamoDB 테이블에 보관해야 합니다. 회사는 데이터를 7년간 보관해야 합니다.\n이러한 요구 사항을 충족하는 운영상 가장 효율적인 솔루션은 무엇입니까?",
      "eng": "A company needs to keep user transaction data in an Amazon DynamoDB table. The company must retain the data for 7 years.\nWhat is the MOST operationally efficient solution that meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "DynamoDB point-in-time recovery를 사용하여 테이블을 지속적으로 백업하십시오.",
        "B": "AWS Backup을 사용하여 테이블에 대한 백업 일정 및 보존 정책을 생성합니다.",
        "C": "DynamoDB 콘솔을 사용하여 테이블의 온디맨드 백업을 생성합니다. Amazon S3 버킷에 백업을 저장합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다.",
        "D": "AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. 테이블을 백업하고 백업을 Amazon S3 버킷에 저장하도록 Lambda 함수를 구성합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다."
      },
      "eng": {
        "A": "Use DynamoDB point-in-time recovery to back up the table continuously.",
        "B": "Use AWS Backup to create backup schedules and retention policies for the table.",
        "C": "Create an on-demand backup of the table by using the DynamoDB console. Store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket.",
        "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to invoke an AWS Lambda function. Configure the Lambda function to back up the table and to store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85742-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 106,
    "question": {
      "kor": "회사는 Amazon S3를 사용하여 기밀 감사 문서를 저장합니다. S3 버킷은 버킷 정책을 사용하여 최소 권한 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다. 회사 관리자는 S3 버킷의 문서를 실수로 삭제하는 것에 대해 걱정하고 보다 안전한 솔루션을 원합니다.\n솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까?",
      "eng": "A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.\nWhat should a solutions architect do to secure the audit documents?"
    },
    "choices": {
      "kor": {
        "A": "S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다.",
        "B": "각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에서 다중 요소 인증(MFA)을 활성화합니다.",
        "C": "감사 날짜 동안 s3:DeleteObject 작업을 거부하도록 감사 팀의 IAM 사용자 계정에 S3 수명 주기 정책을 추가합니다.",
        "D": "AWS Key Management Service(AWS KMS)를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다."
      },
      "eng": {
        "A": "Enable the versioning and MFA Delete features on the S3 bucket.",
        "B": "Enable multi-factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.",
        "C": "Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.",
        "D": "Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "MFA Delete",
      "Versioning"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85808-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 107,
    "question": {
      "kor": "한 회사가 최근 메시지 처리 시스템을 AWS로 마이그레이션했습니다. 시스템은 Amazon EC2 인스턴스에서 실행되는 ActiveMQ 대기열로 메시지를 수신합니다. 메시지는 Amazon EC2에서 실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 메시지를 처리하고 결과를 Amazon EC2에서 실행되는 MySQL 데이터베이스에 기록합니다. 회사는\n이 애플리케이션이 운영 복잡성이 낮으면서 가용성이 높기를 원합니다.\n가장 높은 가용성을 제공하는 아키텍처는 무엇입니까?",
      "eng": "A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity.\nWhich architecture offers the HIGHEST availability?"
    },
    "choices": {
      "kor": {
        "A": "다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.",
        "B": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.",
        "C": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 추가 소비자 EC2 인스턴스를 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다.",
        "D": "두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 두 가용 영역에서 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다."
      },
      "eng": {
        "A": "Add a second ActiveMQ server to another Availability Zone. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
        "B": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
        "C": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled.",
        "D": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 108,
    "question": {
      "kor": "한 회사에서 다중 계층 애플리케이션을 온프레미스에서 AWS 클라우드로 이동하여 애플리케이션의 성능을 개선하려고 합니다. 애플리케이션은 RESTful 서비스를 통해 서로 통신하는 애플리케이션 계층으로 구성됩니다. 한 계층이 과부하되면 트랜잭션이 삭제됩니다. 솔루션 설계자는 이러한 문제를 해결하고 애플리케이션을 현대화하는 솔루션을 설계해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까?",
      "eng": "A company wants to move a multi-tiered application from on premises to the AWS Cloud to improve the application's performance. The application consists of application tiers that communicate with each other by way of RESTful services. Transactions are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application.\nWhich solution meets these requirements and is the MOST operationally efficient?"
    },
    "choices": {
      "kor": {
        "A": "Amazon API Gateway를 사용하고 애플리케이션 계층으로 AWS Lambda 기능에 대한 직접 트랜잭션을 사용하십시오. 애플리케이션 서비스 간의 통신 계층으로 Amazon Simple Queue Service(Amazon SQS)를 사용합니다.",
        "B": "Amazon CloudWatch 지표를 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 시 서버의 최대 사용률을 결정합니다. 최대 요구 사항을 충족하도록 애플리케이션 서버의 Amazon EC2 인스턴스 크기를 늘립니다.",
        "C": "Amazon Simple Notification Service(Amazon SNS)를 사용하여 Auto Scaling 그룹의 Amazon EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 축소합니다.",
        "D": "Amazon Simple Queue Service(Amazon SQS)를 사용하여 Auto Scaling 그룹의 Amazon EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 SQS 대기열 길이를 모니터링하고 통신 실패가 감지되면 확장합니다."
      },
      "eng": {
        "A": "Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.",
        "B": "Use Amazon CloudWatch metrics to analyze the application performance history to determine the servers' peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.",
        "C": "Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.",
        "D": "Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86120-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 109,
    "question": {
      "kor": "한 병원은 최근 Amazon API Gateway 및 AWS Lambda와 함께 RESTful API를 배포했습니다. 병원은 API 게이트웨이와 Lambda를 사용하여 PDF 형식과 JPEG 형식의 보고서를 업로드합니다. 병원은 보고서에서 보호 건강 정보(PHI)를 식별하기 위해 Lambda 코드를 수정해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A hospital recently deployed a RESTful API with Amazon API Gateway and AWS Lambda. The hospital uses API Gateway and Lambda to upload reports that are in PDF format and JPEG format. The hospital needs to modify the Lambda code to identify protected health information (PHI) in the reports.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고 추출된 텍스트에서 PHI를 식별합니다.",
        "B": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker를 사용하여 추출된 텍스트에서 PHI를 식별합니다.",
        "C": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다.",
        "D": "Amazon Rekognition을 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다."
      },
      "eng": {
        "A": "Use existing Python libraries to extract the text from the reports and to identify the PHI from the extracted text.",
        "B": "Use Amazon Textract to extract the text from the reports. Use Amazon SageMaker to identify the PHI from the extracted text.",
        "C": "Use Amazon Textract to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text.",
        "D": "Use Amazon Rekognition to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text."
      }
    },
    "category": [
      "AI"
    ],
    "subcategory": [
      "Textract",
      "Comprehend Medical"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85367-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 110,
    "question": {
      "kor": "회사에서 공개적으로 액세스할 수 있는 영화 데이터를 저장하기 위해 SQL 데이터베이스를 사용하고 있습니다. 데이터베이스는 Amazon RDS 단일 AZ DB 인스턴스에서 실행됩니다. 스크립트는 데이터베이스에 추가된 새 영화의 수를 기록하기 위해 매일 임의의 간격으로 쿼리를 실행합니다. 스크립트는 업무 시간 동안 최종 합계를 보고해야 합니다.\n회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 적합하지 않다는 것을 알게 되었습니다. 솔루션 설계자는 이 문제를 해결하기 위한 솔루션을 추천해야 합니다.\n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is using a SQL database to store movie data that is publicly accessible. The database runs on an Amazon RDS Single-AZ DB instance. A script runs queries at random intervals each day to record the number of new movies that have been added to the database. The script must report a final total during business hours.\nThe company's development team notices that the database performance is inadequate for development tasks when the script is running. A solutions architect must recommend a solution to resolve this issue.\nWhich solution will meet this requirement with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "다중 AZ 배포가 되도록 DB 인스턴스를 수정합니다.",
        "B": "데이터베이스의 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본만 쿼리하도록 스크립트를 구성합니다.",
        "C": "개발 팀에게 매일 일과가 끝날 때 데이터베이스의 항목을 수동으로 내보내도록 지시합니다.",
        "D": "Amazon ElastiCache를 사용하여 스크립트가 데이터베이스에 대해 실행하는 일반적인 쿼리를 캐시합니다."
      },
      "eng": {
        "A": "Modify the DB instance to be a Multi-AZ deployment.",
        "B": "Create a read replica of the database. Configure the script to query only the read replica.",
        "C": "Instruct the development team to manually export the entries in the database at the end of each day.",
        "D": "Use Amazon ElastiCache to cache the common queries that the script runs against the database."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85339-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 111,
    "question": {
      "kor": "한 회사가 AWS에서 전자상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 새 주문에 대한 정보를 Amazon API Gateway REST API로 전송하여 처리합니다. 회사는 주문이 접수된 순서대로 처리되기를 원합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company is building an ecommerce web application on AWS. The application sends information about new orders to an Amazon API Gateway REST API to process. The company wants to ensure that orders are processed in the order that they are received.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "애플리케이션이 주문을 받으면 API Gateway 통합을 사용하여 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 처리를 수행할 주제에 대한 AWS Lambda 함수를 구독합니다.",
        "B": "애플리케이션이 주문을 받으면 API Gateway 통합을 사용하여 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS FIFO 대기열을 구성합니다.",
        "C": "애플리케이션이 주문을 처리하는 동안 API 게이트웨이 권한 부여자를 사용하여 모든 요청을 차단합니다.",
        "D": "애플리케이션이 주문을 받으면 API Gateway 통합을 사용하여 Amazon Simple Queue Service(Amazon SQS) 표준 대기열로 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS 표준 대기열을 구성합니다."
      },
      "eng": {
        "A": "Use an API Gateway integration to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when the application receives an order. Subscribe an AWS Lambda function to the topic to perform processing.",
        "B": "Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) FIFO queue when the application receives an order. Configure the SQS FIFO queue to invoke an AWS Lambda function for processing.",
        "C": "Use an API Gateway authorizer to block any requests while the application processes an order.",
        "D": "Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) standard queue when the application receives an order. Configure the SQS standard queue to invoke an AWS Lambda function for processing."
      }
    },
    "category": [
      "SQS"
    ],
    "subcategory": [
      "FIFO"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84681-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 112,
    "question": {
      "kor": "솔루션 설계자는 Amazon S3를 사용하여 새로운 디지털 미디어 애플리케이션의 스토리지 아키텍처를 설계하고 있습니다. 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 합니다. 일부 파일은 자주 액세스되는 반면 다른 파일은 예측할 수 없는 패턴으로 거의 액세스되지 않습니다. 솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다.\n이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?",
      "eng": "A solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone. Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files.\nWhich storage option meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "S3 기준",
        "B": "S3 지능형 계층화",
        "C": "S3 Standard-Infrequent Access(S3 Standard-IA)",
        "D": "S3 One Zone-Infrequent Access(S3 One Zone-IA)"
      },
      "eng": {
        "A": "S3 Standard",
        "B": "S3 Intelligent-Tiering",
        "C": "S3 Standard-Infrequent Access (S3 Standard-IA)",
        "D": "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Storage Class",
      "unpredictable pattern"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84943-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 113,
    "question": {
      "kor": "회사는 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 둘 다 Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 한 하위 집합 또는 다른 하위 집합을 볼 수 있지만 동시에 모든 문서를 볼 수는 없다고 보고했습니다.\n사용자가 모든 문서를 한 번에 볼 수 있도록 하기 위해 솔루션 설계자는 무엇을 제안해야 합니까?",
      "eng": "A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.\nWhat should a solutions architect propose to ensure users see all of their documents at once?"
    },
    "choices": {
      "kor": {
        "A": "두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다.",
        "B": "문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 구성",
        "C": "두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 새 문서를 Amazon EFS에 저장하도록 애플리케이션 수정",
        "D": "두 서버 모두에 요청을 보내도록 Application Load Balancer를 구성합니다. 올바른 서버에서 각 문서 반환"
      },
      "eng": {
        "A": "Copy the data so both EBS volumes contain all the documents",
        "B": "Configure the Application Load Balancer to direct a user to the server with the documents",
        "C": "Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS",
        "D": "Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server"
      }
    },
    "category": [
      "EFS"
    ],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 114,
    "question": {
      "kor": "회사에는 Microsoft Windows 공유 파일 저장소가 필요한 온-프레미스에서 실행되는 대규모 Microsoft SharePoint 배포가 있습니다. 이 회사는 이 워크로드를 AWS 클라우드로 마이그레이션하려고 하며 다양한 스토리지 옵션을 고려하고 있습니다. 저장소 솔루션은 액세스 제어를 위해 가용성이 높고 Active Directory와 통합되어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control.\nWhich solution will satisfy these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Amazon EFS 스토리지를 구성하고 인증을 위한 Active Directory 도메인을 설정합니다.",
        "B": "두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다.",
        "C": "Amazon S3 버킷을 생성하고 이를 볼륨으로 탑재하도록 Microsoft Windows Server를 구성합니다.",
        "D": "AWS에서 Windows File Server 파일 시스템용 Amazon FSx를 생성하고 인증을 위한 Active Directory 도메인을 설정합니다."
      },
      "eng": {
        "A": "Configure Amazon EFS storage and set the Active Directory domain for authentication.",
        "B": "Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones.",
        "C": "Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume.",
        "D": "Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86626-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 115,
    "question": {
      "kor": "회사에는 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 애플리케이션이 있습니다. EC2 인스턴스는 파일에 로컬로 저장된 사용자 이름과 암호를 사용하여 데이터베이스에 연결합니다. 회사는 자격 증명 관리의 운영 오버헤드를 최소화하려고 합니다.\n이 목표를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까?",
      "eng": "A company has an application that runs on Amazon EC2 instances and uses an Amazon Aurora database. The EC2 instances connect to the database by using user names and passwords that are stored locally in a file. The company wants to minimize the operational overhead of credential management.\nWhat should a solutions architect do to accomplish this goal?"
    },
    "choices": {
      "kor": {
        "A": "AWS Secrets Manager를 사용하십시오. 자동 회전을 켭니다.",
        "B": "AWS Systems Manager Parameter Store를 사용합니다. 자동 회전을 켭니다.",
        "C": "AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장할 Amazon S3 버킷을 생성합니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션이 S3 버킷을 가리키도록 합니다.",
        "D": "각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 새 EBS 볼륨을 각 EC2 인스턴스에 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 마이그레이션합니다. 애플리케이션이 새 EBS 볼륨을 가리키도록 합니다."
      },
      "eng": {
        "A": "Use AWS Secrets Manager. Turn on automatic rotation.",
        "B": "Use AWS Systems Manager Parameter Store. Turn on automatic rotation.",
        "C": "Create an Amazon S3 bucket to store objects that are encrypted with an AWS Key Management Service (AWS KMS) encryption key. Migrate the credential file to the S3 bucket. Point the application to the S3 bucket.",
        "D": "Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume for each EC2 instance. Attach the new EBS volume to each EC2 instance. Migrate the credential file to the new EBS volume. Point the application to the new EBS volume."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84682-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 116,
    "question": {
      "kor": "한 회사에서 us-west-2 리전의 NLB(Network Load Balancer) 뒤에 있는 3개의 Amazon EC2 인스턴스에 자체 관리형 DNS 솔루션을 구현했습니다. 회사 사용자의 대부분은 미국과 유럽에 있습니다. 회사는 솔루션의 성능과 가용성을 개선하고자 합니다. 회사는 eu-west-1 지역에서 3개의 EC2 인스턴스를 시작 및 구성하고 EC2 인스턴스를 새 NLB의 대상으로 추가합니다.\n회사에서 트래픽을 모든 EC2 인스턴스로 라우팅하는 데 사용할 수 있는 솔루션은 무엇입니까?",
      "eng": "A company has implemented a self-managed DNS solution on three Amazon EC2 instances behind a Network Load Balancer (NLB) in the us-west-2 Region.\nMost of the company's users are located in the United States and Europe. The company wants to improve the performance and availability of the solution.\nThe company launches and configures three EC2 instances in the eu-west-1 Region and adds the EC2 instances as targets for a new NLB.\nWhich solution can the company use to route traffic to all the EC2 instances?"
    },
    "choices": {
      "kor": {
        "A": "두 NLB 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다.",
        "B": "AWS Global Accelerator에서 표준 가속기를 생성합니다. us-west-2 및 eu-west-1에서 엔드포인트 그룹을 생성합니다. 끝점 그룹의 끝점으로 두 개의 NLB를 추가합니다.",
        "C": "탄력적 IP 주소를 6개의 EC2 인스턴스에 연결합니다. 6개의 EC2 인스턴스 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다.",
        "D": "두 개의 NLB를 두 개의 ALB(Application Load Balancer)로 교체합니다. 요청을 두 ALB 중 하나로 라우팅하는 Amazon Route 53 지연 시간 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포 원본으로 사용합니다."
      },
      "eng": {
        "A": "Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.",
        "B": "Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.",
        "C": "Attach Elastic IP addresses to the six EC2 instances. Create an Amazon Route 53 geolocation routing policy to route requests to one of the six EC2 instances. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution's origin.",
        "D": "Replace the two NLBs with two Application Load Balancers (ALBs). Create an Amazon Route 53 latency routing policy to route requests to one of the two ALBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 117,
    "question": {
      "kor": "전자상거래 회사는 AWS 클라우드에서 분석 애플리케이션을 호스팅합니다. 이 애플리케이션은 매월 약 300MB의 데이터를 생성합니다. 데이터는 JSON 형식으로 저장됩니다. 회사는 데이\n터 백업을 위한 재해 복구 솔루션을 평가하고 있습니다. 데이터는 필요한 경우 밀리초 단위로 액세스할 수 있어야 하며 데이터는 30일 동안 보관되어야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "An ecommerce company hosts its analytics application in the AWS Cloud. The application generates about 300 MB of data each month. The data is stored in JSON format. The company is evaluating a disaster recovery solution to back up the data. The data must be accessible in milliseconds if it is needed, and the data must be kept for 30 days.\nWhich solution meets these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon OpenSearch 서비스(Amazon Elasticsearch 서비스)",
        "B": "Amazon S3 Glacier",
        "C": "Amazon S3 표준",
        "D": "PostgreSQL용 Amazon RDS"
      },
      "eng": {
        "A": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
        "B": "Amazon S3 Glacier",
        "C": "Amazon S3 Standard",
        "D": "Amazon RDS for PostgreSQL"
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Storage Class"
    ],
    "rote_memorization": true,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87632-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 118,
    "question": {
      "kor": "한 회사가 AWS 클라우드의 Auto Scaling 그룹에 속하는 Amazon EC2 인스턴스에서 게임 애플리케이션을 실행하려고 합니다. 애플리케이션은 UDP 패킷을 사용하여 데이터를 전송합니다. 회사는 트래픽이 증가하거나 감소함에 따라 애플리케이션을 확장 및 축소할 수 있기를 원합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company wants to run a gaming application on Amazon EC2 instances that are part of an Auto Scaling group in the AWS Cloud. The application will transmit data by using UDP packets. The company wants to ensure that the application can scale out and in as traffic increases and decreases.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Auto Scaling 그룹에 Network Load Balancer를 연결합니다.",
        "B": "Auto Scaling 그룹에 Application Load Balancer를 연결합니다.",
        "C": "트래픽을 적절하게 라우팅하기 위한 가중치 정책이 포함된 Amazon Route 53 레코드 세트를 배포합니다.",
        "D": "Auto Scaling 그룹의 EC2 인스턴스에 대한 포트 전달로 구성된 NAT 인스턴스를 배포합니다."
      },
      "eng": {
        "A": "Attach a Network Load Balancer to the Auto Scaling group.",
        "B": "Attach an Application Load Balancer to the Auto Scaling group.",
        "C": "Deploy an Amazon Route 53 record set with a weighted policy to route traffic appropriately.",
        "D": "Deploy a NAT instance that is configured with port forwarding to the EC2 instances in the Auto Scaling group."
      }
    },
    "category": [
      "Elastic Load Balancer"
    ],
    "subcategory": [
      "protocol"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/125215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 119,
    "question": {
      "kor": "회사는 AWS Organizations를 사용하여 각 사업부에 대한 전용 AWS 계정을 생성하여 요청 시 각 사업부의 계정을 독립적으로 관리합니다. 루트 이메일 수신자는 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림을 놓치지 않기를 원합니다. 향후 알림은 계정 관리자로 제한되어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company uses AWS Organizations to create dedicated AWS accounts for each business unit to manage each business unit's account independently upon request. The root email recipient missed a notification that was sent to the root user email address of one account. The company wants to ensure that all future notifications are not missed. Future notifications must be limited to account administrators.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS 계정 루트 사용자 이메일 주소로 전송되는 알림 이메일 메시지를 조직의 모든 사용자에게 전달하도록 회사의 이메일 서버를 구성합니다.",
        "B": "모든 AWS 계정 루트 사용자 이메일 주소를 알림에 응답할 수 있는 소수의 관리자에게 전달되는 배포 목록으로 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다.",
        "C": "모든 AWS 계정 루트 사용자 이메일 메시지가 경고를 모니터링하고 해당 그룹에 해당 경고를 전달하는 역할을 담당하는 한 명의 관리자에게 전송되도록 구성합니다.",
        "D": "동일한 루트 사용자 이메일 주소를 사용하도록 모든 기존 AWS 계정과 새로 생성된 모든 계정을 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다."
      },
      "eng": {
        "A": "Configure the company’s email server to forward notification email messages that are sent to the AWS account root user email address to all users in the organization.",
        "B": "Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.",
        "C": "Configure all AWS account root user email messages to be sent to one administrator who is responsible for monitoring alerts and forwarding those alerts to the appropriate groups.",
        "D": "Configure all existing AWS accounts and all newly created accounts to use the same root user email address. Configure AWS account alternate contacts in the AWS Organizations console or programmatically."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85997-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 120,
    "question": {
      "kor": "회사에는 Amazon EC2 인스턴스에서 실행되는 레거시 데이터 처리 애플리케이션이 있습니다. 데이터는 순차적으로 처리되지만 결과의 순서는 중요하지 않습니다. 응용 프로그램은 모놀리식 아키텍처를 사용합니다. 회사에서 수요 증가에 맞춰 애플리케이션을 확장할 수 있는 유일한 방법은 인스턴스 크기를 늘리는 것입니다.\n이 회사의 개발자는 Amazon Elastic Container Service(Amazon ECS)에서 마이크로서비스 아키텍처를 사용하도록 애플리케이션을 다시 작성하기로 결정했습니다.\n솔루션 설계자는 마이크로서비스 간의 통신을 위해 무엇을 권장해야 합니까?",
      "eng": "A company has a legacy data processing application that runs on Amazon EC2 instances. Data is processed sequentially, but the order of results does not matter. The application uses a monolithic architecture. The only way that the company can scale the application to meet increased demand is to increase the size of the instances.\nThe company’s developers have decided to rewrite the application to use a microservices architecture on Amazon Elastic Container Service (Amazon ECS).\nWhat should a solutions architect recommend for communication between the microservices?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 데이터 생산자에 코드를 추가하고 데이터를 대기열로 보냅니다. 데이터 소비자에 코드를 추가하여 대기열의 데이터를 처리합니다.",
        "B": "Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. 데이터 생산자에 코드를 추가하고 주제에 알림을 게시합니다. 데이터 소비자에 코드를 추가하여 주제를 구독합니다.",
        "C": "메시지를 전달할 AWS Lambda 함수를 생성합니다. 데이터 생산자에 코드를 추가하여 데이터 객체로 Lambda 함수를 호출합니다. 데이터 소비자에 코드를 추가하여 Lambda 함수에서 전달되는 데이터 객체를 수신합니다.",
        "D": "Amazon DynamoDB 테이블을 생성합니다. DynamoDB 스트림을 활성화합니다. 데이터 생산자에 코드를 추가하여 테이블에 데이터를 삽입합니다. 데이터 소비자에 코드를 추가하여 DynamoDB Streams API를 사용하여 새 테이블 항목을 감지하고 데이터를 검색합니다."
      },
      "eng": {
        "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.",
        "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Add code to the data producers, and publish notifications to the topic. Add code to the data consumers to subscribe to the topic.",
        "C": "Create an AWS Lambda function to pass messages. Add code to the data producers to call the Lambda function with a data object. Add code to the data consumers to receive a data object that is passed from the Lambda function.",
        "D": "Create an Amazon DynamoDB table. Enable DynamoDB Streams. Add code to the data producers to insert data into the table. Add code to the data consumers to use the DynamoDB Streams API to detect new table entries and retrieve the data."
      }
    },
    "category": [
      "SQS"
    ],
    "subcategory": [
      "microservices architecture"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87647-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 122,
    "question": {
      "kor": "회사는 사용자 요청을 수집하고 요청 유형에 따라 처리를 위해 적절한 마이크로 서비스에 요청을 발송하는 데 사용되는 비동기 API를 소유하고 있습니다. 이 회사는 Amazon API Gateway를 사용하여 API 프런트 엔드를 배포하고 Amazon DynamoDB를 호출하여 사용자 요청을 처리 마이크로서비스로 보내기 전에 저장하는 AWS Lambda 함수를 사용하고 있습니다.\n회사는 예산이 허용하는 한 많은 DynamoDB 처리량을 프로비저닝했지만 회사는 여전히 가용성 문제를 겪고 있으며 사용자 요청이 손실되고 있습니다.\n솔루션 설계자는 기존 사용자에게 영향을 주지 않고 이 문제를 해결하기 위해 무엇을 해야 합니까?",
      "eng": "A company owns an asynchronous API that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using Amazon API Gateway to deploy the API front end, and an AWS Lambda function that invokes Amazon DynamoDB to store user requests before dispatching them to the processing microservices.\nThe company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests.\nWhat should a solutions architect do to address this issue without impacting existing users?"
    },
    "choices": {
      "kor": {
        "A": "API 게이트웨이에서 서버 측 조절 제한을 사용하여 조절을 추가합니다.",
        "B": "DynamoDB Accelerator(DAX) 및 Lambda를 사용하여 DynamoDB에 대한 쓰기를 버퍼링합니다.",
        "C": "사용자 요청이 있는 테이블에 대해 DynamoDB에서 보조 인덱스를 생성합니다.",
        "D": "Amazon Simple Queue Service(Amazon SQS) 대기열과 Lambda를 사용하여 DynamoDB에 대한 쓰기를 버퍼링합니다."
      },
      "eng": {
        "A": "Add throttling on the API Gateway with server-side throttling limits.",
        "B": "Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.",
        "C": "Create a secondary index in DynamoDB for the table with the user requests.",
        "D": "Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB."
      }
    },
    "category": [
      "SQS"
    ],
    "subcategory": [
      "microservice",
      "asynchronous"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89087-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 123,
    "question": {
      "kor": "한 회사에 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션이 있습니다. 회사에는 종료를 수행하기 SSL 위해 각 인스턴스에 있는 자체 SSL 인증서가 있습니다.\n최근 트래픽이 증가했으며 운영 팀은 SSL 암호화 및 암호 해독으로 인해 웹 서버의 컴퓨팅 용량이 최대 한도에 도달했다고 판단했습니다.\n애플리케이션의 성능을 높이려면 솔루션 설계자가 무엇을 해야 합니까?",
      "eng": "A company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination.\nThere has been an increase in traffic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit.\nWhat should a solutions architect do to increase the application's performance?"
    },
    "choices": {
      "kor": {
        "A": "AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 각 인스턴스에 ACM 인증서를 설치합니다.",
        "B": "Amazon S3 버킷 생성 SSL 인증서를 S3 버킷으로 마이그레이션합니다. SSL 종료를 위해 버킷을 참조하도록 EC2 인스턴스를 구성합니다.",
        "C": "다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다.",
        "D": "SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. ACM의 SSL 인증서를 사용하는 HTTPS 리스너로 Application Load Balancer를 생성합니다."
      },
      "eng": {
        "A": "Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.",
        "B": "Create an Amazon S3 bucket Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.",
        "C": "Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.",
        "D": "Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85943-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 124,
    "question": {
      "kor": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 글로벌 웹 애플리케이션을 실행합니다. 애플리케이션은 Amazon Aurora에 데이터를 저장합니다. 회사는 재해 복구 솔루션을 만들어야 하며 최대 30분의 다운타임과 잠재적인 데이터 손실을 허용할 수 있습니다. 솔루션은 기본 인프라가 정상일 때 부하를 처리할 필요가 없습니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company runs a global web application on Amazon EC2 instances behind an Application Load Balancer. The application stores data in Amazon Aurora.\nThe company needs to create a disaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "필요한 인프라 요소가 있는 애플리케이션을 배치합니다. Amazon Route 53을 사용하여 활성-수동 장애 조치를 구성합니다. 두 번째 AWS 리전에서 Aurora 복제본을 생성합니다.",
        "B": "두 번째 AWS 리전에서 애플리케이션의 축소된 배포를 호스팅합니다. Amazon Route 53을 사용하여 활성-활성 장애 조치를 구성합니다. 두 번째 리전에서 Aurora 복제본을 생성합니다.",
        "C": "두 번째 AWS 리전에서 기본 인프라를 복제합니다. Amazon Route 53을 사용하여 활성-활성 장애 조치를 구성합니다. 최신 스냅샷에서 복원된 Aurora 데이터베이스를 생성합니다.",
        "D": "AWS Backup으로 데이터를 백업합니다. 백업을 사용하여 두 번째 AWS 리전에 필요한 인프라를 생성합니다. Amazon Route 53을 사용하여 활성-수동 장애 조치를 구성합니다. 두 번째 리전에서 Aurora 두 번째 기본 인스턴스를 생성합니다."
      },
      "eng": {
        "A": "Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.",
        "B": "Host a scaled-down deployment of the application in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora Replica in the second Region.",
        "C": "Replicate the primary infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora database that is restored from the latest snapshot.",
        "D": "Back up data with AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-passive failover. Create an Aurora second primary instance in the second Region."
      }
    },
    "category": [
      "Aurora"
    ],
    "subcategory": [
      "disater recovery"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95015-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 125,
    "question": {
      "kor": "회사는 중요한 애플리케이션에 대한 애플리케이션 로그 파일을 10년 동안 보관해야 합니다. 애플리케이션 팀은 문제 해결을 위해 지난 달의 로그에 정기적으로 액세스하지만 한 달이 지난 로그는 거의 액세스하지 않습니다. 애플리케이션은 매월 10TB 이상의 로그를 생성합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 옵션은 무엇입니까?",
      "eng": "A company needs to retain application log files for a critical application for 10 years. The application team regularly accesses logs from the past month for troubleshooting, but logs older than 1 month are rarely accessed. The application generates more than 10 TB of logs per month.\nWhich storage option meets these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "Amazon S3에 로그를 저장합니다. AWS Backup을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive로 이동합니다.",
        "B": "로그를 Amazon S3에 저장합니다. S3 수명 주기 정책을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive로 이동합니다.",
        "C": "Amazon CloudWatch Logs에 로그를 저장합니다. AWS Backup을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive로 이동합니다.",
        "D": "Amazon CloudWatch Logs에 로그를 저장합니다. Amazon S3 수명 주기 정책을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive로 이동합니다."
      },
      "eng": {
        "A": "Store the logs in Amazon S3. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.",
        "B": "Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.",
        "C": "Store the logs in Amazon CloudWatch Logs. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.",
        "D": "Store the logs in Amazon CloudWatch Logs. Use Amazon S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "lifecycle policies"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86864-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 126,
    "question": {
      "kor": "회사에는 다양한 런타임으로 분당 최대 800회 AWS Lambda 함수를 호출하는 이벤트 기반 애플리케이션이 있습니다. Lambda 함수는 Amazon Aurora MySQL DB 클러스터에 저장된 데이터에 액세스합니다. 회사는 사용자 활동이 증가함에 따라 연결 시간 초과를 인지하고 있습니다. 데이터베이스는 과부하의 징후를 보이지 않습니다. CPU, 메모리 및 디스크 액세스 메트릭이 모두 낮습니다.\n최소한의 운영 오버헤드로 이 문제를 해결하는 솔루션은 무엇입니까?",
      "eng": "A company has an event-driven application that invokes AWS Lambda functions up to 800 times each minute with varying runtimes. The Lambda functions access data that is stored in an Amazon Aurora MySQL DB cluster. The company is noticing connection timeouts as user activity increases. The database shows no signs of being overloaded. CPU, memory, and disk access metrics are all low.\nWhich solution will resolve this issue with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "더 많은 연결을 처리하려면 Aurora MySQL 노드의 크기를 조정하십시오. 데이터베이스 연결 시도에 대한 Lambda 함수의 재시도 논리를 구성합니다.",
        "B": "Redis용 Amazon ElastiCache를 설정하여 데이터베이스에서 일반적으로 읽은 항목을 캐시합니다. 읽기를 위해 ElastiCache에 연결하도록 Lambda 함수를 구성합니다.",
        "C": "Aurora 복제본을 리더 노드로 추가합니다. 라이터 엔드포인트가 아닌 DB 클러스터의 리더 엔드포인트에 연결하도록 Lambda 함수를 구성합니다.",
        "D": "Amazon RDS 프록시를 사용하여 프록시를 생성합니다. DB 클러스터를 대상 데이터베이스로 설정합니다. DB 클러스터가 아닌 프록시에 연결하도록 Lambda 함수를 구성합니다."
      },
      "eng": {
        "A": "Adjust the size of the Aurora MySQL nodes to handle more connections. Configure retry logic in the Lambda functions for attempts to connect to the database.",
        "B": "Set up Amazon ElastiCache for Redis to cache commonly read items from the database. Configure the Lambda functions to connect to ElastiCache for reads.",
        "C": "Add an Aurora Replica as a reader node. Configure the Lambda functions to connect to the reader endpoint of the DB cluster rather than to the writer endpoint.",
        "D": "Use Amazon RDS Proxy to create a proxy. Set the DB cluster as the target database. Configure the Lambda functions to connect to the proxy rather than to the DB cluster."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/84700-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 127,
    "question": {
      "kor": "솔루션 아키텍트가 회사의 고객 대면 애플리케이션을 설계하고 있습니다. 응용 프로그램의 데이터베이스는 일년 내내 명확하게 정의된 액세스 패턴을 가지며 연중 시간에 따라 가변적인 읽기 및 쓰기 횟수를 갖게 됩니다. 회사는 데이터베이스에 대한 감사 기록을 7일 동안 보관해야 합니다. RPO(복구 지점 목표)는 5시간 미만이어야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?",
      "eng": "A solutions architect is designing a customer-facing application for a company. The application's database will have a clearly defined access pattern throughout the year and will have a variable number of reads and writes that depend on the time of year. The company must retain audit records for the database for 7 days. The recovery point objective (RPO) must be less than 5 hours.\nWhich solution meets these requirements?"
    },
    "choices": {
      "kor": {
        "A": "Auto Scaling과 함께 Amazon DynamoDB 사용 온디맨드 백업 및 Amazon DynamoDB 스트림을 사용합니다.",
        "B": "Amazon Redshift를 사용하십시오. 동시성 확장을 구성합니다. 감사 로깅을 활성화합니다. 4시간마다 데이터베이스 스냅샷을 수행합니다.",
        "C": "프로비저닝된 IOPS와 함께 Amazon RDS 사용 데이터베이스 감사 매개변수 활성화 5시간마다 데이터베이스 스냅샷을 수행합니다.",
        "D": "Auto Scaling과 함께 Amazon Aurora MySQL을 사용합니다. 데이터베이스 감사 매개변수를 활성화하십시오."
      },
      "eng": {
        "A": "Use Amazon DynamoDB with auto scaling Use on-demand backups and Amazon DynamoDB Streams.",
        "B": "Use Amazon Redshift. Configure concurrency scaling. Activate audit logging. Perform database snapshots every 4 hours.",
        "C": "Use Amazon RDS with Provisioned IOPS Activate the database auditing parameter Perform database snapshots every 5 hours.",
        "D": "Use Amazon Aurora MySQL with auto scaling. Activate the database auditing parameter."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/111115-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 128,
    "question": {
      "kor": "회사는 단일 Amazon EC2 온디맨드 인스턴스에서 웹 사이트 분석 애플리케이션을 호스팅합니다. 분석 소프트웨어는 PHP로 작성되었으며 MySQL 데이터베이스를 사용합니다. 분석 소프트웨어, PHP를 제공하는 웹 서버 및 데이터베이스 서버는 모두 EC2 인스턴스에서 호스팅됩니다. 애플리케이션이 사용량이 많은 시간 동안 성능 저하의 징후를 보이고 있으며 5xx 오류를 표시하고 있습니다. 회사는 애플리케이션을 원활하게 확장해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a website analytics application on a single Amazon EC2 On-Demand Instance. The analytics software is written in PHP and uses a MySQL database. The analytics software, the web server that provides PHP, and the database server are all hosted on the EC2 instance. The application is showing signs of performance degradation during busy times and is presenting 5xx errors. The company needs to make the application scale seamlessly.\nWhich solution will meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. AMI를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Application Load Balancer를 사용하여 각 EC2 인스턴스에 로드를 분산합니다.",
        "B": "데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. AMI를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Amazon Route 53 가중 라우팅을 사용하여 2개의 EC2 인스턴스에 로드를 분산합니다.",
        "C": "데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. EC2 인스턴스를 중지하고 인스턴스 유형을 변경하는 AWS Lambda 함수를 생성합니다. CPU 사용률이 75%를 초과하면 Lambda 함수를 호출하는 Amazon CloudWatch 경보를 생성합니다.",
        "D": "데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. 시작 템플릿에 AMI를 적용합니다. 시작 템플릿으로 Auto",
        "E": "Scaling 그룹 생성 스팟 플릿을 사용하도록 시작 템플릿을 구성합니다. Application Load Balancer를 Auto Scaling 그룹에 연결합니다."
      },
      "eng": {
        "A": "Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load to each EC2 instance.",
        "B": "Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances.",
        "C": "Migrate the database to an Amazon Aurora MySQL DB instance. Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization surpasses 75%.",
        "D": "Migrate the database to an Amazon Aurora MySQL DB instance. Create an AMI of the web application. Apply the AMI to a launch template. Create an Auto Scaling group with the launch template. Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group."
      }
    },
    "category": [
      "ASG"
    ],
    "subcategory": [
      "Spot Fleet",
      "cost-effective",
      "launch template"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86474-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 129,
    "question": {
      "kor": "게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 실행되며 UDP 기반 트래픽만 지원합니다. 회사는 최상의 사용자 경험을 제공하기 위해 프런트엔드 계층이 필요합니다. 해당 계층은 대기 시간이 짧아야 하고 트래픽을 가장 가까운 엣지 로케이션으로 라우팅하고 애플리케이션 엔드포인트에 진입하기 위한 정적 IP 주소를 제공해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A gaming company is designing a highly available architecture. The application runs on a modified Linux kernel and supports only UDP-based traffic. The company needs the front-end tier to provide the best possible user experience. That tier must have low latency, route traffic to the nearest edge location, and provide static IP addresses for entry into the application endpoints.\nWhat should a solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "요청을 Application Load Balancer로 전달하도록 Amazon Route 53을 구성합니다. AWS Application Auto Scaling에서 애플리케이션에 AWS Lambda를 사용합니다.",
        "B": "요청을 Network Load Balancer로 전달하도록 Amazon CloudFront를 구성합니다. AWS Application Auto Scaling 그룹의 애플리케이션에 AWS Lambda를 사용합니다.",
        "C": "요청을 Network Load Balancer로 전달하도록 AWS Global Accelerator를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다.",
        "D": "요청을 Application Load Balancer로 전달하도록 Amazon API Gateway를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다."
      },
      "eng": {
        "A": "Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.",
        "B": "Configure Amazon CloudFront to forward requests to a Network Load Balancer. Use AWS Lambda for the application in an AWS Application Auto Scaling group.",
        "C": "Configure AWS Global Accelerator to forward requests to a Network Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.",
        "D": "Configure Amazon API Gateway to forward requests to an Application Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group."
      }
    },
    "category": [
      "Global Accelerator"
    ],
    "subcategory": [
      "availability",
      "protocol",
      "static IP addresses"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86667-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 130,
    "question": {
      "kor": "회사는 AWS 클라우드를 사용하여 기존 애플리케이션의 가용성과 탄력성을 높이려고 합니다. 애플리케이션의 현재 버전은 회사의 데이터 센터에 상주합니다. 예기치 않은 정전으로 인해 데이터베이스 서버가 충돌한 후 애플리케이션에서 최근 데이터 손실이 발생했습니다.\n회사는 단일 실패 지점을 방지하는 솔루션이 필요합니다. 솔루션은 애플리케이션에 사용자 요구에 맞게 확장할 수 있는 기능을 제공해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to use the AWS Cloud to make an existing application highly available and resilient. The current version of the application resides in the company's data center. The application recently experienced data loss after a database server crashed because of an unexpected power outage.\nThe company needs a solution that avoids any single points of failure. The solution must give the application the ability to scale to meet user demand.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 배포합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 사용합니다.",
        "B": "단일 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 배포합니다. EC2 인스턴스에 데이터베이스를 배포합니다. EC2 자동 복구를 활성화합니다.",
        "C": "여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 배포합니다. 단일 가용 영역에서 읽기 전용 복제본이 있는 Amazon RDS DB 인스턴스를 사용합니다. 기본 DB 인스턴스가 실패할 경우 읽기 전용 복제본을 승격하여 기본 DB 인스턴스를 교체하십시오.",
        "D": "여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 배포합니다. 여러 가용 영역에 걸쳐 EC2 인스턴스에 기본 및 보조 데이터베이스 서버를 배포합니다. Amazon Elastic Block Store(Amazon EBS) 다중 연결을 사용하여 인스턴스 간에 공유 스토리지를 생성합니다."
      },
      "eng": {
        "A": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon RDS DB instance in a Multi-AZ configuration.",
        "B": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group in a single Availability Zone. Deploy the database on an EC2 instance. Enable EC2 Auto Recovery.",
        "C": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon RDS DB instance with a read replica in a single Availability Zone. Promote the read replica to replace the primary DB instance if the primary DB instance fails.",
        "D": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Deploy the primary and secondary database servers on EC2 instances across multiple Availability Zones. Use Amazon Elastic Block Store (Amazon EBS) Multi-Attach to create shared storage between the instances."
      }
    },
    "category": [
      "Availability"
    ],
    "subcategory": [
      "ASG",
      "Multi-AZ configuration"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102170-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 131,
    "question": {
      "kor": "애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40% 또는 거의 40%일 때 최상의 성능을 발휘합니다.\n솔루션 설계자는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까?",
      "eng": "An application runs on Amazon EC2 instances across multiple Availability Zonas. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%.\nWhat should a solutions architect do to maintain the desired performance across all instances in the group?"
    },
    "choices": {
      "kor": {
        "A": "간단한 조정 정책을 사용하여 Auto Scaling 그룹을 동적으로 조정하십시오.",
        "B": "대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다.",
        "C": "AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다.",
        "D": "예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다."
      },
      "eng": {
        "A": "Use a simple scaling policy to dynamically scale the Auto Scaling group.",
        "B": "Use a target tracking policy to dynamically scale the Auto Scaling group.",
        "C": "Use an AWS Lambda function ta update the desired Auto Scaling group capacity.",
        "D": "Use scheduled scaling actions to scale up and scale down the Auto Scaling group."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86659-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 132,
    "question": {
      "kor": "한 회사에서 인기 있는 노래 클립으로 만든 벨소리를 판매합니다. 벨소리가 포함된 파일은 Amazon S3 Standard에 저장되며 크기는 128KB 이상입니다. 회사에는 수백만 개의 파일이 있지만 90일보다 오래된 벨소리의 경우 다운로드가 자주 발생하지 않습니다. 회사는 사용자가 가장 많이 액세스하는 파일을 쉽게 사용할 수 있도록 유지하면서 스토리지 비용을 절감해야 합니다.\n이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 회사는 어떤 조치를 취해야 합니까?",
      "eng": "A company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 128 KB in size. The company has millions of files, but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users.\nWhich action should the company take to meet these requirements MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "객체의 초기 스토리지 계층에 대해 S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지를 구성합니다.",
        "B": "파일을 S3 Intelligent-Tiering으로 이동하고 90일 후에 개체를 더 저렴한 스토리지 계층으로 이동하도록 구성합니다.",
        "C": "개체를 관리하도록 S3 인벤토리를 구성하고 90일 후에 개체를 S3 Standard-Infrequent Access(S3 Standard-1A)로 이동합니다.",
        "D": "90일 후에 객체를 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-1A)로 이동하는 S3 수명 주기 정책을 구현합니다."
      },
      "eng": {
        "A": "Configure S3 Standard-Infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects.",
        "B": "Move the files to S3 Intelligent-Tiering and configure it to move objects to a less expensive storage tier after 90 days.",
        "C": "Configure S3 inventory to manage objects and move them to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days.",
        "D": "Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "Storage Class",
      "lifecycle policies"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86933-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 133,
    "question": {
      "kor": "대규모 미디어 회사는 AWS에서 웹 애플리케이션을 호스팅합니다. 회사는 전 세계 사용자가 파일에 안정적으로 액세스할 수 있도록 기밀 미디어 파일 캐싱을 시작하려고 합니다. 콘텐츠는 Amazon S3 버킷에 저장됩니다. 회사는 요청이 지리적으로 발생한 위치에 관계없이 콘텐츠를 신속하게 제공해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A large media company hosts a web application on AWS. The company wants to start caching confidential media files so that users around the world will have reliable access to the files. The content is stored in Amazon S3 buckets. The company must deliver the content quickly, regardless of where the requests originate geographically.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS DataSync를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다.",
        "B": "AWS Global Accelerator를 배포하여 S3 버킷을 웹 애플리케이션에 연결합니다.",
        "C": "Amazon CloudFront를 배포하여 S3 버킷을 CloudFront 에지 서버에 연결합니다.",
        "D": "Amazon Simple Queue Service(Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다."
      },
      "eng": {
        "A": "Use AWS DataSync to connect the S3 buckets to the web application.",
        "B": "Deploy AWS Global Accelerator to connect the S3 buckets to the web application.",
        "C": "Deploy Amazon CloudFront to connect the S3 buckets to CloudFront edge servers.",
        "D": "Use Amazon Simple Queue Service (Amazon SQS) to connect the S3 buckets to the web application."
      }
    },
    "category": [
      "CloudFront"
    ],
    "subcategory": [
      "caching",
      "origin"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86795-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 134,
    "question": {
      "kor": "회사에는 데이터베이스에 주문을 작성하고 지불을 처리하기 위해 서비스를 호출하는 전자 상거래 체크아웃 워크플로우가 있습니다. 사용자는 체크아웃 프로세스 중에 시간 초과를 경험하고 있습니다. 사용자가 체크아웃 양식을 다시 제출하면 동일한 원하는 거래에 대해 여러 고유 주문이 생성됩니다.\n여러 주문 생성을 방지하기 위해 솔루션 설계자는 이 워크플로우를 어떻게 리팩터링해야 합니까?",
      "eng": "A company has an ecommerce checkout workflow that writes an order to a database and calls a service to process the payment. Users are experiencing timeouts during the checkout process. When users resubmit the checkout form, multiple unique orders are created for the same desired transaction.\nHow should a solutions architect refactor this workflow to prevent the creation of multiple orders?"
    },
    "choices": {
      "kor": {
        "A": "Amazon Kinesis Data Firehose로 주문 메시지를 보내도록 웹 애플리케이션을 구성합니다. Kinesis Data Firehose에서 메시지를 검색하고 주문을 처리하도록 결제 서비스를 설정합니다.",
        "B": "로깅된 애플리케이션 경로 요청을 기반으로 AWS Lambda 함수를 호출하기 위해 AWS CloudTrail에서 규칙을 생성합니다. Lambda를 사용하여 데이터베이스를 쿼리하고 결제 서비스를 호출하고 주문 정보를 전달합니다.",
        "C": "데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple Notification Service(Amazon SNS)로 보냅니다. Amazon SNS를 폴링하고 메시지를 검색하고 주문을 처리하도록 결제 서비스를 설정합니다.",
        "D": "데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열로 보냅니다. 메시지를 검색하고 주문을 처리하도록 결제 서비스를 설정합니다. 대기열에서 메시지를 삭제합니다."
      },
      "eng": {
        "A": "Configure the web application to send an order message to Amazon Kinesis Data Firehose. Set the payment service to retrieve the message from Kinesis Data Firehose and process the order.",
        "B": "Create a rule in AWS CloudTrail to invoke an AWS Lambda function based on the logged application path request. Use Lambda to query the database, call the payment service, and pass in the order information.",
        "C": "Store the order in the database. Send a message that includes the order number to Amazon Simple Notification Service (Amazon SNS). Set the payment service to poll Amazon SNS, retrieve the message, and process the order.",
        "D": "Store the order in the database. Send a message that includes the order number to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the payment service to retrieve the message and process the order. Delete the message from the queue."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/95026-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 135,
    "question": {
      "kor": "한 온라인 소매 회사는 5천만 명 이상의 활성 고객을 보유하고 있으며 매일 25,000건 이상의 주문을 받습니다. 회사는 고객의 구매 데이터를 수집하고 이 데이터를 Amazon S3에 저장합니다. 추가 고객 데이터는 Amazon RDS에 저장됩니다.\n회사는 팀이 분석을 수행할 수 있도록 다양한 팀에서 모든 데이터를 사용할 수 있도록 하려고 합니다. 솔루션은 데이터에 대한 세분화된 권한을 관리하는 기능을 제공하고 운영 오버헤드를 최소화해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "An online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS.\nThe company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "구매 데이터를 마이그레이션하여 Amazon RDS에 직접 씁니다. RDS 액세스 제어를 사용하여 액세스를 제한하십시오.",
        "B": "Amazon RDS에서 Amazon S3로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. AWS Glue 크롤러를 생성합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. S3 정책을 사용하여 액세스를 제한하십시오.",
        "C": "AWS Lake Formation을 사용하여 데이터 레이크를 생성합니다. Amazon RDS에 대한 AWS Glue JDBC 연결을 생성합니다. Lake Formation에 S3 버킷을 등록합니다. Lake Formation 액세스 제어를 사용하여 액세스를 제한하십시오.",
        "D": "Amazon Redshift 클러스터를 생성합니다. Amazon S3 및 Amazon RDS에서 Amazon Redshift로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. Amazon Redshift 액세스 제어를 사용하여 액세스를 제한하십시오."
      },
      "eng": {
        "A": "Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access.",
        "B": "Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access.",
        "C": "Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.",
        "D": "Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 136,
    "question": {
      "kor": "회사에서 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션하고 있습니다. 마이그레이션 설계 요구 사항의 일부로 솔루션 설계자는 인프라 지표 경보를 구현해야 합니다. 짧은 시간 동안 CPU 사용률이 50% 이상으로 증가하면 회사에서 조치를 취할 필요가 없습니다. 그러나 CPU 사용률이 50% 이상으로 증가하고 디스크의 읽기 IOPS가 동시에 높은 경우 회사는 가능한 한 빨리 조치를 취해야 합니다. 솔루션 설계자는 또한 잘못된 경보를 줄여야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is migrating an application from on-premises servers to Amazon EC2 instances. As part of the migration design requirements, a solutions architect must implement infrastructure metric alarms. The company does not need to take action if CPU utilization increases to more than 50% for a short burst of time. However, if the CPU utilization increases to more than 50% and read IOPS on the disk are high at the same time, the company needs to act as soon as possible. The solutions architect also must reduce false alarms.\nWhat should the solutions architect do to meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "가능한 경우 Amazon CloudWatch 복합 경보를 생성합니다.",
        "B": "지표를 시각화하고 문제에 신속하게 대응하기 위해 Amazon CloudWatch 대시보드를 생성합니다.",
        "C": "Amazon CloudWatch Synthetics 카나리아를 생성하여 애플리케이션을 모니터링하고 경보를 울립니다.",
        "D": "가능한 경우 여러 지표 임계값이 있는 단일 Amazon CloudWatch 지표 경보를 생성합니다."
      },
      "eng": {
        "A": "Create Amazon CloudWatch composite alarms where possible.",
        "B": "Create Amazon CloudWatch dashboards to visualize the metrics and react to issues quickly.",
        "C": "Create Amazon CloudWatch Synthetics canaries to monitor the application and raise an alarm.",
        "D": "Create single Amazon CloudWatch metric alarms with multiple metric thresholds where possible."
      }
    },
    "category": [
      "CloudWatch"
    ],
    "subcategory": [
      "composite alarms"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86034-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 137,
    "question": {
      "kor": "회사는 AWS에서 워크로드를 실행합니다. 회사는 외부 공급자의 서비스에 연결해야 합니다. 서비스는 공급자의 VPC에서 호스팅됩니다. 회사의 보안 팀에 따르면 연결은 비공개여야 하며 대상 서비스로 제한되어야 합니다. 연결은 회사의 VPC에서만 시작되어야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company runs workloads on AWS. The company needs to connect to a service from an external provider. The service is hosted in the provider's VPC.\nAccording to the company’s security team, the connectivity must be private and must be restricted to the target service. The connection must be initiated only from the company’s VPC.\nWhich solution will mast these requirements?"
    },
    "choices": {
      "kor": {
        "A": "회사의 VPC와 공급자의 VPC 간에 VPC 피어링 연결을 생성합니다. 대상 서비스에 연결하도록 라우팅 테이블을 업데이트합니다.",
        "B": "공급자에게 VPC에 가상 프라이빗 게이트웨이를 생성하도록 요청하십시오. AWS PrivateLink를 사용하여 대상 서비스에 연결합니다.",
        "C": "대상 서비스에 연결하기 위해 회사의 VPUpdate 라우팅 테이블의 퍼블릭 서브넷에 NAT 게이트웨이를 생성합니다.",
        "D": "공급자에게 대상 서비스에 대한 VPC 끝점을 생성하도록 요청하십시오. AWS PrivateLink를 사용하여 대상 서비스에 연결합니다."
      },
      "eng": {
        "A": "Create a VPC peering connection between the company's VPC and the provider's VPC. Update the route table to connect to the target service.",
        "B": "Ask the provider to create a virtual private gateway in its VPC. Use AWS PrivateLink to connect to the target service.",
        "C": "Create a NAT gateway in a public subnet of the company’s VPUpdate the route table to connect to the target service.",
        "D": "Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85994-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 138,
    "question": {
      "kor": "회사는 온프레미스에서 다중 계층 웹 애플리케이션을 실행하고 있습니다. 웹 애플리케이션은 컨테이너화되어 있으며 사용자 레코드가 포함된 PostgreSQL 데이터베이스에 연결된 여러 Linux 호스트에서 실행됩니다. 인프라 및 용량 계획을 유지 관리하는 운영 오버헤드는 회사의 성장을 제한하고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다.\n이를 달성하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A company is running a multi-tier web application on premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company's growth. A solutions architect must improve the application's infrastructure.\nWhich combination of actions should the solutions architect take to accomplish this? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.",
        "B": "Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.",
        "C": "웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다.",
        "D": "웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache를 설정합니다.",
        "E": "Amazon Elastic Container Service(Amazon ECS)를 사용하여 AWS Fargate에서 호스팅할 웹 애플리케이션을 마이그레이션합니다."
      },
      "eng": {
        "A": "Migrate the PostgreSQL database to Amazon Aurora.",
        "B": "Migrate the web application to be hosted on Amazon EC2 instances.",
        "C": "Set up an Amazon CloudFront distribution for the web application content.",
        "D": "Set up Amazon ElastiCache between the web application and the PostgreSQL database.",
        "E": "Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86658-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A",
      "E"
    ]
  },
  {
    "idx": 139,
    "question": {
      "kor": "신입 사원이 배포 엔지니어로 회사에 합류했습니다. 배포 엔지니어는 AWS CloudFormation 템플릿을 사용하여 여러 AWS 리소스를 생성합니다. 솔루션 설계자는 배포 엔지니어가 최소\n권한 원칙에 따라 작업 활동을 수행하기를 원합니다.\n이 목표를 달성하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)",
      "eng": "A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege.\nWhich combination of actions should the solutions architect take to accomplish this goal? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "배포 엔지니어가 AWS CloudFormation 스택 작업을 수행하기 위해 AWS 계정 루트 사용자 자격 증명을 사용하도록 합니다.",
        "B": "배포 엔지니어를 위한 새 IAM 사용자를 생성하고 PowerUsers IAM 정책이 연결된 그룹에 IAM 사용자를 추가합니다.",
        "C": "배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AdministratorAccess IAM 정책이 연결된 그룹에 IAM 사용자를 추가합니다.",
        "D": "배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AWS CloudFormation 작업만 허용하는 IAM 정책이 있는 그룹에 IAM 사용자를 추가합니다.",
        "E": "배포 엔지니어를 위한 IAM 역할을 생성하여 해당 IAM 역할을 사용하여 AWS CloudFormation 스택 및 시작 스택에 특정한 권한을 명시적으로 정의합니다."
      },
      "eng": {
        "A": "Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.",
        "B": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.",
        "C": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached.",
        "D": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.",
        "E": "Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/102155-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D",
      "E"
    ]
  },
  {
    "idx": 140,
    "question": {
      "kor": "회사에서 애플리케이션을 서버리스 솔루션으로 이동하려고 합니다. 서버리스 솔루션은 SL을 사용하여 기존 및 신규 데이터를 분석해야 합니다. 회사는 데이터를 Amazon S3 버킷에 저장합니다. 데이터는 암호화가 필요하며 다른 AWS 리전에 복제되어야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to move its application to a serverless solution. The serverless solution needs to analyze existing and new data by using SL. The company stores the data in an Amazon S3 bucket. The data requires encryption and must be replicated to a different AWS Region.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "새 S3 버킷을 생성합니다. 새 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.",
        "B": "새 S3 버킷을 생성합니다. 새 S3 버킷에 데이터를 로드합니다. S3 CRR(Cross-Region Replication)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon RDS를 사용하여 데이터를 쿼리합니다.",
        "C": "기존 S3 버킷에 데이터를 로드합니다. S3 CRR(Cross-Region Replication)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.",
        "D": "기존 S3 버킷에 데이터를 로드합니다. S3 CRR(Cross-Region Replication)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. Amazon RDS를 사용하여 데이터를 쿼리합니다."
      },
      "eng": {
        "A": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data.",
        "B": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data.",
        "C": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon Athena to query the data.",
        "D": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon RDS to query the data."
      }
    },
    "category": [
      "S3"
    ],
    "subcategory": [
      "encryption at rest",
      "replication"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85993-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 141,
    "question": {
      "kor": "회사에서 Amazon ECS를 사용하여 애플리케이션을 실행합니다. 애플리케이션은 원본 이미지의 크기가 조정된 버전을 생성한 다음 Amazon S3 API를 호출하여 크기가 조정된 이미지를\nAmazon S3에 저장합니다.\n솔루션 설계자는 애플리케이션이 에 액세스할 Amazon S3 권한이 있는지 어떻게 확인할 수 있습니까?",
      "eng": "A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3.\nHow can a solutions architect ensure that the application has permission to access Amazon S3?"
    },
    "choices": {
      "kor": {
        "A": "Amazon ECS에서 읽기/쓰기 액세스를 허용하도록 AWS IAM에서 S3 역할을 업데이트한 다음 컨테이너를 다시 시작합니다.",
        "B": "S3 권한이 있는 IAM 역할을 생성한 다음 작업 정의에서 해당 역할을 taskRoleArn으로 지정합니다.",
        "C": "Amazon ECS에서 Amazon S3로의 액세스를 허용하는 보안 그룹을 생성하고 ECS 클러스터에서 사용하는 시작 구성을 업데이트합니다.",
        "D": "S3 권한이 있는 IAM 사용자를 만든 다음 이 계정으로 로그인한 상태에서 ECS 클러스터에 대한 Amazon EC2 인스턴스를 다시 시작합니다."
      },
      "eng": {
        "A": "Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.",
        "B": "Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.",
        "C": "Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.",
        "D": "Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87648-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B"
    ]
  },
  {
    "idx": 142,
    "question": {
      "kor": "회사에 소프트웨어 엔지니어링에 사용되는 AWS 계정이 있습니다. AWS 계정은 한 쌍의 AWS Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 액세스할 수 있습니다. 모든 비 VPC 트래픽은 가상 프라이빗 게이트웨이로 라우팅됩니다.\n개발팀은 최근 콘솔을 통해 AWS Lambda 함수를 생성했습니다. 개발 팀은 함수가 회사 데이터 센터의 프라이빗 서브넷에서 실행되는 데이터베이스에 액세스할 수 있도록 허용해야 합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company has an AWS account used for software engineering. The AWS account has access to the company’s on-premises data center through a pair of AWS Direct Connect connections. All non-VPC traffic routes to the virtual private gateway.\nA development team recently created an AWS Lambda function through the console. The development team needs to allow the function to access a database that runs in a private subnet in the company’s data center.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "적절한 보안 그룹을 사용하여 VPC에서 실행되도록 Lambda 함수를 구성합니다.",
        "B": "AWS에서 데이터 센터로 VPN 연결을 설정합니다. VPN을 통해 Lambda 함수의 트래픽을 라우팅합니다.",
        "C": "Lambda 함수가 Direct Connect를 통해 온프레미스 데이터 센터에 액세스할 수 있도록 VPC의 라우팅 테이블을 업데이트합니다.",
        "D": "탄력적 IP 주소를 생성합니다. 탄력적 네트워크 인터페이스 없이 탄력적 IP 주소를 통해 트래픽을 보내도록 Lambda 함수를 구성합니다."
      },
      "eng": {
        "A": "Configure the Lambda function to run in the VPC with the appropriate security group.",
        "B": "Set up a VPN connection from AWS to the data center. Route the traffic from the Lambda function through the VPN.",
        "C": "Update the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect.",
        "D": "Create an Elastic IP address. Configure the Lambda function to send traffic through the Elastic IP address without an elastic network interface."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87534-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 143,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 이동해야 합니다. 회사는 API 호출 및 데이터가 공용 인터넷 경로를 통해 라우팅되지 않도록 해야 합니다. EC2 인스턴스만 S3 버킷에 데이터를 업로드할 수 있는 액세스 권한을 가질 수 있습니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "EC2 인스턴스가 있는 서브넷에서 Amazon S3에 대한 인터페이스 VPC 엔드포인트를 생성합니다. 리소스 정책을 S3 버킷에 연결하여 EC2 인스턴스의 IAM 역할만 액세스하도록 허용합니다.",
        "B": "EC2 인스턴스가 있는 가용 영역에서 Amazon S3에 대한 게이트웨이 VPC 엔드포인트를 생성합니다. 엔드포인트에 적절한 보안 그룹을 연결합니다. 리소스 정책을 S3 버킷에 연결하여 EC2 인스턴스의 IAM 역할만 액세스하도록 허용합니다.",
        "C": "EC2 인스턴스 내부에서 nslookup 도구를 실행하여 S3 버킷 서비스 API 엔드포인트의 프라이빗 IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 EC2 인스턴스에 제공하기 위해 VPC 경로 테이블에 경로를 생성합니다. 리소스 정책을 S3 버킷에 연결하여 EC2 인스턴스의 IAM 역할만 액세스하도록 허용합니다.",
        "D": "AWS에서 제공하고 공개적으로 사용 가능한 ip-ranges.json 파일을 사용하여 S3 버킷 서비스 API 엔드포인트의 프라이빗 IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 EC2 인스턴스에 제공하기 위해 VPC 경로 테이블에 경로를 생성합니다. 리소스 정책을 S3 버킷에 연결하여 EC2 인스턴스의 IAM 역할만 액세스하도록 허용합니다."
      },
      "eng": {
        "A": "Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
        "B": "Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
        "C": "Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
        "D": "Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89088-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 144,
    "question": {
      "kor": "한 병원에서 대규모 기록 기록 수집을 위한 디지털 사본을 만들고자 합니다. 병원은 매일 수백 개의 새로운 문서를 계속 추가할 것입니다. 병원의 데이터 팀이 문서를 스캔하고 문서를 AWS 클라우드에 업로드합니다.\n솔루션 설계자는 애플리케이션이 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 분석하고, 의료 정보를 추출하고, 문서를 저장하는 솔루션을 구현해야 합니다. 솔루션은 확장성과 운영\n효율성을 극대화해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (두 가지를 선택하세요.)",
      "eng": "A hospital wants to create digital copies for its large collection of historical written records. The hospital will continue to add hundreds of new documents each day. The hospital’s data team will scan the documents and will upload the documents to the AWS Cloud.\nA solutions architect must implement a solution to analyze the documents, extract the medical information, and store the documents so that an application can run SQL queries on the data. The solution must maximize scalability and operational efficiency.\nWhich combination of steps should the solutions architect take to meet these requirements? (Choose two.)"
    },
    "choices": {
      "kor": {
        "A": "MySQL 데이터베이스를 실행하는 Amazon EC2 인스턴스에 문서 정보를 씁니다.",
        "B": "문서 정보를 Amazon S3 버킷에 씁니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.",
        "C": "Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 스캔한 파일을 처리하고 의료 정보를 추출하는 사용자 지정 애플리케이션을 실행합니다.",
        "D": "새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon Rekognition을 사용하여 문서를 원시 텍스트로 변환합니다. Amazon Transcribe Medical을 사용하여 텍스트에서 관련 의료 정보를 감지하고 추출합니다.",
        "E": "새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon Textract를 사용하여 문서를 원시 텍스트로 변환합니다. Amazon Comprehend Medical을 사용하여 텍스트에서 관련 의료 정보를 감지하고 추출합니다."
      },
      "eng": {
        "A": "Write the document information to an Amazon EC2 instance that runs a MySQL database.",
        "B": "Write the document information to an Amazon S3 bucket. Use Amazon Athena to query the data.",
        "C": "Create an Auto Scaling group of Amazon EC2 instances to run a custom application that processes the scanned files and extracts the medical information.",
        "D": "Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Rekognition to convert the documents to raw text. Use Amazon Transcribe Medical to detect and extract relevant medical information from the text.",
        "E": "Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Textract to convert the documents to raw text. Use Amazon Comprehend Medical to detect and extract relevant medical information from the text."
      }
    },
    "category": [
      "AI",
      "S3"
    ],
    "subcategory": [
      "Textract",
      "Athena",
      "Comprehend Medical"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89133-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "B",
      "E"
    ]
  },
  {
    "idx": 145,
    "question": {
      "kor": "회사는 최근 웹 공격으로 인해 공용 웹 애플리케이션의 보안에 대해 우려하고 있습니다. 애플리케이션은 Application Load Balancer(ALB)를 사용합니다. 솔루션 설계자는 애플리케이션에 대한 DDoS 공격의 위험을 줄여야 합니다.\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
      "eng": "A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load Balancer (ALB).\nA solutions architect must reduce the risk of DDoS attacks against the application.\nWhat should the solutions architect do to meet this requirement?"
    },
    "choices": {
      "kor": {
        "A": "ALB에 Amazon Inspector 에이전트를 추가합니다.",
        "B": "공격을 방지하도록 Amazon Macie를 구성합니다.",
        "C": "공격을 방지하려면 AWS Shield Advanced를 활성화하십시오.",
        "D": "ALB를 모니터링하도록 Amazon GuardDuty를 구성합니다."
      },
      "eng": {
        "A": "Add an Amazon Inspector agent to the ALB.",
        "B": "Configure Amazon Macie to prevent attacks.",
        "C": "Enable AWS Shield Advanced to prevent attacks.",
        "D": "Configure Amazon GuardDuty to monitor the ALB."
      }
    },
    "category": [
      "DDoS"
    ],
    "subcategory": [
      "Shield"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87526-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 146,
    "question": {
      "kor": "회사에서 Amazon 머신 이미지(AMI)를 관리하려고 합니다. 회사는 현재 AMI가 생성된 동일한 AWS 리전에 AMI를 복사합니다. 회사는 AWS API 호출을 캡처하고 회사 계정 내에서 Amazon EC2 CreateImage API 작업이 호출될 때마다 알림을 보내는 애플리케이션을 설계해야 합니다.\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to manage Amazon Machine Images (AMIs). The company currently copies AMIs to the same AWS Region where the AMIs were created.\nThe company needs to design an application that captures AWS API calls and sends alerts whenever the Amazon EC2 CreateImage API operation is called within the company’s account.\nWhich solution will meet these requirements with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "AWS CloudTrail 로그를 쿼리하고 CreateImage API 호출이 감지되면 알림을 보내는 AWS Lambda 함수를 생성합니다.",
        "B": "업데이트된 로그가 Amazon S3로 전송될 때 발생하는 Amazon Simple Notification Service(Amazon SNS) 알림으로 AWS CloudTrail을 구성합니다. Amazon Athena를 사용하여 새 테이블을 생성하고 API 호출이 감지되면 CreateImage에서 쿼리합니다.",
        "C": "CreateImage API 호출에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. CreateImage API 호출이 감지되면 알림을 보내도록 대상을 Amazon Simple Notification Service(Amazon SNS) 주제로 구성합니다.",
        "D": "Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 AWS CloudTrail 로그의 대상으로 구성합니다. CreateImage API 호출이 감지되면 Amazon Simple Notification Service(Amazon SNS) 주제에 알림을 보내는 AWS Lambda 함수를 생성합니다."
      },
      "eng": {
        "A": "Create an AWS Lambda function to query AWS CloudTrail logs and to send an alert when a CreateImage API call is detected.",
        "B": "Configure AWS CloudTrail with an Amazon Simple Notification Service (Amazon SNS) notification that occurs when updated logs are sent to Amazon S3. Use Amazon Athena to create a new table and to query on CreateImage when an API call is detected.",
        "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the CreateImage API call. Configure the target as an Amazon Simple Notification Service (Amazon SNS) topic to send an alert when a CreateImage API call is detected.",
        "D": "Configure an Amazon Simple Queue Service (Amazon SQS) FIFO queue as a target for AWS CloudTrail logs. Create an AWS Lambda function to send an alert to an Amazon Simple Notification Service (Amazon SNS) topic when a CreateImage API call is detected."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/89086-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "C"
    ]
  },
  {
    "idx": 147,
    "question": {
      "kor": "회사는 Amazon CloudWatch Logs 로그 그룹에 애플리케이션 로그를 저장합니다. 새로운 정책에 따라 회사는 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 모든 애플리케이션 로그를 저장해야 합니다.\n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company stores its application logs in an Amazon CloudWatch Logs log group. A new policy requires the company to store all application logs in Amazon OpenSearch Service (Amazon Elasticsearch Service) in near-real time.\nWhich solution will meet this requirement with the LEAST operational overhead?"
    },
    "choices": {
      "kor": {
        "A": "로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍하도록 CloudWatch Logs 구독을 구성합니다.",
        "B": "AWS Lambda 함수를 생성합니다. 로그 그룹을 사용하여 함수를 호출하여 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 로그를 기록합니다.",
        "C": "Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. 전송 스트림 소스로 로그 그룹을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 전송 스트림의 대상으로 구성합니다.",
        "D": "각 애플리케이션 서버에 Amazon Kinesis Agent를 설치하고 구성하여 Amazon Kinesis Data Streams에 로그를 전달합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)에 로그를 전달하도록 Kinesis Data Streams를 구성합니다."
      },
      "eng": {
        "A": "Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).",
        "B": "Create an AWS Lambda function. Use the log group to invoke the function to write the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).",
        "C": "Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery streams sources. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination.",
        "D": "Install and configure Amazon Kinesis Agent on each application server to deliver the logs to Amazon Kinesis Data Streams. Configure Kinesis Data Streams to deliver the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service)."
      }
    },
    "category": [],
    "subcategory": [],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/85802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "A"
    ]
  },
  {
    "idx": 148,
    "question": {
      "kor": "회사는 Amazon EC2 인스턴스와 Amazon RDS에서 2계층 애플리케이션을 호스팅합니다. 응용 프로그램의 요구 사항은 시간에 따라 다릅니다. 업무 시간 이후와 주말에는 부하가 최소화 됩니다. EC2 인스턴스는 최소 2개의 인스턴스와 최대 5개의 인스턴스로 구성된 EC2 Auto Scaling 그룹에서 실행됩니다. 응용 프로그램은 항상 사용할 수 있어야 하지만 회사는 전체 비용에 대해 우려하고 있습니다.\n비용 효율적으로 가용성 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
      "eng": "A company hosts a two-tier application on Amazon EC2 instances and Amazon RDS. The application's demand varies based on the time of day. The load is minimal after work hours and on weekends. The EC2 instances run in an EC2 Auto Scaling group that is configured with a minimum of two instances and a maximum of five instances. The application must be available at all times, but the company is concerned about overall cost.\nWhich solution meets the availability requirement MOST cost-effectively?"
    },
    "choices": {
      "kor": {
        "A": "모든 EC2 스팟 인스턴스를 사용하십시오. 사용하지 않을 때는 RDS 데이터베이스를 중지하십시오.",
        "B": "5개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans를 구입합니다. RDS 예약 DB 인스턴스를 구매합니다.",
        "C": "2개의 EC2 예약 인스턴스를 구입합니다. 필요에 따라 최대 3개의 추가 EC2 스팟 인스턴스를 사용합니다. 사용하지 않을 때는 RDS 데이터베이스를 중지하십시오.",
        "D": "2개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans를 구입합니다. 필요에 따라 최대 3개의 추가 EC2 온디맨드 인스턴스를 사용합니다. RDS 예약 DB 인스턴스를 구",
        "E": "매합니다."
      },
      "eng": {
        "A": "Use all EC2 Spot Instances. Stop the RDS database when it is not in use.",
        "B": "Purchase EC2 Instance Savings Plans to cover five EC2 instances. Purchase an RDS Reserved DB Instance.",
        "C": "Purchase two EC2 Reserved Instances. Use up to three additional EC2 Spot Instances as needed. Stop the RDS database when it is not in use.",
        "D": "Purchase EC2 Instance Savings Plans to cover two EC2 instances. Use up to three additional EC2 On-Demand Instances as needed. Purchase an RDS Reserved DB Instance."
      }
    },
    "category": [
      "Availability"
    ],
    "subcategory": [
      "EC2 Instance Savings Plan",
      "Spot instancessx"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/81440-exam-aws-certified-solutions-architect-associate-saa-c02/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 149,
    "question": {
      "kor": "솔루션 설계자는 정적 웹 사이트를 저장하기 위해 Amazon S3 오리진과 함께 Amazon CloudFront를 사용하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹 사이트 트래픽은 AWS WAF에서 검사해야 합니다.\n솔루션 설계자는 이러한 요구 사항을 어떻게 준수해야 합니까?",
      "eng": "A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company’s security policy requires that all website traffic be inspected by AWS WAF.\nHow should the solutions architect comply with these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS WAF Amazon 리소스 이름(ARN)에서만 오는 요청을 수락하도록 S3 버킷 정책을 구성합니다.",
        "B": "S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF로 전달하도록 Amazon CloudFront를 구성합니다.",
        "C": "Amazon CloudFront IP 주소가 Amazon S3에만 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에 연결합니다.",
        "D": "원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 Amazon S3를 구성합니다. 배포에서 AWS WAF를 활성화합니다."
      },
      "eng": {
        "A": "Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.",
        "B": "Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.",
        "C": "Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.",
        "D": "Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution."
      }
    },
    "category": [
      "WAF"
    ],
    "subcategory": [
      "CloudFront",
      "S3",
      "OAI"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/87524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  },
  {
    "idx": 150,
    "question": {
      "kor": "회사에서 기존 온프레미스 모놀리식 애플리케이션을 AWS로 마이그레이션하려고 합니다. 회사는 프런트엔드 코드와 백엔드 코드를 최대한 많이 유지하려고 합니다. 그러나 회사는 응용 프로그램을 더 작은 응용 프로그램으로 나누기를 원합니다. 다른 팀이 각 애플리케이션을 관리합니다. 이 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 필요합니다.\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
      "eng": "A company wants to migrate its existing on-premises monolithic application to AWS. The company wants to keep as much of the front-end code and the backend code as possible. However, the company wants to break the application into smaller applications. A different team will manage each application.\nThe company needs a highly scalable solution that minimizes operational overhead.\nWhich solution will meet these requirements?"
    },
    "choices": {
      "kor": {
        "A": "AWS Lambda에서 애플리케이션을 호스팅합니다. 애플리케이션을 Amazon API Gateway와 통합합니다.",
        "B": "AWS Amplify로 애플리케이션을 호스팅합니다. AWS Lambda와 통합된 Amazon API Gateway API에 애플리케이션을 연결합니다.",
        "C": "Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Auto Scaling 그룹의 EC2 인스턴스를 대상으로 하는 Application Load Balancer를 설정합니다.",
        "D": "Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS를 대상으로 하는 Application Load Balancer를 설정합니다."
      },
      "eng": {
        "A": "Host the application on AWS Lambda. Integrate the application with Amazon API Gateway.",
        "B": "Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda.",
        "C": "Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets.",
        "D": "Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target."
      }
    },
    "category": [
      "ECS"
    ],
    "subcategory": [
      "microservice",
      "keep the code"
    ],
    "rote_memorization": false,
    "reference": "https://www.examtopics.com/discussions/amazon/view/86473-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "answer": [
      "D"
    ]
  }
]